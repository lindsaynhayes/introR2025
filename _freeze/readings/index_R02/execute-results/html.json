{
  "hash": "61bccf8a1e927b1cea4402b4409b4827",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Navigating Data Types in R\"\ndescription: \"Reading for Class 02\"\nauthor: \n  - name: Lindsay Hayes\n    url: https://lindsaynhayes.github.io\n    affiliation: Department of Cell Biology, OUHSC\ndate: 2025-07-03\ndraft: false\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\nThe last class introduced important concepts in data science such as directory structure, working directories, projects, and quarto. This lesson will dig deeper into working in R. We will cover importing and exporting, data objects, and operations. \n\nSpreadsheets are good for data entry. As a scientists, we have a lot of data in spreadsheets. However, data exploration, manipulation, and visualization tools in spreadsheets are extremely limited and cumbersome when performed manually. Much of your time as a researcher will be spent **data wrangling** to generate the analyses you desire. R makes this process easy and most importantly reproducible.\n\n::: callout-note\n### Learning objectives\n\n**At the end of this lesson you will be able to:**\n\n-   Generate and navigate a quarto document\n-   Understand what packages are and how to use them\n-   Get data in and out of R\n-   Recognize and create various data types in R\n:::\n\n## Welcome to Quarto\n\nIn the first class, we looked at the `PalmerPenguins` data in a very tidy and curated quarto document to see how you can incorporate narrative text, code, outputs, and more in a single document. I hope you can now appreciate the utility of using Quarto to tell the story of the data analysis. The beautiful html outputs can easily be shared with others and helps build the logic of a data analysis pipeline from beginning to end.\n\nRead the [Quarto welcome tutorial](https://quarto.org/docs/get-started/hello/rstudio.html) to learn about some of the cool tools, such as `code-folding`, `echo=false`, and more.\n\n-   Read through Part 1: \"Hello, Quarto\"\n-   Read through Part 2: \"Computations\".\n-   Part 3 is more advanced for generating diverse outputs such as pdf documents feel free to explore, but we won't use this feature.\n\n## The Tidyverse\n\n### What is a package?\n\nIn R, the fundamental unit of shareable code is the **package.** A package bundles together *code*, *data*, *documentation*, and *tests*, and is easy to share with others. There are tens of thousands of R packages that exist. Two main repository of R packages exist. **CRAN** or the Comprehensive R Archive Network is the public clearing house for R packages and where you went to install R. **Bioconductor** is an open source project that develops and shares open source software for precise and repeatable analysis of biological data. It is this huge variety of packages that R is so successful because the chances are high that someone has already solved a problem that you’re working on.\n\n### How to get a package?\n\nTo install packages from CRAN use the `install.packages()` function. Once the package is installed you can load the pack using the `library()` function. Installing packages from Bioconductor take a few more steps which we won't cover just yet.\n\n<img src=\"figs/tidy_hex.png\" width=\"50%\" style=\"float:right\"/>\n\n### Tidyverse package\n\nThe [Tidyverse](https://www.tidyverse.org) which is a collection of R packages that share an underlying design, syntax, and grammer to streamline many main functions used in data science. You can install the complete tidyverse with `install.packages(\"tidyverse\")`, once the package is installed you can load it using `library(tidyverse)`.\n\nThe packages installed in tidyverse include:\n\n-   `ggplot2` is a graphic package to plot your data.\n-   `dplyr` and `tidyr` are packages for data manipulation to subset, re-arrange, and format your dataset.\n-   `readr` is a tidy way to input or read in data into R.\n-   `purrr` is a functional programming toolkit to handle looping functions.\n-   `tibble` is a tidy way of displaying data frames that are easier to view.\n-   `stringr` is a way of handling text and character strings.\n-   `forcats` is a package providing tools to handle categorical variables and discrete (non-continuous) variables.\n-   `lubridate` is a package for working with times and dates.\n\n::: callout-important\nThere are nice [cheatsheets](https://posit.co/resources/cheatsheets/) for each of the packages to demonstrate what they do in detail!\n:::\n\n## Tidy Syntax\n\nThe BIG picture of what we do in data science. \n\n<img src=\"figs/base.png\" width=\"90%\" style=\"display:block; margin-left: auto; margin-right: auto\"/>\n<figcaption>Figure 1: In our model of the data science process, you start with data import and tidying. Next, you understand your data with an iterative cycle of transforming, visualizing, and modeling. You finish the process by communicating your results to other humans.</figcaption>\n\n### Import\nFirst we need to import data into R. I prefer to import .csv files because I think its a good way to indicate a data file and it eliminates any weird formatting that may exist in excel. I am showing 2 ways to import the data one using base R function `read.csv()` and the other using the `readr` function `read_csv`. \n\nIn base R, the `header` field determines if the first row of the data had column header titles or not. The `stringsAsFactors` determines if the character variables in your data set should be set as a factor variable (set as TRUE) or as character (set to FALSE). The `row.names` field will allow you to specify if the first column is data or the names of the rows. \n\nIn tidyverse, the `col_names` field specifies if the first row is a header. If you want to specify the type of data for each field you have to specify it using the `col_types` field. I specified that for you here. There are a lot more options you can look at in the *Help* section.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\n\n# reading in csv is for importing comma-separated files\n\n# base R\ndata_base <- read.csv(file = \"data/taylorswift.csv\", \n                 header = TRUE, \n                 sep = \",\", \n                 stringsAsFactors = TRUE)\n\n\n# Tidyverse\ndata_tidy <- read_csv(file = \"data/taylorswift.csv\",\n                 col_names = TRUE)\n```\n:::\n\n\nUsing `readr` you can also import data directly from excel spreadsheets using `read_excel` or `read_xls` and even google sheets using `read_sheet`. However, we won't use these function in the course. But you are free to explore them on your own from the [readr package](https://readr.tidyverse.org).\n\n### Export\nYou can also save files using the `write` functions for both csv or tsv files. \n\n::: {.cell}\n\n```{.r .cell-code}\n# base R\nwrite.csv(data, file = \"data/taylorswift.csv\")\n\n# Tidyverse\nwrite_csv(data, file = \"data/taylorswift.csv\")\n```\n:::\n\n\n\n### Manipulating Data Types\nR requires data to be in specific formats in order to perform **operations** on the data. Recall from last class the major types of data!\n\n::: {.callout-important}\n## DATA TYPES\n\n-   character\n-   numeric\n-   integer\n-   factor\n-   logical\n:::\n\nLets look at data types in the `taylorswift` data in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# first load the packages we are going to need\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(ggplot2)\n\n# next import some data, as an example we are using the taylorswift data\ndata <- read_csv(file = \"data/taylorswift.csv\",\n                 col_names = TRUE)\n\n# Its good to start any data analysis with basic data exploration.\n# how many columns of data are there?\nncol(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 21\n```\n\n\n:::\n\n```{.r .cell-code}\n# how many rows of observations are there?\nnrow(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 314\n```\n\n\n:::\n\n```{.r .cell-code}\n# when we imported the data, what is the type of data in each column?\nas.data.frame(map_chr(data, class))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 map_chr(data, class)\nalbum_name                  character\nalbum_release                    Date\ntrack_number                  numeric\ntrack_name                  character\ndanceability                  numeric\nenergy                        numeric\nkey                           numeric\nloudness                      numeric\nmode                          numeric\nspeechiness                   numeric\nacousticness                  numeric\ninstrumentalness              numeric\nliveness                      numeric\nvalence                       numeric\ntempo                         numeric\ntime_signature                numeric\nduration_ms                   numeric\nexplicit                      logical\nkey_name                    character\nmode_name                   character\nkey_mode                    character\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 314\nColumns: 21\n$ album_name       <chr> \"Taylor Swift\", \"Taylor Swift\", \"Taylor Swift\", \"Tayl…\n$ album_release    <date> 2006-10-24, 2006-10-24, 2006-10-24, 2006-10-24, 2006…\n$ track_number     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1,…\n$ track_name       <chr> \"Tim McGraw\", \"Picture To Burn\", \"Teardrops On My Gui…\n$ danceability     <dbl> 0.580, 0.658, 0.621, 0.576, 0.418, 0.589, 0.479, 0.59…\n$ energy           <dbl> 0.491, 0.877, 0.417, 0.777, 0.482, 0.805, 0.578, 0.62…\n$ key              <dbl> 0, 7, 10, 9, 5, 5, 2, 8, 4, 2, 2, 8, 7, 4, 10, 5, 7, …\n$ loudness         <dbl> -6.462, -2.098, -6.941, -2.881, -5.769, -4.055, -4.96…\n$ mode             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ speechiness      <dbl> 0.0251, 0.0323, 0.0231, 0.0324, 0.0266, 0.0293, 0.029…\n$ acousticness     <dbl> 0.57500, 0.17300, 0.28800, 0.05100, 0.21700, 0.00491,…\n$ instrumentalness <dbl> 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.0…\n$ liveness         <dbl> 0.1210, 0.0962, 0.1190, 0.3200, 0.1230, 0.2400, 0.084…\n$ valence          <dbl> 0.425, 0.821, 0.289, 0.428, 0.261, 0.591, 0.192, 0.50…\n$ tempo            <dbl> 76.009, 105.586, 99.953, 115.028, 175.558, 112.982, 1…\n$ time_signature   <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ duration_ms      <dbl> 232107, 173067, 203040, 199200, 239013, 207107, 24810…\n$ explicit         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ key_name         <chr> \"C\", \"G\", \"A#\", \"A\", \"F\", \"F\", \"D\", \"G#\", \"E\", \"D\", \"…\n$ mode_name        <chr> \"major\", \"major\", \"major\", \"major\", \"major\", \"major\",…\n$ key_mode         <chr> \"C major\", \"G major\", \"A# major\", \"A major\", \"F major…\n```\n\n\n:::\n:::\n\n\nThe most common data type conversions are between:\n1) characters -> factors\n2) numeric --> factors\n\nFor example, if we wanted to see how the loudness differs across Taylor Swift albums we need to convert the `album_name` vector into a factor variable\n\n::: {.cell}\n\n```{.r .cell-code}\n# note alphabetical order\nggplot(data, aes(x=album_release, y=duration_ms, color = album_name)) + geom_point()\n\n\nggplot(data, aes(x=track_number, y=duration_ms, color = album_name)) + geom_point()\n\n\nmod <- lm(duration_ms ~ album_name, data = data) \nanova(mod)\n\n\n\n\n\n# change the album name from character to factor\ndata$album_name <- as.factor(data$album_name) # order = alphabetical\ndata$album_name <- as_factor(data$album_name) # order = as unique()\n\nmod <- lm(tempo ~ album_name, data = data) \nanova(mod)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# sometimes we want numeric variables as numbers and sometimes we want them to be factors. In this case the x axis is spaced based on the time between album releases.\nggplot(data, aes(x=album_release, y = track_number)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](index_R02_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# If we convert the year to a factor variable the time between won't matter and it will be equally distributed.\n\ndata$album_release <- as.factor(data$album_release)\nggplot(data, aes(x=album_release, y = track_number)) + geom_point() + \n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](index_R02_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# This makes a big difference not only for the plotting, but will also impact how statistical analyses are performed. So be careful and make sure the data type is correctly specified (continuous versus categorical versus factored versus ordered)\n\n\nggplot(data, aes(x=time_signature, y = key)) + geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_R02_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n:::\n\n\n\n\n\nExamples I want to include:\ncharacter to factor and ordered\nhow that makes a difference in plotting and statistics\n\nnumeric to factor and ordered\nhow that makes a difference in plotting and statistics\n\n\n\n\n\n::: callout-tip\n### Want More?\n\nThere are so many great tools to learn R and data science!\n\n-   To explore the tidyverse and data science in more detail check out the *R for Data Science* [textbook](https://r4ds.hadley.nz) written by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\n\n-   Want more stats and data science conversations?! Check out the **not so standard deviations** [podcast](https://nssdeviations.com) by Roger Peng and Hilary Parker.\n:::\n",
    "supporting": [
      "index_R02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "701f729e293bb81c2b3cfa8d9f60591a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Wrangling with tidyverse\"\ndescription: \"Reading for Class 03\"\nauthor: \n  - name: Lindsay Hayes\n    url: https://lindsaynhayes.github.io\n    affiliation: Department of Cell Biology, OUHSC\ndate: 2025-07-08\ndraft: false\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\n\n::: callout-note\n### Learning objectives\n\n**At the end of this lesson you will be able to:**\n\n-   Recognize and define an untidy dataset\n-   Recognize and convert between long and wide data formats\n-   Understand when to use both formats\n-   Pipe functions together to perform multiple commands in sequence\n:::\n\n## The problem with messy data\n\nMost scientists are not trained to collect and organize data using `tidydata` principles. The results are data sets which are hard to follow, difficult to repeat, and challenging to report to journals. Understanding how to organize and store your data and analyses will make your life easier! Moreover, many journals request raw data submissions along with your manuscript. If you've analyzed and organized all your data in `R` using `tidydata` principles this process becomes a super simple, rather than tracking all the data across messy spreadsheets.\n\n> \"Tidy datasets are all alike, but every messy dataset is messy in its own way.\"\\\n> --- Hadley Wickham\n\n## The principles of `tidydata`\n\n1.  **Treat your raw data as immutable.**\n\n*Try to manipulate the original form of the data as little as possible. The reason is to make the whole data analysis pipeline reproducible and transparent. If you start changing fields on the data spreadsheet you can't track where those values came from. Manipulating data with code also decreases the chances for errors being introduced to the raw data.*\n\n2.  **Each variable is a column; each column is a variable.**\n\n3.  **Each observation is a row; each row is an observation.**\n\n4.  **Each value is a cell; each cell is a single value.**\n\nFor example, take the following data\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n      groups val\n1   Con_male 134\n2 CON_female 106\n3      Exp_m  84\n4      Exp_F 105\n```\n\n\n:::\n:::\n\n\n\n**Why might this data be a problem?**\n\n-   combining 2 observations into one field (group and sex).\n-   changing the notation styles\n\nHere's another example\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  groups      val2\n1    CON  78_ug/ul\n2    CON  67_ug/ul\n3    EXP  69_ug/ul\n4    EXP 115_ug/ul\n```\n\n\n:::\n:::\n\n\n\n**Why might this data be a problem?**\n\n-   the data field contains 2 values the numeric value and the units\n\nThe second step after getting your data into R is **data wrangling** in order to modify the data so that you can perform an analysis. Luckily R has a whole suite of tools to makes this process easy and most importantly reproducible. This less will teach you practices for effective data wrangling.\n\n## The Tidyverse\n\n<img src=\"figs/tidy_hex.png\" width=\"50%\" style=\"float:right\"/>\n\nThe [Tidyverse](https://www.tidyverse.org) which is a collection of R packages that share an underlying design, syntax, and grammer to streamline many main functions used in data science. You can install the complete tidyverse with `install.packages(\"tidyverse\")`, once the package is installed you can load it using `library(tidyverse)`.\n\nThe packages installed in tidyverse include:\n\n-   `dplyr` and `tidyr` are packages for data manipulation to subset, re-arrange, and format your dataset.\n-   `tibble` is a tidy way of displaying data frames that are easier to view.\n-   `readr` is a tidy way to input or read in data into R that we covered last class.\n-   `purrr` is a functional programming toolkit to handle looping functions.\n-   `stringr` is a way of handling text and character strings.\n-   `forcats` is a package providing tools to handle categorical variables and discrete (non-continuous) variables.\n-   `lubridate` is a package for working with times and dates.\n-   `ggplot2` is a graphic package to plot your data. We will cover this package in the next class!\n\n::: callout-important\nThere are nice [cheatsheets](https://posit.co/resources/cheatsheets/) for each of the packages to demonstrate what they do in detail!\n\nDon't forget to check out the *Help* section in RStudio for any function you come across.\n:::\n\n## The BIG picture\n\nWe have now progressed to the Tidy part of the data analysis pipeline!\n\n<img src=\"figs/tidy.png\" width=\"90%\" style=\"display:block; margin-left: auto; margin-right: auto\"/>\n\n<figcaption>Figure 1: In our model of the data science process, you start with data import and tidying. Next, you understand your data with an iterative cycle of transforming, visualizing, and modeling. You finish the process by communicating your results to other humans.</figcaption>\n\n## Examples of some not so tidy data\n\nHave you seen or even generated data that looks like this?\n\n#### example 1\n\n::: img-float\n<img src=\"figs/untidy1.png\" width=\"90%\" style=\"float:center\"/>\n:::\n\n#### example 2\n\n::: img-float\n<img src=\"figs/untidy2.png\" width=\"90%\" style=\"float:center\"/>\n:::\n\n#### example 3\nsome of my data! \n\n::: {.img-float} \n<img src=\"figs/untidy3.png\" width=\"90%\" style=\"float:center\"/> \n:::\n\n## Tidy data with `tidyr`\n\n`tidyr` is a package with tools that help you create **tidy data**. `tidyr` functions reform the data so that other R functions can perform manipulation or analysis on it.\n\n### Wide vs Long\n\nWide data puts many variables for each observation in the same row. An example is a time series, where each time point for an observation is in a different column. Data in this format can be easier to data enter when the data is collected. However, it is difficult for R to then plot or evaluate across time, but we need to convert it in R.\n\nHere is an example of wide data, you can see different metrics across time are represented across the columns for each country.\n\n![](figs/tidyr-wide.png)\n\nThis is an example of long data. Now each value is in a single column. The next step would be to split the observation type and the year into 2 separate columns that we'll cover below.\n\n![](figs/tidyr-long.png){fig-align=\"center\" width=\"341\"}\n\nTo convert between wide to longer we use the function `pivot_longer()` and to convert between long to wide we use the function `pivot_wider()`. The `pivot_longer()` function takes the main arguments `data`, `cols`, `names_to`, and `values_to`. `data` is the input data (the wide data frame). `cols` is the columns of the data you want to convert, you don't have to use the whole data set you can only select a few columns if you want. `names_to` is what you want to name the header of the new variable you are creating this is often called the \"key\" or for example the observation type in the above example. `values_to` is what you want to call the actual data \"value\" this could be the concentration or the units of the measurement.\n\n![](figs/tidyr-wide_long2.png)\n\nLets look at an example in code!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndata <- read_csv(\"data/wide_data.csv\")\nglimpse(data) # first look at the data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 10\nColumns: 11\n$ Dam               <chr> \"HFD-25-01\", \"HFD-25-02\", \"HFD-25-03\", \"HFD-25-04\", …\n$ Group             <chr> \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"HFD\", \"HFD\", \"HF…\n$ `Baseline Weight` <dbl> 21.1, 22.4, 22.4, 22.8, 22.8, 21.8, 23.0, 23.6, 22.0…\n$ `Wk1 Weight`      <dbl> 20.0, 20.9, 22.2, 22.4, 21.8, 23.8, 25.8, 22.7, 23.2…\n$ `Wk2 Weight`      <dbl> 20.0, 21.2, 22.6, 23.1, 22.5, 23.6, 26.4, 21.8, 22.7…\n$ `Wk3 Weight`      <dbl> 19.9, 22.2, 22.3, 22.4, 22.0, 26.2, 29.4, 24.9, 25.4…\n$ `Wk4 Weight`      <dbl> 20.3, 21.7, 22.3, 24.1, 21.8, 28.1, 31.6, 22.9, 26.7…\n$ `Wk5 Weight`      <dbl> 20.7, 22.4, 22.6, 25.0, 21.9, 27.8, 35.8, 23.8, 31.5…\n$ `Wk6 Weight`      <dbl> 21.4, 22.7, 23.4, 23.1, 23.4, 31.6, 34.8, 25.5, 33.8…\n$ `Wk7 Weight`      <dbl> 21.1, 22.0, 23.2, 24.1, 23.0, 32.0, 36.7, 28.5, 30.8…\n$ `Wk8 Weight`      <dbl> 21.1, 21.0, 22.0, 23.2, 22.8, 32.8, 38.2, 25.3, 33.3…\n```\n\n\n:::\n:::\n\n\nYou can see the weight each week but its spread across columns lets convert to long format\n\nUsing the `pivot_longer()` function we tell it to take columns 3 through 11 and put the column names into a new column called week and the weights into a new column called grams using this code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong.data <- data |> \n  pivot_longer(cols = c(3:11), names_to = \"week\", values_to = \"grams\")\n\nglimpse(long.data) # this is what the new data looks like. \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 90\nColumns: 4\n$ Dam   <chr> \"HFD-25-01\", \"HFD-25-01\", \"HFD-25-01\", \"HFD-25-01\", \"HFD-25-01\",…\n$ Group <chr> \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"…\n$ week  <chr> \"Baseline Weight\", \"Wk1 Weight\", \"Wk2 Weight\", \"Wk3 Weight\", \"Wk…\n$ grams <dbl> 21.1, 20.0, 20.0, 19.9, 20.3, 20.7, 21.4, 21.1, 21.1, 22.4, 20.9…\n```\n\n\n:::\n:::\n\n\nThe data is separated into weeks and weight. Now we could plot it across time.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_R03_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\nOther times we need the data to be **wide** format if we want to do computations on the data. For example, maybe we want to determine the percent weight change from baseline and plot that instead of the absolute weight. Lets convert it back to wide format using `pivot_wider()`.\n\nWe tell `pivot_wider()` it to take the \"week\" column and make a new columnn for each unique value and put the value of grams in the cells as the values for each unique week column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwide.data <- pivot_wider(long.data, names_from = week, values_from = grams)\nglimpse(wide.data) # look at the data again\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 10\nColumns: 11\n$ Dam               <chr> \"HFD-25-01\", \"HFD-25-02\", \"HFD-25-03\", \"HFD-25-04\", …\n$ Group             <chr> \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"HFD\", \"HFD\", \"HF…\n$ `Baseline Weight` <dbl> 21.1, 22.4, 22.4, 22.8, 22.8, 21.8, 23.0, 23.6, 22.0…\n$ `Wk1 Weight`      <dbl> 20.0, 20.9, 22.2, 22.4, 21.8, 23.8, 25.8, 22.7, 23.2…\n$ `Wk2 Weight`      <dbl> 20.0, 21.2, 22.6, 23.1, 22.5, 23.6, 26.4, 21.8, 22.7…\n$ `Wk3 Weight`      <dbl> 19.9, 22.2, 22.3, 22.4, 22.0, 26.2, 29.4, 24.9, 25.4…\n$ `Wk4 Weight`      <dbl> 20.3, 21.7, 22.3, 24.1, 21.8, 28.1, 31.6, 22.9, 26.7…\n$ `Wk5 Weight`      <dbl> 20.7, 22.4, 22.6, 25.0, 21.9, 27.8, 35.8, 23.8, 31.5…\n$ `Wk6 Weight`      <dbl> 21.4, 22.7, 23.4, 23.1, 23.4, 31.6, 34.8, 25.5, 33.8…\n$ `Wk7 Weight`      <dbl> 21.1, 22.0, 23.2, 24.1, 23.0, 32.0, 36.7, 28.5, 30.8…\n$ `Wk8 Weight`      <dbl> 21.1, 21.0, 22.0, 23.2, 22.8, 32.8, 38.2, 25.3, 33.3…\n```\n\n\n:::\n:::\n\n\n\nNext, we want to calculate the percent weight gain by performing this calculation for each row `Wk8 Weight`/`Baseline Weight` * 100 to determine the percent of weight gain. This computation is done more easily if the data is in wide format.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwide.data <- wide.data |> mutate(perc.gain = `Wk8 Weight`/`Baseline Weight`*100)\nglimpse(wide.data) # check it out\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 10\nColumns: 12\n$ Dam               <chr> \"HFD-25-01\", \"HFD-25-02\", \"HFD-25-03\", \"HFD-25-04\", …\n$ Group             <chr> \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"HFD\", \"HFD\", \"HF…\n$ `Baseline Weight` <dbl> 21.1, 22.4, 22.4, 22.8, 22.8, 21.8, 23.0, 23.6, 22.0…\n$ `Wk1 Weight`      <dbl> 20.0, 20.9, 22.2, 22.4, 21.8, 23.8, 25.8, 22.7, 23.2…\n$ `Wk2 Weight`      <dbl> 20.0, 21.2, 22.6, 23.1, 22.5, 23.6, 26.4, 21.8, 22.7…\n$ `Wk3 Weight`      <dbl> 19.9, 22.2, 22.3, 22.4, 22.0, 26.2, 29.4, 24.9, 25.4…\n$ `Wk4 Weight`      <dbl> 20.3, 21.7, 22.3, 24.1, 21.8, 28.1, 31.6, 22.9, 26.7…\n$ `Wk5 Weight`      <dbl> 20.7, 22.4, 22.6, 25.0, 21.9, 27.8, 35.8, 23.8, 31.5…\n$ `Wk6 Weight`      <dbl> 21.4, 22.7, 23.4, 23.1, 23.4, 31.6, 34.8, 25.5, 33.8…\n$ `Wk7 Weight`      <dbl> 21.1, 22.0, 23.2, 24.1, 23.0, 32.0, 36.7, 28.5, 30.8…\n$ `Wk8 Weight`      <dbl> 21.1, 21.0, 22.0, 23.2, 22.8, 32.8, 38.2, 25.3, 33.3…\n$ perc.gain         <dbl> 100.00000, 93.75000, 98.21429, 101.75439, 100.00000,…\n```\n\n\n:::\n:::\n\n\nnow you can see the new column of data called perc.gain as a new column at the end. We'll talk more about the `mutate()` function below. \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_R03_files/figure-html/unnamed-chunk-7-1.png){width=384}\n:::\n:::\n\n\n\n### Unite vs Separate\nAs we saw in countries data above sometimes we get data that has multiple pieces of data in one field. We can fix this problem with `separate_wider_delim()` function that will split a cell into 2 columns based on a specified delimiter. If you've ever used the \"text to columns\" feature in excel its essentially the same thing.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(data) # lets look at the countries data.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 5,112\nColumns: 4\n$ country      <fct> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan…\n$ continent    <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asi…\n$ obstype_year <chr> \"pop_1952\", \"lifeExp_1952\", \"gdpPercap_1952\", \"pop_1957\",…\n$ obs_value    <dbl> 8.425333e+06, 2.880100e+01, 7.794453e+02, 9.240934e+06, 3…\n```\n\n\n:::\n:::\n\n\nAs you can see the \"obstype_year\" has too many pieces of information in it. Before we can `pivot_wider()`, we need to split out the observation by type and the year using the `separate_wider_delim()` function. We tell the function which column to split, what the names of the splits will be, and how the fields are deliminated. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- separate_wider_delim(data, cols = obstype_year, names = c(\"obstype\", \"year\"), delim = \"_\")\nglimpse(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 5,112\nColumns: 5\n$ country   <fct> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", …\n$ continent <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, …\n$ obstype   <chr> \"pop\", \"lifeExp\", \"gdpPercap\", \"pop\", \"lifeExp\", \"gdpPercap\"…\n$ year      <chr> \"1952\", \"1952\", \"1952\", \"1957\", \"1957\", \"1957\", \"1962\", \"196…\n$ obs_value <dbl> 8.425333e+06, 2.880100e+01, 7.794453e+02, 9.240934e+06, 3.03…\n```\n\n\n:::\n:::\n\n\nNow the data is in a format that can be put into pivot_wider() to get out each of the observation types.\n\n\n### Nesting and Unnesting\nAnother cool function related to spliting data is a function called `unnest_longer`. We talked a little in the first class about a class of data called list which is very flexible on what can be put there, but you need special functions to access that data. Unnest is a way to unnest the listed items that are embedded into a dataframe. Lets look at the taylor swift data as an example.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(taylor)\n\ntaylor <- taylor_album_songs\nglimpse(taylor) # look at some data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 240\nColumns: 29\n$ album_name          <chr> \"Taylor Swift\", \"Taylor Swift\", \"Taylor Swift\", \"T…\n$ ep                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ album_release       <date> 2006-10-24, 2006-10-24, 2006-10-24, 2006-10-24, 2…\n$ track_number        <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…\n$ track_name          <chr> \"Tim McGraw\", \"Picture To Burn\", \"Teardrops On My …\n$ artist              <chr> \"Taylor Swift\", \"Taylor Swift\", \"Taylor Swift\", \"T…\n$ featuring           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ bonus_track         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ promotional_release <date> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ single_release      <date> 2006-06-19, 2008-02-03, 2007-02-19, NA, NA, NA, N…\n$ track_release       <date> 2006-06-19, 2006-10-24, 2006-10-24, 2006-10-24, 2…\n$ danceability        <dbl> 0.580, 0.658, 0.621, 0.576, 0.418, 0.589, 0.479, 0…\n$ energy              <dbl> 0.491, 0.877, 0.417, 0.777, 0.482, 0.805, 0.578, 0…\n$ key                 <int> 0, 7, 10, 9, 5, 5, 2, 8, 4, 2, 2, 8, 7, 4, 10, 5, …\n$ loudness            <dbl> -6.462, -2.098, -6.941, -2.881, -5.769, -4.055, -4…\n$ mode                <int> 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ speechiness         <dbl> 0.0251, 0.0323, 0.0231, 0.0324, 0.0266, 0.0293, 0.…\n$ acousticness        <dbl> 0.57500, 0.17300, 0.28800, 0.05100, 0.21700, 0.004…\n$ instrumentalness    <dbl> 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, …\n$ liveness            <dbl> 0.1210, 0.0962, 0.1190, 0.3200, 0.1230, 0.2400, 0.…\n$ valence             <dbl> 0.425, 0.821, 0.289, 0.428, 0.261, 0.591, 0.192, 0…\n$ tempo               <dbl> 76.009, 105.586, 99.953, 115.028, 175.558, 112.982…\n$ time_signature      <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ duration_ms         <int> 232107, 173067, 203040, 199200, 239013, 207107, 24…\n$ explicit            <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ key_name            <chr> \"C\", \"G\", \"A#\", \"A\", \"F\", \"F\", \"D\", \"G#\", \"E\", \"D\"…\n$ mode_name           <chr> \"major\", \"major\", \"major\", \"major\", \"major\", \"majo…\n$ key_mode            <chr> \"C major\", \"G major\", \"A# major\", \"A major\", \"F ma…\n$ lyrics              <list> [<tbl_df[55 x 4]>], [<tbl_df[33 x 4]>], [<tbl_df[…\n```\n\n\n:::\n:::\n\n\nIf you look at the last line the lyrics is a list which is a tibble (or table) that is the all the lines of lyrics for each song. Since each line is a song and the lyrics can be many lines long its a nice way to be able to store a table inside a data frame. cool huh! If you wanted to access the lyrics you need to unnest the lyric data in the table. The function unnest_longer() does that.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlyr <- taylor |> select(album_name, track_name, lyrics) |> unnest_longer(lyrics)\ndim(lyr) # the dimensions of the data number of rows and number of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12151     3\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(lyr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  album_name   track_name lyrics$line $lyric            $element $element_artist\n  <chr>        <chr>            <int> <chr>             <chr>    <chr>          \n1 Taylor Swift Tim McGraw           1 \"He said the way… Verse 1  Taylor Swift   \n2 Taylor Swift Tim McGraw           2 \"Put those Georg… Verse 1  Taylor Swift   \n3 Taylor Swift Tim McGraw           3 \"I said, \\\"That'… Verse 1  Taylor Swift   \n4 Taylor Swift Tim McGraw           4 \"Just a boy in a… Verse 1  Taylor Swift   \n5 Taylor Swift Tim McGraw           5 \"That had a tend… Verse 1  Taylor Swift   \n6 Taylor Swift Tim McGraw           6 \"On backroads at… Verse 1  Taylor Swift   \n```\n\n\n:::\n:::\n\n\nYou can see the dataframe is much longer (12,151 rows) as each row is a lyric. If you wanted to see how many times specific words were used this is how you could do it.\n\n## Transform data with `dplyr`\n\n<img src=\"figs/transform.png\" width=\"90%\" style=\"display:block; margin-left: auto; margin-right: auto\"/>\n\nOnce the data is tidy we can do transformation and calculations for downstream analysis. You've already seen some of these tools in action throughout the course. We'll formally go over them now so you'll recognize it when you see it!\n\nThe functions we'll use *in combinations* include: \n\n- `select()`\n- `filter()`\n- `arrange()`\n- `distinct()`\n- `count()`\n- `summarize()`\n- `group_by()`\n- `mutate()`\n\n::: callout-important\n### Remember your pipes!\n\n`%>%` & `|>` These allow you to link functions together\n:::\n\n::: callout-note\n### A note on style\nWhen using pipes it is tidy style to put everything after a pipe on a new line so each line of code is noting one operation so its easier to understand. This may seem silly when you're only doing one operation, but the standard style is for it to be on a new line. \n:::\n\n### Summary functions\n\n#### select()\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(palmerpenguins)\nglimpse(penguins) # lets look at the penguins data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n```\n\n\n:::\n:::\n\n\nIf we only want to look at the penguin body mass we can use the `select()` function to pull out only the data we want to see.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> select(species, island, body_mass_g) #(example, on one line of code)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 344 × 3\n   species island    body_mass_g\n   <fct>   <fct>           <int>\n 1 Adelie  Torgersen        3750\n 2 Adelie  Torgersen        3800\n 3 Adelie  Torgersen        3250\n 4 Adelie  Torgersen          NA\n 5 Adelie  Torgersen        3450\n 6 Adelie  Torgersen        3650\n 7 Adelie  Torgersen        3625\n 8 Adelie  Torgersen        4675\n 9 Adelie  Torgersen        3475\n10 Adelie  Torgersen        4250\n# ℹ 334 more rows\n```\n\n\n:::\n:::\n\n\n\n#### filter()\nNext, if we want to select only certain rows that meet a specific criteria we use the `filter()` function to filter out only the data we want. We can combine this with `select()` too.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n  select(species, island, body_mass_g) |> \n  filter(body_mass_g > 4000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 172 × 3\n   species island    body_mass_g\n   <fct>   <fct>           <int>\n 1 Adelie  Torgersen        4675\n 2 Adelie  Torgersen        4250\n 3 Adelie  Torgersen        4400\n 4 Adelie  Torgersen        4500\n 5 Adelie  Torgersen        4200\n 6 Adelie  Dream            4150\n 7 Adelie  Dream            4650\n 8 Adelie  Dream            4400\n 9 Adelie  Dream            4600\n10 Adelie  Dream            4150\n# ℹ 162 more rows\n```\n\n\n:::\n:::\n\n\n\n#### arrange()\narrange will re-order the data based on a specific column or columns. It we want to quickly see the lightest or heaviest penguins, for example.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lighest\npenguins |> \n  select(species, island, body_mass_g) |> \n  arrange(body_mass_g)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 344 × 3\n   species   island    body_mass_g\n   <fct>     <fct>           <int>\n 1 Chinstrap Dream            2700\n 2 Adelie    Biscoe           2850\n 3 Adelie    Biscoe           2850\n 4 Adelie    Biscoe           2900\n 5 Adelie    Dream            2900\n 6 Adelie    Torgersen        2900\n 7 Chinstrap Dream            2900\n 8 Adelie    Biscoe           2925\n 9 Adelie    Dream            2975\n10 Adelie    Dream            3000\n# ℹ 334 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n# heaviest using the `desc()` descending function.\npenguins |> \n  select(species, island, body_mass_g) |> \n  arrange(desc(body_mass_g))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 344 × 3\n   species island body_mass_g\n   <fct>   <fct>        <int>\n 1 Gentoo  Biscoe        6300\n 2 Gentoo  Biscoe        6050\n 3 Gentoo  Biscoe        6000\n 4 Gentoo  Biscoe        6000\n 5 Gentoo  Biscoe        5950\n 6 Gentoo  Biscoe        5950\n 7 Gentoo  Biscoe        5850\n 8 Gentoo  Biscoe        5850\n 9 Gentoo  Biscoe        5850\n10 Gentoo  Biscoe        5800\n# ℹ 334 more rows\n```\n\n\n:::\n:::\n\n\n\n#### distinct()\ndistinct is a function similar to unique. It identifies the distinct or unique features across one or multiple columns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# what are the distinct islands in the data? Note it is not counting the occurances (thats a different function)\npenguins |> \n  distinct(island)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 1\n  island   \n  <fct>    \n1 Torgersen\n2 Biscoe   \n3 Dream    \n```\n\n\n:::\n\n```{.r .cell-code}\n# what are the distinct islands and species?\npenguins |> \n  distinct(island, species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  island    species  \n  <fct>     <fct>    \n1 Torgersen Adelie   \n2 Biscoe    Adelie   \n3 Dream     Adelie   \n4 Biscoe    Gentoo   \n5 Dream     Chinstrap\n```\n\n\n:::\n:::\n\n\n\n#### count()\ncount is similar to the `table()` function in base R. It will tally the number of times that unique variable is listed. So its similar to distinct, but it includes the count of the number of occurances.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n  count(island, species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n  island    species       n\n  <fct>     <fct>     <int>\n1 Biscoe    Adelie       44\n2 Biscoe    Gentoo      124\n3 Dream     Adelie       56\n4 Dream     Chinstrap    68\n5 Torgersen Adelie       52\n```\n\n\n:::\n:::\n\n\n\n#### summarize\nsummarize is a powerful tool that summarizes many variables across the data. It can calculate mean, median, standard deviation, variance, sum, and many more features. It outputs a new table that includes just the summary data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lets look at the average mass of all the penguins\npenguins |> \n  summarize(avg_mass = mean(body_mass_g))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_mass\n     <dbl>\n1       NA\n```\n\n\n:::\n\n```{.r .cell-code}\n# this doesn't work... why? because there are missing values! We have to add a special note to remove the NA values using the na.rm = TRUE setting. We can also look at more than one summary data at a time!\n\npenguins |> \n  summarize(avg_mass = mean(body_mass_g, na.rm = TRUE),\n            sd = sd(body_mass_g, na.rm=TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_mass    sd\n     <dbl> <dbl>\n1    4202.  802.\n```\n\n\n:::\n:::\n\n\n\n#### group_by\nIf we wanted to summarize the data across categorical variables in the data we use the `group_by()` function that will first group the data and then perform a summary function on each grouping.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# just running group_by() you won't see any difference, but under the hood it is sorting the observations.\npenguins |> \n  group_by(island, species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 344 × 8\n# Groups:   island, species [5]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex <fct>, year <int>\n```\n\n\n:::\n\n```{.r .cell-code}\npenguins |> \n  group_by(island, species) |> \n  summarize(mean_mass = mean(body_mass_g, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'island'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n# Groups:   island [3]\n  island    species   mean_mass\n  <fct>     <fct>         <dbl>\n1 Biscoe    Adelie        3710.\n2 Biscoe    Gentoo        5076.\n3 Dream     Adelie        3688.\n4 Dream     Chinstrap     3733.\n5 Torgersen Adelie        3706.\n```\n\n\n:::\n\n```{.r .cell-code}\n# we can also add in multiple variables for spread or count\npenguins |> \n  group_by(island, species) |> \n  summarize(n=n(), \n            mean_mass = mean(body_mass_g, na.rm = TRUE), \n            sd = sd(body_mass_g, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'island'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n# Groups:   island [3]\n  island    species       n mean_mass    sd\n  <fct>     <fct>     <int>     <dbl> <dbl>\n1 Biscoe    Adelie       44     3710.  488.\n2 Biscoe    Gentoo      124     5076.  504.\n3 Dream     Adelie       56     3688.  455.\n4 Dream     Chinstrap    68     3733.  384.\n5 Torgersen Adelie       52     3706.  445.\n```\n\n\n:::\n:::\n\n\nExample calculations you can run in summarize: n(), sum(),mean(), median(), min(), max(), IQR(), sd(), var()\n\nThese commands output a new table and did not modify the original data. However, sometimes you need to add a new calculation or mutate how the data is presented you can do that with the mutate function. If you paid attention above when we looked at the percent weight gain on high fat diet we used the `mutate()` function to add the new variable to the data. \n\n### mutate()\n`mutate()` takes all the same functions that summarize did above. The big difference is that instead of returning a new table or a single value it returns the whole dataset with a new column.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# if we run the same command as above but with mutate instead of summarize look at how the results differ\npenguins |> \n  group_by(island, species) |> \n  mutate(mean_mass = mean(body_mass_g, na.rm = TRUE)) |> glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 344\nColumns: 9\nGroups: island, species [5]\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ mean_mass         <dbl> 3706.373, 3706.373, 3706.373, 3706.373, 3706.373, 37…\n```\n\n\n:::\n:::\n\n\n\n**Note the mean_mass column that has now put the mean value in every row. Be aware of the type of output you will get out of the functions you implement!!**\n\n#### Lets look at another example\nremember our wide.data that was weight measurements of animals on a high fat diet\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwide.data <- read.csv(\"data/wide_data.csv\")\nglimpse(wide.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 10\nColumns: 11\n$ Dam             <chr> \"HFD-25-01\", \"HFD-25-02\", \"HFD-25-03\", \"HFD-25-04\", \"H…\n$ Group           <chr> \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"HFD\", \"HFD\", \"HFD\"…\n$ Baseline.Weight <dbl> 21.1, 22.4, 22.4, 22.8, 22.8, 21.8, 23.0, 23.6, 22.0, …\n$ Wk1.Weight      <dbl> 20.0, 20.9, 22.2, 22.4, 21.8, 23.8, 25.8, 22.7, 23.2, …\n$ Wk2.Weight      <dbl> 20.0, 21.2, 22.6, 23.1, 22.5, 23.6, 26.4, 21.8, 22.7, …\n$ Wk3.Weight      <dbl> 19.9, 22.2, 22.3, 22.4, 22.0, 26.2, 29.4, 24.9, 25.4, …\n$ Wk4.Weight      <dbl> 20.3, 21.7, 22.3, 24.1, 21.8, 28.1, 31.6, 22.9, 26.7, …\n$ Wk5.Weight      <dbl> 20.7, 22.4, 22.6, 25.0, 21.9, 27.8, 35.8, 23.8, 31.5, …\n$ Wk6.Weight      <dbl> 21.4, 22.7, 23.4, 23.1, 23.4, 31.6, 34.8, 25.5, 33.8, …\n$ Wk7.Weight      <dbl> 21.1, 22.0, 23.2, 24.1, 23.0, 32.0, 36.7, 28.5, 30.8, …\n$ Wk8.Weight      <dbl> 21.1, 21.0, 22.0, 23.2, 22.8, 32.8, 38.2, 25.3, 33.3, …\n```\n\n\n:::\n\n```{.r .cell-code}\n# mutate is doing the calculation of percent gain for each row so the output is a unique value in each row instead of repeating the mean of a column of data. \nwide.data |> \n  mutate(perc.gain = Wk8.Weight/Baseline.Weight*100)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Dam Group Baseline.Weight Wk1.Weight Wk2.Weight Wk3.Weight Wk4.Weight\n1  HFD-25-01   CON            21.1       20.0       20.0       19.9       20.3\n2  HFD-25-02   CON            22.4       20.9       21.2       22.2       21.7\n3  HFD-25-03   CON            22.4       22.2       22.6       22.3       22.3\n4  HFD-25-04   CON            22.8       22.4       23.1       22.4       24.1\n5  HFD-25-05   CON            22.8       21.8       22.5       22.0       21.8\n6  HFD-25-06   HFD            21.8       23.8       23.6       26.2       28.1\n7  HFD-25-07   HFD            23.0       25.8       26.4       29.4       31.6\n8  HFD-25-08   HFD            23.6       22.7       21.8       24.9       22.9\n9  HFD-25-09   HFD            22.0       23.2       22.7       25.4       26.7\n10 HFD-25-10   HFD            21.0       22.1       22.2       24.6       23.3\n   Wk5.Weight Wk6.Weight Wk7.Weight Wk8.Weight perc.gain\n1        20.7       21.4       21.1       21.1 100.00000\n2        22.4       22.7       22.0       21.0  93.75000\n3        22.6       23.4       23.2       22.0  98.21429\n4        25.0       23.1       24.1       23.2 101.75439\n5        21.9       23.4       23.0       22.8 100.00000\n6        27.8       31.6       32.0       32.8 150.45872\n7        35.8       34.8       36.7       38.2 166.08696\n8        23.8       25.5       28.5       25.3 107.20339\n9        31.5       33.8       30.8       33.3 151.36364\n10       22.7       25.3       25.4       25.9 123.33333\n```\n\n\n:::\n:::\n\n\nThis is what we wanted a unique variable for every row rather than a summary data such as mean.\n\n\n### rename()\n\nAnother cool function is `rename()`. There are many ways to rename columns in R, but `rename()` is in the convenient tidy style. In the weight data the word \"weight\" is repeated over and over and in the graph it can clutter the axis. We can rename it for brevity. For `rename()` the function takes the format new_name = old_name. Alternatively, you can use the column number too\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwide.data |> rename(baseline = Baseline.Weight,\n                    Wk1 = 4,\n                    Wk2 = 5,\n                    Wk3 = 6,\n                    Wk4 = 7,\n                    Wk5 = 8,\n                    Wk6 = 9,\n                    Wk7 = 10,\n                    Wk8 = 11)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Dam Group baseline  Wk1  Wk2  Wk3  Wk4  Wk5  Wk6  Wk7  Wk8\n1  HFD-25-01   CON     21.1 20.0 20.0 19.9 20.3 20.7 21.4 21.1 21.1\n2  HFD-25-02   CON     22.4 20.9 21.2 22.2 21.7 22.4 22.7 22.0 21.0\n3  HFD-25-03   CON     22.4 22.2 22.6 22.3 22.3 22.6 23.4 23.2 22.0\n4  HFD-25-04   CON     22.8 22.4 23.1 22.4 24.1 25.0 23.1 24.1 23.2\n5  HFD-25-05   CON     22.8 21.8 22.5 22.0 21.8 21.9 23.4 23.0 22.8\n6  HFD-25-06   HFD     21.8 23.8 23.6 26.2 28.1 27.8 31.6 32.0 32.8\n7  HFD-25-07   HFD     23.0 25.8 26.4 29.4 31.6 35.8 34.8 36.7 38.2\n8  HFD-25-08   HFD     23.6 22.7 21.8 24.9 22.9 23.8 25.5 28.5 25.3\n9  HFD-25-09   HFD     22.0 23.2 22.7 25.4 26.7 31.5 33.8 30.8 33.3\n10 HFD-25-10   HFD     21.0 22.1 22.2 24.6 23.3 22.7 25.3 25.4 25.9\n```\n\n\n:::\n:::\n\n\n\n## stringr, lubridate, forcats, purrr\n\nThese packages contain function to handle other tricky data or processes in R that we won't cover as heavily here. I wanted to just give a few notes. \n\n#### stringr\nstringr is for handing text and character strings to perform operations such as\n\n- find character strings (ie, find the work \"love\" in song lyrics)\n- subset strings of characters (ie, extract the first or last 5 characters of a string)\n- join or split charcter strings (ie, extract the year, month, and day from a date string\n\n#### lubridate\nlubridate is used to more easily handle dates and times. It can handle am/pm/24-h time notations, and change dates from yymmdd to mmddyy and more formats.\n\n#### forcats\nforcats is for working with factors and categorical data in R. Some of the functions are factoring or converting a character vector to a factor vector. Setting the levels of the factors, such as which group is the reference group. It can combine 2 sets of factors or reorder how the factors are plotted.\n\n#### purrr\npurrr is a powerful set of functions for performing for loops or iterations of operations across your data either row-wise or column-wise. This is commonly done in data science, but is a slighly more advanced topic. I encourage you to read about purrr and for loops in R. If we have time at the end of the course we can cover this topic.\n\n\n\n::: {.callout-note}\nDo you learn better by listening? Check out these videos covering some of this material.\n\n[Intro to Tidyverse](https://www.youtube.com/watch?v=MKwyauo8nSI)\n\n[Data Wrangling](https://posit.co/resources/videos/data-wrangling-with-r-and-rstudio/)\nthis video is a little older and has some different syntax on the functions, but its all the same logic given by Garrett Grolemund himself (co-author of R for Data Science book)\n:::\n",
    "supporting": [
      "index_R03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
---
title: "Predictive Modeling using tidymodels"
author: "Lindsay N. Hayes"
date: 2025-07-16
draft: false
editor_options: 
  chunk_output_type: console
---

## About the activity

1)  Access the Quarto document [here](https://github.com/lindsaynhayes/introR2025/blob/main/activities/classwork05/PCA_Penguins.qmd).

2)  Download the raw file.

3) Open it in RStudio.

We will work our way through this quarto document together during class. The activity will cover Principal Component Analysis (PCA) using tidymodels.


https://www.stepbystepdatascience.com/ml-with-tidymodels



## Load the Packages
```{r}
#| message: false
#| error: false

library(tidyverse)
library(tidymodels)
library(palmerpenguins)
library(ranger)

```

## Explore the Data
```{r}

glimpse(penguins)
penguins |> count(species)

```

## Build the model
```{r}
# set a seed
set.seed(462)

# split the data into training and testing sets

split_data <- initial_split(penguins, prop=0.7, strata = species)
data_training <- training(split_data)
data_testing <- testing(split_data)

# lets check it did the split correctly

data_training |> 
  group_by(species) |>
  summarise( count = n(),
             percent = n()/nrow(data_training) * 100)
  
data_testing |> 
  group_by(species) |>
  summarise( count = n(),
             percent = n()/nrow(data_testing) * 100)

penguin_recipe <-
  recipe( species ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data = penguins) %>%
  step_normalize(all_predictors())

penguin_recipe


data_prep <- prep(penguin_recipe, data_training)
data_prep



data_bake <- bake(data_prep, new_data = NULL)
data_bake


# MODEL 1 Random Forest
rf_model <- 
  # model type
  rand_forest() %>%
  # arguments
  set_args(mtry = 4) %>%
  # engine/package that underlies the model
  set_engine("ranger", importance = "impurity") %>%
  # mode
  set_mode("classification") 


# MODEL 2 Logistic Regression
lr_model <- 
  # specify that the model is a multinom_reg
  multinom_reg() %>%
  # select the engine/package that underlies the model
  set_engine("nnet") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification") 


rf_wflow <- 
  workflow() |>
  add_recipe(penguin_recipe) |>
  add_model(rf_model)

lr_wflow <- 
  workflow() |>
  add_recipe(penguin_recipe) |>
  add_model(lr_model)


rf_fit <- fit(rf_wflow, data_training)
lr_fit <- fit(lr_wflow, data_training)
```

## evaluate the model
```{r}

rf.predict <- predict(rf_fit, data_testing)
lr.predict <- predict(lr_fit, data_testing)




rf.outcome <- rf.predict %>%
  transmute(pred = .pred_class,
            truth = data_testing$species)

rf.outcome |> accuracy(pred, truth)

rf.outcome |> conf_mat(pred, truth)


lr.outcome <- lr.predict %>%
  transmute(pred = .pred_class,
            truth = data_testing$species)

# accuracy
lr.outcome |> accuracy(pred, truth)

# confusion matrix
lr.outcome |> conf_mat(pred, truth)

```

```{r}
sessionInfo()
```


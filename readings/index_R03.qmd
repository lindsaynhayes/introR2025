---
title: "Data Wrangling with tidyverse"
description: "Reading for Class 03"
author: 
  - name: Lindsay Hayes
    url: https://lindsaynhayes.github.io
    affiliation: Department of Cell Biology, OUHSC
date: 2025-07-08
draft: true
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
#| message: false
library(here)
```

Spreadsheets are good for data entry. As a scientists, we have a lot of data in spreadsheets. However, data exploration, manipulation, and visualization tools in spreadsheets are extremely limited and cumbersome when performed manually. Much of your time as a researcher will be spent **data wrangling** to generate the analyses you desire.

R makes this process easy and most importantly reproducible. This less will teach you how to think about data organization and some practices for effective data wrangling.

::: callout-note
### Learning objectives

**At the end of this lesson you will be able to:**

-   Generate and navigate a quarto document
-   Import Data into R
-   Recognize data format as long or wide format
-   Understand when to use both formats and how to convert between long and wide
:::

## Welcome to Quarto

In the first class, we looked at the `PalmerPenguins` data in a very tidy and curated quarto document to see how you can incorporate narrative text, code, outputs, and more in a single document. I hope you can now appreciate the utility of using Quarto to tell the story of the data analysis. The beautiful html outputs can easily be shared with others and helps build the logic of a data analysis pipeline from beginning to end.

Read the [Quarto welcome tutorial](https://quarto.org/docs/get-started/hello/rstudio.html) to learn about some of the cool tools, such as `code-folding`, `echo=false`, and more.

-   Read through Part 1: "Hello, Quarto"
-   Read through Part 2: "Computations".
-   Part 3 is more advanced for generating diverse outputs such as pdf documents feel free to explore, but we won't use this feature.

## The Tidyverse

### What is a package?

In R, the fundamental unit of shareable code is the **package.** A package bundles together *code*, *data*, *documentation*, and *tests*, and is easy to share with others. There are tens of thousands of R packages that exist. Two main repository of R packages exist. **CRAN** or the Comprehensive R Archive Network is the public clearing house for R packages and where you went to install R. **Bioconductor** is an open source project that develops and shares open source software for precise and repeatable analysis of biological data. It is this huge variety of packages that R is so successful because the chances are high that someone has already solved a problem that you’re working on.

### How to get a package?

To install packages from CRAN use the `install.packages()` function. Once the package is installed you can load the pack using the `library()` function. Installing packages from Bioconductor take a few more steps which we won't cover just yet.

<img src="figs/tidy_hex.png" width="50%" style="float:right"/>

### Tidyverse package

The [Tidyverse](https://www.tidyverse.org) which is a collection of R packages that share an underlying design, syntax, and grammer to streamline many main functions used in data science. You can install the complete tidyverse with `install.packages("tidyverse")`, once the package is installed you can load it using `library(tidyverse)`.

The packages installed in tidyverse include:

-   `ggplot2` is a graphic package to plot your data.
-   `dplyr` and `tidyr` are packages for data manipulation to subset, re-arrange, and format your dataset.
-   `readr` is a tidy way to input or read in data into R.
-   `purrr` is a functional programming toolkit to handle looping functions.
-   `tibble` is a tidy way of displaying data frames that are easier to view.
-   `stringr` is a way of handling text and character strings.
-   `forcats` is a package providing tools to handle categorical variables and discrete (non-continuous) variables.
-   `lubridate` is a package for working with times and dates.

::: callout-important
There are nice [cheatsheets](https://posit.co/resources/cheatsheets/) for each of the packages to demonstrate what they do in detail!
:::

## Tidy Syntax

The BIG picture of what we do in data science. 

<img src="figs/base.png" width="90%" style="display:block; margin-left: auto; margin-right: auto"/>
<figcaption>Figure 1: In our model of the data science process, you start with data import and tidying. Next, you understand your data with an iterative cycle of transforming, visualizing, and modeling. You finish the process by communicating your results to other humans.</figcaption>


In this next class we will focus on the **Import**, **Tidy**, and **Transform** parts of the data science pipeline. 

### Import
First we need to import data into R. I prefer to import .csv files because I think its a good way to indicate a data file and it eliminates any weird formatting that may exist in excel. I am showing 2 ways to import the data one using base R function `read.csv()` and the other using the `readr` function `read_csv`. 

In base R, the `header` field determines if the first row of the data had column header titles or not. The `stringsAsFactors` determines if the character variables in your data set should be set as a factor variable (set as TRUE) or as character (set to FALSE). The `row.names` field will allow you to specify if the first column is data or the names of the rows. 

In tidyverse, the `col_names` field specifies if the first row is a header. If you want to specify the type of data for each field you have to specify it using the `col_types` field. I specified that for you here. There are a lot more options you can look at in the *Help* section.

```{r}
#| label: setup
#| include: false
#| eval: false

library(readr)
library(taylor)

data <- taylor_all_songs
final <- data[1:314,c(1,3,4,5,12:28)]
types <- as.character(as.col_spec(final))
types <- "fDicddididdddddiilfff"
write_csv(final, file = "data/taylorswift.csv")

```

```{r}
#| label: importing.data
#| message: false

library(readr)

# BASE R
# read.csv() is for importing comma-separated files
data_base <- read.csv(file = "data/taylorswift.csv", 
                 header = TRUE, 
                 sep = ",", 
                 stringsAsFactors = TRUE)


# Tidyverse
data_tidy <- read_csv(file = "data/taylorswift.csv",
                 col_names = TRUE)

```

Using `readr` you can also import data directly from excel spreadsheets using `read_excel` or `read_xls` and even google sheets using `read_sheet`. However, we won't use these function in the course. But you are free to explore them on your own from the [readr package](https://readr.tidyverse.org).

### Export
You can also save files using the `write` functions for both csv or tsv files. 
```{r}
#| label: exporting.data
#| message: false
#| eval: false

write_csv(data, file = "data/taylorswift.csv")
```

### Tidy & Transform
The next step it to tidy and transform the data into the format that R can use to perform visualization and analysis. We will use some of the tools in `dplyr` and `tidyr`.

::: callout-important
### A note on pipes!

"Piping" is a process of directly sending the output of one funtion into the input of the next function. Piping can be performed in a long line of commands as a way of streamling the code writing to make it easier to read. We will use this a lot in this course.

`%>%` is the pipe command to connect 2 functions

`|>` is the same pipe command, but in a different syntax

The code in the course will mostly use `|>` because this is the tidyverse way of writing code, but across the internet you will also see `%>%`

:::

#### Assigning Data Types

```{r}
#| label: tidy.data
#| message: false

library(tidyr)
library(dplyr)





```





::: callout-tip
### Want More?

There are so many great tools to learn R and data science!

-   To explore the tidyverse and data science in more detail check out the *R for Data Science* [textbook](https://r4ds.hadley.nz) written by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.

-   Want more stats and data science conversations?! Check out the **not so standard deviations** [podcast](https://nssdeviations.com) by Roger Peng and Hilary Parker.
:::




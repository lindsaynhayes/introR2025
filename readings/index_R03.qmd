---
title: "Data Wrangling with tidyverse"
description: "Reading for Class 03"
author: 
  - name: Lindsay Hayes
    url: https://lindsaynhayes.github.io
    affiliation: Department of Cell Biology, OUHSC
date: 2025-07-08
draft: false
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
#| message: false
library(here)
```

::: callout-note
### Learning objectives

**At the end of this lesson you will be able to:**

-   Reconize and define an untidy dataset
-   Recognize and convert between long and wide data set formats
-   Understand when to use both formats
-   Pipe functions together to perform multiple commands in sequence
:::

## The problem with messy data
Most scientists are **not** trained to collect and organize data using `tidydata` principles. The results are data sets which are hard to follow, difficult to repeat, and challenging to report to journals. Understanding how to collect, organize, and store your data and analyses will make your life easier! Moreover, many journals request raw data submissions along with your manuscript. If you've analyzed and organized all your data in `R` using `tidydata` principles this process becomes a super simple, rather than tracking all the data across messy spreadsheets.

> "Tidy datasets are all alike, but every messy dataset is messy in its own way."\
> --- Hadley Wickham

## The principles of `tidydata`

1.  **Treat your raw data as immutable.**

*Try to manipulate the original form of the data as little as possible. The reason is to make the whole data analysis pipeline reproducible and transparent. If you start changing fields on the data spreadsheet you can't track where those values came from. Manipulating data with code also decreases the chances for errors being introduced to the raw data.*

2.  **Each variable is a column; each column is a variable.**

3.  **Each observation is a row; each row is an observation.**

4.  **Each value is a cell; each cell is a single value.**

For example, take the following data
```{r}
#| echo: false

groups <- c("Con_male", "CON_female", "Exp_m", "Exp_F")
val <- round(rnorm(4, mean = 100, sd = 25),0)
df <- as.data.frame(cbind(groups, val))
df
```

**Why might this data be a problem?** 

- combining 2 observations into one field (group and sex). 
- changing the notation styles

Here's another example
```{r}
#| echo: false

groups <- c("CON", "CON", "EXP", "EXP")
val <- round(rnorm(4, mean = 100, sd = 25),0)
val2 <- paste(val, "ug/ul", sep = "_")
df <- as.data.frame(cbind(groups, val2))
df
```

**Why might this data be a problem? **

- the data field contains 2 values the numeric value and the units

The second step after getting your data into R will be **data wrangling** in order to modify the data so that you can perform an analysis. Luckily R has a whole suite of tools to makes this process easy and most importantly reproducible. This less will teach you practices for effective data wrangling.


## The Tidyverse

<img src="figs/tidy_hex.png" width="50%" style="float:right"/>


The [Tidyverse](https://www.tidyverse.org) which is a collection of R packages that share an underlying design, syntax, and grammer to streamline many main functions used in data science. You can install the complete tidyverse with `install.packages("tidyverse")`, once the package is installed you can load it using `library(tidyverse)`.

The packages installed in tidyverse include:

-   `dplyr` and `tidyr` are packages for data manipulation to subset, re-arrange, and format your dataset.
-   `tibble` is a tidy way of displaying data frames that are easier to view.
-   `readr` is a tidy way to input or read in data into R.
-   `purrr` is a functional programming toolkit to handle looping functions.
-   `stringr` is a way of handling text and character strings.
-   `forcats` is a package providing tools to handle categorical variables and discrete (non-continuous) variables.
-   `lubridate` is a package for working with times and dates.
-   `ggplot2` is a graphic package to plot your data.

::: callout-important
There are nice [cheatsheets](https://posit.co/resources/cheatsheets/) for each of the packages to demonstrate what they do in detail!

Don't forget to check out the *Help* section too!
:::

## The BIG picture

We have now progressed to the Tidy part of the data analysis pipeline!

<img src="figs/tidy.png" width="90%" style="display:block; margin-left: auto; margin-right: auto"/>

<figcaption>Figure 1: In our model of the data science process, you start with data import and tidying. Next, you understand your data with an iterative cycle of transforming, visualizing, and modeling. You finish the process by communicating your results to other humans.</figcaption>

## Some not so tidy data

Have you seen or even generated data that looks like this?

#### example 1
::: {.img-float}
<img src="figs/untidy1.png" width="90%" style="float:center"/>
:::

#### example 2
::: {.img-float}
<img src="figs/untidy2.png" width="90%" style="float:center"/>
:::

#### example 3
::: {.img-float}
<img src="figs/untidy3.png" width="90%" style="float:center"/>
:::

## Tidy data with `tidyr`

The next step it to tidy and transform the data into a format that R can use to perform visualization and analysis.

::: callout-important
### Remember your pipes!
`%>%` & `|>` 
:::

### Wide vs Long data
```{r}
#| label: wide.long
#| message: false

library(tidyr)
library(palmerpenguins)


# pivot_longer
# pivot_wider


```
https://www.youtube.com/watch?v=MKwyauo8nSI

https://posit.co/resources/videos/data-wrangling-with-r-and-rstudio/



### unite vs separate
```{r}
#| label: unite.separate
#| message: false

library(tidyr)
library(palmerpenguins)


# unite
# separate_wider_delim
# separate_longer_delim
# unnest_longer(films)

```


### dealing with missing values
```{r}
#| label: missing
#| message: false

library(tidyr)
library(palmerpenguins)

# drop_na
# replace_na

```






## Transform data with `dplyr`
<img src="figs/tidy2.png" width="90%" style="display:block; margin-left: auto; margin-right: auto"/>

### Summarize

```{r}
#| label: transform.data
#| message: false
#| 

library(dplyr)

# summarize
# count
# group_by
# filter
# distinct same as unique
# slice
# arrange
# select
# mutate
### n()
### sum()
### mean(), median(), min(), max()
### IQR(), sd(), var(),

# rename

# bind_cols
# bind_rows






```






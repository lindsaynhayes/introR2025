[
  {
    "objectID": "readings/04-data-collection-apis/index.html",
    "href": "readings/04-data-collection-apis/index.html",
    "title": "Retrieving data from APIs with httr",
    "section": "",
    "text": "Before we begin, let’s load a few R packages\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(httr)"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#raw-vs-clean-data",
    "href": "readings/04-data-collection-apis/index.html#raw-vs-clean-data",
    "title": "Retrieving data from APIs with httr",
    "section": "“Raw” vs “Clean” data",
    "text": "“Raw” vs “Clean” data\nAs data analysts, this is what we wished data looked like whenever we start a project\n\n\n\n\n\n\n\n\n\nHowever, the reality, is data is rarely in that form in comes in all types of “raw” formats that need to be transformed into a “clean” format.\nFor example, in field of genomics, raw data looks like something like this:\n\n\n\n\n\n\n\n\n\nOr if you are interested in analyzing data from Twitter:\n\n\n\n\n\n\n\n\n\nOr data from Electronic Healthcare Records (EHRs):\n\n\n\n\n\n\n\n\n\nWe all have our scary spreadsheet tales. Here is Jenny Bryan from Posit and UBC actually asking for some of those spreadsheet tales on twitter.\n\n\n\n\n\n\n\n\n\nFor example, this is an actual spreadsheet from Enron in 2001:"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#what-do-we-mean-by-raw-data",
    "href": "readings/04-data-collection-apis/index.html#what-do-we-mean-by-raw-data",
    "title": "Retrieving data from APIs with httr",
    "section": "What do we mean by “raw” data?",
    "text": "What do we mean by “raw” data?\nFrom https://simplystatistics.org/posts/2016-07-20-relativity-raw-data/ raw data is defined as data…\n\n…if you have done no processing, manipulation, coding, or analysis of the data. In other words, the file you received from the person before you is untouched. But it may not be the rawest version of the data. The person who gave you the raw data may have done some computations. They have a different “raw data set”."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#where-do-data-live",
    "href": "readings/04-data-collection-apis/index.html#where-do-data-live",
    "title": "Retrieving data from APIs with httr",
    "section": "Where do data live?",
    "text": "Where do data live?\nData lives anywhere and everywhere. Data might be stored simply in a .csv or .txt file. Data might be stored in an Excel or Google Spreadsheet. Data might be stored in large databases that require users to write special functions to interact with to extract the data they are interested in.\nFor example, you may have heard of the terms mySQL or MongoDB.\nFrom Wikipedia, MySQL is defined as an open-source relational database management system (RDBMS). Its name is a combination of “My”, the name of co-founder Michael Widenius’s daughter,[7] and “SQL”, the abbreviation for Structured Query Language.\nFrom Wikipeda, MongoDB is defined as “a free and open-source cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schemata.”\nSo after reading that, we get the sense that there are multiple ways large databases can be structured, data can be formatted and interacted with. In addition, we see that database programs (e.g. MySQL and MongoDB) can also interact with each other.\n\n\n\n\n\n\n\n\n\nWe will learn more about JSON today and learn about SQL in a later lecture more formally."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#json-files",
    "href": "readings/04-data-collection-apis/index.html#json-files",
    "title": "Retrieving data from APIs with httr",
    "section": "JSON files",
    "text": "JSON files\nJSON (or JavaScript Object Notation) is a file format that stores information in human-readable, organized, logical, easy-to-access manner.\nFor example, here is what a JSON file looks like:\nvar stephanie = {\n    \"job-title\" : \"Associate Professor\",\n    \"hometown\" : \"Baltimore, MD\",\n    \"pronouns\": \"she/her\",\n  \"states-lived\" : {\n    \"state1\" : \"Louisiana\",\n    \"state2\" : \"Texas\",\n    \"state3\" : \"Massachusetts\",\n    \"state4\" : \"Maryland\"\n  }\n}\nSome features about JSON objects:\n\nJSON objects are surrounded by curly braces {}\nJSON objects are written in key/value pairs\nKeys must be strings, and values must be a valid JSON data type (string, number, object, array, boolean)\nKeys and values are separated by a colon\nEach key/value pair is separated by a comma"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#overview-of-apis",
    "href": "readings/04-data-collection-apis/index.html#overview-of-apis",
    "title": "Retrieving data from APIs with httr",
    "section": "Overview of APIs",
    "text": "Overview of APIs\nFrom AWS, API stands for Application Programming Interface.\n\n“Application” = any software with a distinct function\n“Interface” = a contract of service between two applications. This contract defines how the two communicate with each other using requests and responses.\n\nThe API documentation contains information on how developers are to structure those requests and responses.\n\n\n\n\n\n\nPurpose of APIs\n\n\n\nThe purpose of APIs is enable two software components to communicate with each other using a set of definitions and protocols.\nFor example, the weather bureau’s software system contains daily weather data. The weather app on your phone “talks” to this system via APIs and shows you daily weather updates on your phone.\n\n\n\nHow do APIs work?\nTo understand how APIs work, two terms that are important are\n\nclient. This is the application sending the request.\nserver. This is the application sending the response.\n\nSo in the weather example, the bureau’s weather database is the server, and the mobile app is the client.\n\n\nFour types of API architectures\nThere are four different ways that APIs can work depending on when and why they were created.\n\nSOAP APIs. These APIs use Simple Object Access Protocol. Client and server exchange messages using XML. This is a less flexible API that was more popular in the past.\nRPC APIs. These APIs are called Remote Procedure Calls. The client completes a function (or procedure) on the server, and the server sends the output back to the client.\nWebsocket APIs. Websocket API is another modern web API development that uses JSON objects to pass data. A WebSocket API supports two-way communication between client apps and the server. The server can send callback messages to connected clients, making it more efficient than REST API.\nREST APIs. REST stands for Representational State Transfer (and are the most popular and flexible APIs). The client sends requests to the server as data. The server uses this client input to start internal functions and returns output data back to the client. REST defines a set of functions like GET, PUT, DELETE, etc. that clients can use to access server data. Clients and servers exchange data using HTTP.\n\nThe main feature of REST API is statelessness (i.e. servers do not save client data between requests). Client requests to the server are similar to URLs you type in your browser to visit a website. The response from the server is plain data, without the typical graphical rendering of a web page.\n\n\nHow to use an API?\nThe basic steps to using an API are:\n\nObtaining an API key. This is done by creating a verified account with the API provider.\nSet up an HTTP API client. This tool allows you to structure API requests easily using the API keys received. Here, we will use the GET() function from the httr package.\nIf you don’t have an API client, you can try to structure the request yourself in your browser by referring to the API documentation.\nOnce you are comfortable with the new API syntax, you can start using it in your code.\n\n\n\nWhere can I find new APIs?\nNew web APIs can be found on API marketplaces and API directories, such as:\n\nRapid API – One of the largest global API markets (10k+ public APIs). Users to test APIs directly on the platform before committing to purchase.\nPublic REST APIs – Groups REST APIs into categories, making it easier to browse and find the right one to meet your needs.\nAPIForThat and APIList – Both these websites have lists of 500+ web APIs, along with in-depth information on how to use them."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#access-the-api-from-r",
    "href": "readings/04-data-collection-apis/index.html#access-the-api-from-r",
    "title": "Retrieving data from APIs with httr",
    "section": "Access the API from R",
    "text": "Access the API from R\nThere are packages for many programming languages that provide convenient access for communicating with the GitHub API, but there are no such packages (that I’m aware of) for accessing the API from R.\nThis means we can only access the API directly, e.g. by using the jsonlite package to fetch the data and convert it to an R list or data.frame.\nSpecifically, we will use the jsonlite::fromJSON() function to convert from a JSON object to a data frame.\nThe JSON file is located at https://api.github.com/users/stephaniehicks/repos\n\ngithub_url = \"https://api.github.com/users/stephaniehicks/repos\"\n\nlibrary(jsonlite)\nlibrary(tidyverse)\njsonData &lt;- as_tibble(fromJSON(github_url))\nglimpse(jsonData)\n\nRows: 30\nColumns: 79\n$ id                          &lt;int&gt; 160194123, 132884754, 647539937, 225501707…\n$ node_id                     &lt;chr&gt; \"MDEwOlJlcG9zaXRvcnkxNjAxOTQxMjM=\", \"MDEwO…\n$ name                        &lt;chr&gt; \"2018-bioinfosummer-scrnaseq\", \"advdatasci…\n$ full_name                   &lt;chr&gt; \"stephaniehicks/2018-bioinfosummer-scrnase…\n$ private                     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ owner                       &lt;df[,19]&gt; &lt;data.frame[26 x 19]&gt;\n$ html_url                    &lt;chr&gt; \"https://github.com/stephaniehicks/201…\n$ description                 &lt;chr&gt; NA, NA, \"Repo to share code for the atlas-…\n$ fork                        &lt;lgl&gt; FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FAL…\n$ url                         &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ forks_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ keys_url                    &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ collaborators_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ teams_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ hooks_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issue_events_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ events_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ assignees_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ branches_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ tags_url                    &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ blobs_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_tags_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_refs_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ trees_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ statuses_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ languages_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ stargazers_url              &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ contributors_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ subscribers_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ subscription_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ commits_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_commits_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ comments_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issue_comment_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ contents_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ compare_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ merges_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ archive_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ downloads_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issues_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ pulls_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ milestones_url              &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ notifications_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ labels_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ releases_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ deployments_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ created_at                  &lt;chr&gt; \"2018-12-03T13:20:45Z\", \"2018-05-10T10:22:…\n$ updated_at                  &lt;chr&gt; \"2019-08-08T02:18:17Z\", \"2018-05-10T10:22:…\n$ pushed_at                   &lt;chr&gt; \"2018-12-05T17:07:09Z\", \"2017-12-18T17:18:…\n$ git_url                     &lt;chr&gt; \"git://github.com/stephaniehicks/2018-bioi…\n$ ssh_url                     &lt;chr&gt; \"git@github.com:stephaniehicks/2018-bioinf…\n$ clone_url                   &lt;chr&gt; \"https://github.com/stephaniehicks/2018-bi…\n$ svn_url                     &lt;chr&gt; \"https://github.com/stephaniehicks/2018-bi…\n$ homepage                    &lt;chr&gt; NA, NA, NA, NA, NA, \"\", NA, NA, NA, NA, NA…\n$ size                        &lt;int&gt; 60296, 172353, 8866, 121, 675, 26688, 20, …\n$ stargazers_count            &lt;int&gt; 4, 0, 2, 1, 0, 0, 1, 8, 0, 1, 0, 15, 3, 0,…\n$ watchers_count              &lt;int&gt; 4, 0, 2, 1, 0, 0, 1, 8, 0, 1, 0, 15, 3, 0,…\n$ language                    &lt;chr&gt; \"TeX\", \"HTML\", \"R\", NA, NA, \"R\", \"R\", \"Jup…\n$ has_issues                  &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRU…\n$ has_projects                &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_downloads               &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_wiki                    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_pages                   &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ has_discussions             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ forks_count                 &lt;int&gt; 4, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 4, 1, 1, …\n$ mirror_url                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ archived                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ disabled                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ open_issues_count           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ license                     &lt;df[,5]&gt; &lt;data.frame[26 x 5]&gt;\n$ allow_forking               &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ is_template                 &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ web_commit_signoff_required &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ topics                      &lt;list&gt; &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;…\n$ visibility                  &lt;chr&gt; \"public\", \"public\", \"public\", \"public\", \"p…\n$ forks                       &lt;int&gt; 4, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 4, 1, 1,…\n$ open_issues                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ watchers                    &lt;int&gt; 4, 0, 2, 1, 0, 0, 1, 8, 0, 1, 0, 15, 3, 0,…\n$ default_branch              &lt;chr&gt; \"master\", \"master\", \"main\", \"master\", \"mas…\n\n\nThe function fromJSON() has now converted the JSON file into a data frame.\nHowever, from here, we see that there are only 30 rows (or 30 repositories). If you look on my github page, you can see there are more than 30 repositories.\n\nhttps://github.com/stephaniehicks?tab=repositories\n\n\n\n\n\n\n\nAPIs limit info from users\n\n\n\nWhat’s happening is called pagination.\nAt a high-level, the API is limiting the amount of items a user gets and splitting it into pages.\nFormally, pagination is the process of splitting the contents or a section of a website into discrete pages. Users tend to get lost when there’s bunch of data and with pagination splitting they can concentrate on a particular amount of content. Hierarchy and paginated structure improve the readability score of the content.\nIn this use case Github api splits the result into 30 items per resonse, depends on the request\n\n\nSolution: You should explicitly specify in your request how many items you would like to receive from server pagination engine, using formula for Github pagination api:\n?page=1&per_page=&lt;numberOfItemsYouSpecify&gt;\"\nYou can read more about pagination here:\n\nhttps://docs.github.com/en/rest/guides/using-pagination-in-the-rest-api\n\n\n\n\n\n\n\nExample\n\n\n\nHere we can visit this website:\n\nhttps://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000\n\nAnd see there are more than 30 repos. Let’s read it into R.\n\ngithub_url = \"https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000\"\n\njsonDataAll &lt;- as_tibble(fromJSON(github_url))\ndim(jsonDataAll)\n\n[1] 91 79\n\n\nWe now get all the public repositories! yay!"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#using-api-keys",
    "href": "readings/04-data-collection-apis/index.html#using-api-keys",
    "title": "Retrieving data from APIs with httr",
    "section": "Using API keys",
    "text": "Using API keys\nAuthenticating with the GitHub API via an API key allows you to send much more requests to the API.\nAPI access keys for the GitHub API are called personal access tokens (PAT) and the documentation explains how to generate a PAT once you have logged into your GitHub account.\n\n\n\n\n\n\nWhere to store API keys\n\n\n\nFirst, please be careful with your PATs and never publish them.\nIf you want guidance on where you should store them, I like this post:\n\nhttps://www.r-bloggers.com/2015/11/how-to-store-and-use-webservice-keys-and-authentication-details-with-r/\n\nPersonally, I keep mine in my .Renviron file which looks something like this on the inside:\nGITHUB_API_KEY = &lt;add my GitHub API key here&gt; \nCENSUS_API_KEY = &lt;add my tidycensus API key here&gt; \nOPENFDA_API_KEY = &lt;add my openFDA API key here&gt; \nIf you do not have an .Renviron file in your home directory, you can make one:\ncd ~\ntouch .Renviron\n\n\nAssuming you have created and stored an API key in the .Renviron file in your home directory, you can fetch it with the Sys.getenv() function.\n\ngithub_key &lt;- Sys.getenv(\"GITHUB_API_KEY\")\n\nWe will use this in a little bit."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#access-api-with-httr-and-get",
    "href": "readings/04-data-collection-apis/index.html#access-api-with-httr-and-get",
    "title": "Retrieving data from APIs with httr",
    "section": "Access API with httr and GET",
    "text": "Access API with httr and GET\nThere are a set of basic HTTP verbs that allow you access a set of endpoints.\nThe basic request patterns are:\n\nRetrieve a single item (GET)\nRetrieve a list of items (GET)\nCreate an item (POST)\nUpdate an item (PUT)\nDelete an item (DELETE)\n\nHere, we will use the GET() function from httr package (i.e. tools to work with URLs and HTTP) to retrieve a single JSON file.\nWe will also make this an authenticated HTTP response to the GitHub API using authenticate() from the httr package.\n\n\n\n\n\n\nExample\n\n\n\nLet’s start by using the GitHub API to learn information about myself (Stephanie Hicks)\n\ngithub_key &lt;- Sys.getenv(\"GITHUB_API_KEY\")\nresponse &lt;- GET('https://api.github.com/user', \n                authenticate(user = 'stephaniehicks', \n                             password = github_key))\nresponse\n\nResponse [https://api.github.com/user]\n  Date: 2024-10-26 00:50\n  Status: 401\n  Content-Type: application/json; charset=utf-8\n  Size: 109 B\n{\n  \"message\": \"Bad credentials\",\n  \"documentation_url\": \"https://docs.github.com/rest\",\n  \"status\": \"401\"\n}\n\n\nWe see the response we got is a JSON file.\n\n\nNext we extract / retrieve the contents from the raw JSON output using the content() function from the httr package. If you use the argument as = 'text', it extracts the contents as a character vector.\n\naccount_details &lt;- fromJSON(httr::content(response, as = 'text'))\naccount_details[1:30]\n\n$message\n[1] \"Bad credentials\"\n\n$documentation_url\n[1] \"https://docs.github.com/rest\"\n\n$status\n[1] \"401\"\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n$&lt;NA&gt;\nNULL\n\n\nNext, let’s perform the same request we did above about my 85 repositories, but instead of reading in the JSON file from the web, we use an authenticated GET() response:\n\nresponse &lt;- GET('https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000',\n                authenticate('stephaniehicks', github_key))\nrepo_details &lt;- as_tibble(fromJSON(httr::content(response, as = 'text')))\nrepo_details\n\n# A tibble: 1 × 3\n  message         documentation_url            status\n  &lt;chr&gt;           &lt;chr&gt;                        &lt;chr&gt; \n1 Bad credentials https://docs.github.com/rest 401"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#a-bit-of-eda-fun",
    "href": "readings/04-data-collection-apis/index.html#a-bit-of-eda-fun",
    "title": "Retrieving data from APIs with httr",
    "section": "A bit of EDA fun",
    "text": "A bit of EDA fun\nLet’s have a bit of fun and explore some questions:\n\nHow many have forks? How many forks?\n\n\ntable(repo_details$forks)\n\nWarning: Unknown or uninitialised column: `forks`.\n\n\n&lt; table of extent 0 &gt;\n\n\nWhat’s the most popular language?\n\ntable(repo_details$language)\n\nWarning: Unknown or uninitialised column: `language`.\n\n\n&lt; table of extent 0 &gt;\n\n\nTo find out how many repos that I have with open issues, we can just create a table:\n\n# how many repos have open issues? \ntable(repo_details$open_issues_count)\n\nWarning: Unknown or uninitialised column: `open_issues_count`.\n\n\n&lt; table of extent 0 &gt;\n\n\nWhew! Not as many as I thought.\n\n\n\n\n\n\nMore about GET\n\n\n\nYou can use the query argument to specify details about the response.\nLet’s look how many open issues there are in the dplyr package in the tidyverse\n\nreq &lt;- GET(\"https://api.github.com/repos/tidyverse/dplyr/issues\", \n           query = list(state = \"open\", per_page = 100, page = 1))\ndplyr_details &lt;- as_tibble(fromJSON(httr::content(req, as = 'text')))\ndplyr_details\n\n# A tibble: 83 × 31\n   url         repository_url labels_url comments_url events_url html_url     id\n   &lt;chr&gt;       &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt;\n 1 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.56e9\n 2 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.56e9\n 3 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.53e9\n 4 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.53e9\n 5 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.51e9\n 6 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.51e9\n 7 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.49e9\n 8 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.49e9\n 9 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.44e9\n10 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.43e9\n# ℹ 73 more rows\n# ℹ 24 more variables: node_id &lt;chr&gt;, number &lt;int&gt;, title &lt;chr&gt;,\n#   user &lt;df[,19]&gt;, labels &lt;list&gt;, state &lt;chr&gt;, locked &lt;lgl&gt;,\n#   assignee &lt;df[,19]&gt;, assignees &lt;list&gt;, milestone &lt;lgl&gt;, comments &lt;int&gt;,\n#   created_at &lt;chr&gt;, updated_at &lt;chr&gt;, closed_at &lt;lgl&gt;,\n#   author_association &lt;chr&gt;, active_lock_reason &lt;chr&gt;, draft &lt;lgl&gt;,\n#   pull_request &lt;df[,5]&gt;, body &lt;chr&gt;, closed_by &lt;lgl&gt;, reactions &lt;df[,10]&gt;, …"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#other-examples-with-github-api",
    "href": "readings/04-data-collection-apis/index.html#other-examples-with-github-api",
    "title": "Retrieving data from APIs with httr",
    "section": "Other examples with GitHub API",
    "text": "Other examples with GitHub API\nFinally, I will leave you with a few other examples of using GitHub API:\n\nHow long does it take to close a GitHub Issue in the dplyr package?\nHow to retrieve all commits for a branch\nGetting my GitHub Activity"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#register-for-an-api-key",
    "href": "readings/04-data-collection-apis/index.html#register-for-an-api-key",
    "title": "Retrieving data from APIs with httr",
    "section": "Register for an API Key",
    "text": "Register for an API Key\nFirst, you need to register for an API key here\n\nhttps://open.fda.gov/apis/authentication/\n\nYou should also store the API key in your .Renviron like above for the GitHub API key."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#building-the-url-for-get",
    "href": "readings/04-data-collection-apis/index.html#building-the-url-for-get",
    "title": "Retrieving data from APIs with httr",
    "section": "Building the URL for GET",
    "text": "Building the URL for GET\nFirst, we will request a summarized set of counts around food recalls either voluntary by a firm or mandated by the FDA.\nThe URL we want is the following\nhttps://api.fda.gov/food/enforcement.json?api_key=&lt;your_API_key_here&gt;&count=voluntary_mandated.exact\nLet’s build up the URL.\n\nThe first is the base URL: https://api.fda.gov/food/enforcement.json. This part of the URL will be the same for all our calls to the food enforcement API (but is different if you want to investigate e.g. patient responses from drugs).\nNext, ?apiKey=&lt;your_API_key_here&gt; is how I use my authorization token, which tells the openFDA servers that I am allowed to ask for this data.\nFinally, we want to return a set of summarized counts for a specific field (&count=voluntary_mandated.exact)\n\nNow that we have dissected the anatomy of an API, you can see how easy it is to build them!\nBasically anybody with an internet connection, an authorization token, and who knows the grammar of the API can access it. Most APIs are published with extensive documentation to help you understand the available options and parameters."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#calling-an-api-with-get",
    "href": "readings/04-data-collection-apis/index.html#calling-an-api-with-get",
    "title": "Retrieving data from APIs with httr",
    "section": "Calling an API with GET",
    "text": "Calling an API with GET\nLet’s join the URL together:\n\n## extract my API from `.Renviron`\nopenFDA_key &lt;- Sys.getenv(\"OPENFDA_API_KEY\")\n\n## build the URL\nbase &lt;- 'https://api.fda.gov/food/enforcement.json?api_key='\nquery &lt;- '&count=voluntary_mandated.exact'\n\n## put it all together\nAPI_URL &lt;- paste0(base, openFDA_key, query)\n\nNow we have the entire URL stored in a simple R object called API_URL.\nWe can now use the URL to call the API, and we will store the returned data in an object called raw_data:\n\nraw_data &lt;- GET(API_URL)\nraw_data\n\nResponse [https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact]\n  Date: 2024-10-26 00:50\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 687 B\n{\n  \"meta\": {\n    \"disclaimer\": \"Do not rely on openFDA to make decisions regarding medical...\n    \"terms\": \"https://open.fda.gov/terms/\",\n    \"license\": \"https://open.fda.gov/license/\",\n    \"last_updated\": \"2024-10-16\"\n  },\n  \"results\": [\n    {\n      \"term\": \"Voluntary: Firm initiated\",\n...\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nWe can see status element of the list. Traditionally, a status of “200” means that the API call was successful, and other codes are used to indicate errors. You can troubleshoot those error codes using the API documentation.\n\n\nNext, we can inspect the object and we see that it is a list.\n\nstr(raw_data)\n\nList of 10\n $ url        : chr \"https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact\"\n $ status_code: int 200\n $ headers    :List of 22\n  ..$ date                            : chr \"Sat, 26 Oct 2024 00:50:53 GMT\"\n  ..$ content-type                    : chr \"application/json; charset=utf-8\"\n  ..$ vary                            : chr \"Accept-Encoding\"\n  ..$ access-control-allow-credentials: chr \"true\"\n  ..$ access-control-allow-origin     : chr \"*\"\n  ..$ age                             : chr \"0\"\n  ..$ cache-control                   : chr \"no-cache, no-store, must-revalidate\"\n  ..$ content-security-policy         : chr \"default-src 'none'\"\n  ..$ etag                            : chr \"W/\\\"2af-aJ2B+UTvZEOibSzVowCdOsJz+QQ\\\"\"\n  ..$ strict-transport-security       : chr \"max-age=31536000;\"\n  ..$ strict-transport-security       : chr \"max-age=31536000; preload\"\n  ..$ vary                            : chr \"Accept-Encoding\"\n  ..$ via                             : chr \"https/1.1 api-umbrella (ApacheTrafficServer [cMsSf ])\"\n  ..$ x-api-umbrella-request-id       : chr \"ciop7000t1q26nifnfug\"\n  ..$ x-cache                         : chr \"MISS\"\n  ..$ x-content-type-options          : chr \"nosniff\"\n  ..$ x-ratelimit-limit               : chr \"240\"\n  ..$ x-ratelimit-remaining           : chr \"239\"\n  ..$ x-vcap-request-id               : chr \"0db6cfda-8692-4b13-7ab4-611c91c93851\"\n  ..$ x-xss-protection                : chr \"1; mode=block\"\n  ..$ x-frame-options                 : chr \"deny\"\n  ..$ content-encoding                : chr \"gzip\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ all_headers:List of 1\n  ..$ :List of 3\n  .. ..$ status : int 200\n  .. ..$ version: chr \"HTTP/2\"\n  .. ..$ headers:List of 22\n  .. .. ..$ date                            : chr \"Sat, 26 Oct 2024 00:50:53 GMT\"\n  .. .. ..$ content-type                    : chr \"application/json; charset=utf-8\"\n  .. .. ..$ vary                            : chr \"Accept-Encoding\"\n  .. .. ..$ access-control-allow-credentials: chr \"true\"\n  .. .. ..$ access-control-allow-origin     : chr \"*\"\n  .. .. ..$ age                             : chr \"0\"\n  .. .. ..$ cache-control                   : chr \"no-cache, no-store, must-revalidate\"\n  .. .. ..$ content-security-policy         : chr \"default-src 'none'\"\n  .. .. ..$ etag                            : chr \"W/\\\"2af-aJ2B+UTvZEOibSzVowCdOsJz+QQ\\\"\"\n  .. .. ..$ strict-transport-security       : chr \"max-age=31536000;\"\n  .. .. ..$ strict-transport-security       : chr \"max-age=31536000; preload\"\n  .. .. ..$ vary                            : chr \"Accept-Encoding\"\n  .. .. ..$ via                             : chr \"https/1.1 api-umbrella (ApacheTrafficServer [cMsSf ])\"\n  .. .. ..$ x-api-umbrella-request-id       : chr \"ciop7000t1q26nifnfug\"\n  .. .. ..$ x-cache                         : chr \"MISS\"\n  .. .. ..$ x-content-type-options          : chr \"nosniff\"\n  .. .. ..$ x-ratelimit-limit               : chr \"240\"\n  .. .. ..$ x-ratelimit-remaining           : chr \"239\"\n  .. .. ..$ x-vcap-request-id               : chr \"0db6cfda-8692-4b13-7ab4-611c91c93851\"\n  .. .. ..$ x-xss-protection                : chr \"1; mode=block\"\n  .. .. ..$ x-frame-options                 : chr \"deny\"\n  .. .. ..$ content-encoding                : chr \"gzip\"\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ cookies    :'data.frame':    0 obs. of  7 variables:\n  ..$ domain    : logi(0) \n  ..$ flag      : logi(0) \n  ..$ path      : logi(0) \n  ..$ secure    : logi(0) \n  ..$ expiration: 'POSIXct' num(0) \n  ..$ name      : logi(0) \n  ..$ value     : logi(0) \n $ content    : raw [1:687] 7b 0a 20 20 ...\n $ date       : POSIXct[1:1], format: \"2024-10-26 00:50:53\"\n $ times      : Named num [1:6] 0 0.0391 0.1145 0.2709 0.4375 ...\n  ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n $ request    :List of 7\n  ..$ method    : chr \"GET\"\n  ..$ url       : chr \"https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact\"\n  ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. ..- attr(*, \"names\")= chr \"Accept\"\n  ..$ fields    : NULL\n  ..$ options   :List of 2\n  .. ..$ useragent: chr \"libcurl/8.7.1 r-curl/5.2.3 httr/1.4.7\"\n  .. ..$ httpget  : logi TRUE\n  ..$ auth_token: NULL\n  ..$ output    : list()\n  .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  ..- attr(*, \"class\")= chr \"request\"\n $ handle     :Class 'curl_handle' &lt;externalptr&gt; \n - attr(*, \"class\")= chr \"response\"\n\n\nOne of the elements is content and we can inspect that\n\nstr(raw_data$content)\n\n raw [1:687] 7b 0a 20 20 ...\n\n\nWe see the actual data have been stored as raw vectors (or raw bytes), which need to be converted to character vectors. This is not in a useable format yet."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#converting-json-to-a-data.frame",
    "href": "readings/04-data-collection-apis/index.html#converting-json-to-a-data.frame",
    "title": "Retrieving data from APIs with httr",
    "section": "Converting JSON to a data.frame",
    "text": "Converting JSON to a data.frame\nThere is a function in base R rawTo_Char() that converts raw bytes to characters\n\nopenFDA_data &lt;- fromJSON(rawToChar(raw_data$content), flatten = TRUE)\n\nThis converts the raw data into a list.\n\n\n\n\n\n\nNote\n\n\n\nWe can also do this with httr::content (as above) and just define the encoding for the character set.\n\nopenFDA_data &lt;- fromJSON(httr::content(raw_data, \n                                       as = 'text', \n                                       encoding =  \"UTF-8\"))\nstr(openFDA_data)\n\nList of 2\n $ meta   :List of 4\n  ..$ disclaimer  : chr \"Do not rely on openFDA to make decisions regarding medical care. While we make every effort to ensure that data\"| __truncated__\n  ..$ terms       : chr \"https://open.fda.gov/terms/\"\n  ..$ license     : chr \"https://open.fda.gov/license/\"\n  ..$ last_updated: chr \"2024-10-16\"\n $ results:'data.frame':    4 obs. of  2 variables:\n  ..$ term : chr [1:4] \"Voluntary: Firm initiated\" \"FDA Mandated\" \"N/A\" \"\"\n  ..$ count: int [1:4] 26139 396 6 2\n\n\n\n\nNow that it is in a list format, you can see that it actually contains several data frames!\nYou can use this data right away if you are already familiar with lists in R, or you can extract the data frames into separate objects, like this:\n\nts_df &lt;- openFDA_data$results\nts_df\n\n                       term count\n1 Voluntary: Firm initiated 26139\n2              FDA Mandated   396\n3                       N/A     6\n4                               2\n\n\nWe could wrangle and visualize the data from here."
  },
  {
    "objectID": "readings/03-functional-programming/index.html",
    "href": "readings/03-functional-programming/index.html",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "If you have ever heard the phrase\n\n“R is a functional language.”\n\nyou might have asked yourself what does this means exactly? Generally, this means that R lends itself nice to a particular style of programming, namely a functional style of programming (will explain more below), which is often very helpful to the types of problems you encounter when doing a data analysis.\n\n\nA functional style of programming is contrast to a the formal definition of a functional language (or functional programming, which can be complementary to object-oriented programming), which are languages that use functions to create conditional expressions to perform specific computations.\n\n\n\n\n\n\nDifferences between functional and object-oriented programming\n\n\n\nFrom this resource some differences are:\n\nBasic elements: The fundamental elements of object-oriented languages are objects and methods, while the elements of functional programming are functions and variables.\nStates: Object-oriented languages can change objects within the program, which means it has states or current modifications that affect the result of inputs. Functional languages do not use imperative programming, so they do not keep track of current states.\nParallel programming: This type of programming involves multiple computational processes occurring at the same time. Object-oriented languages have little support for parallel programming, but functional languages have extensive support for it.\nOrder: In object-oriented programming, computations occur in a specific order. In functional programming, computations can occur in any order.\nIterative data: Object-oriented programming uses loops, meaning repeated execution, for iterative data. Functional programming uses recursion for iterative data, meaning it attempts to solve problems using simpler versions of the same problem.\n\n\n\nA traditional weakness of functional languages are poorer performance and sometimes unpredictable memory usage, but these have been much reduced in recent years.\n\n\n\nThere are many definitions for precisely what makes a language functional, but there are two common threads and/or characteristics.\n\n\nAt it is core, functional programming treats functions equally as other data structures, called first class functions.\n\nIn R, this means that you can do many of the things with a function that you can do with a vector: you can assign them to variables, store them in lists, pass them as arguments to other functions, create them inside functions, and even return them as the result of a function.\n\n\n\n\n\n\n\nExamples of cool things you can do with functions in R\n\n\n\n\nAssign a function to a variable (foo):\n\n\nfoo &lt;- function(){\n  return(\"This is foo.\")\n}\nclass(foo)\n\n[1] \"function\"\n\nfoo\n\nfunction () \n{\n    return(\"This is foo.\")\n}\n\nfoo()\n\n[1] \"This is foo.\"\n\n\n\nYou can store functions in a list:\n\n\nfoo_list &lt;- list( \n  fun_1 = function() return(\"foo_1\"),\n  fun_2 = function() return(\"foo_2\")\n)\n\nstr(foo_list)\n\nList of 2\n $ fun_1:function ()  \n $ fun_2:function ()  \n\nfoo_list$fun_1()\n\n[1] \"foo_1\"\n\nfoo_list$fun_2()\n\n[1] \"foo_2\"\n\n\n\nYou can pass functions as arguments to other functions:\n\n\nshell_fn &lt;- function(f) f()\nshell_fn(foo_list$fun_1)\n\n[1] \"foo_1\"\n\nshell_fn(foo_list$fun_2)\n\n[1] \"foo_2\"\n\n\n\nYou can create functions inside of functions and return them as the result of a function\n\n\nfoo_wrap &lt;- function(){\n  foo_2 &lt;- function(){\n    return(\"This is foo_2.\")\n  }\n  return(foo_2)\n}\n\nfoo_wrap()\n\nfunction () \n{\n    return(\"This is foo_2.\")\n}\n&lt;environment: 0x12824dbf8&gt;\n\n(foo_wrap())()\n\n[1] \"This is foo_2.\"\n\n\nThe bottom line, you can manipulate functions as the same way as you can to a vector or a matrix.\n\n\n\n\n\nA function is pure, if it satisfies two properties:\n\nThe output only depends on the inputs, i.e. if you call it again with the same inputs, you get the same outputs. This excludes functions like runif(), read.csv(), or Sys.time() that can return different values.\nThe function has no side-effects, like changing the value of a global variable, writing to disk, or displaying to the screen. This excludes functions like print(), write.csv() and &lt;-.\n\nPure functions are much easier to reason about, but obviously have significant downsides: imagine doing a data analysis where you could not generate random numbers or read files from disk.\n\n\n\n\n\n\nImportant\n\n\n\nTo be clear, R is not formally a functional programming language as it does not require pure functions to be used when writing code.\n\n\nSo you might be asking yourself, why are we talking about this then?\nThe formal definition of a functional programming language introduces a new style of programming, namely a functional style of programming.\n\n\n\n\n\n\nNote\n\n\n\nThe key idea of a functional style is this programming style encourages programmers to write a big function as many smaller isolated functions, where each function addresses one specific task.\n\n\nYou can always adopt a functional style for certain parts of your code! For example, this style of writing code motivates more humanly readable code, and recyclable code.\n\n\"data_set.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()\n\n\"data_set2.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_different_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()\n\n\n\n\n\nAt a high-level, a functional style is the concept of decomposing a big problem into smaller components, then solving each piece with a function or combination of functions.\n\nWhen using a functional style, you strive to decompose components of the problem into isolated functions that operate independently.\nEach function taken by itself is simple and straightforward to understand; complexity is handled by composing functions in various ways.\n\n\n\nIn this lecture, we will focus on one type of functional technique, namely functionals, which are functions that take another function as an argument and returns a vector as output.\nFunctionals allow you to take a function that solves the problem for a single input and generalize it to handle any number of inputs. Once you learn about them, you will find yourself using them all the time in data analysis.\n\n\n\n\n\n\nExample of a functional\n\n\n\nHere’s a simple functional: it calls the function provided as input with 1000 random uniform numbers.\n\nrandomise &lt;- function(f) f(runif(1e3))\nrandomise(mean)\n\n[1] 0.5021298\n\nrandomise(mean)\n\n[1] 0.5110258\n\nrandomise(sum)\n\n[1] 518.8307\n\n\n\n\nThe chances are that you have already used a functional. You might have used for-loop replacements like base R’s lapply(), apply(), and tapply() or maybe you have used a mathematical functional like integrate() or optim().\nOne of the most common use of functionals is an alternative to for loops.\nFor loops have a bad rap in R because many people believe they are slow, but the real downside of for loops is that they’re very flexible: a loop conveys that you’re iterating, but not what should be done with the results.\n\n\nTypically it is not the for loop itself that is slow, but what you are doing inside of it. A common culprit of slow loops is modifying a data structure, where each modification generates a copy.\nIf you’re an experienced for loop user, switching to functionals is typically a pattern matching exercise. You look at the for loop and find a functional that matches the basic form. If one does not exist, do not try and torture an existing functional to fit the form you need. Instead, just leave it as a for loop! (Or once you have repeated the same loop two or more times, maybe think about writing your own functional).\nJust as it is better to use while than repeat, and it’s better to use for than while, it is better to use a functional than for.\nEach functional is tailored for a specific task, so when you recognize the functional you immediately know why it’s being used."
  },
  {
    "objectID": "readings/03-functional-programming/index.html#functional-programming-language",
    "href": "readings/03-functional-programming/index.html#functional-programming-language",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "A functional style of programming is contrast to a the formal definition of a functional language (or functional programming, which can be complementary to object-oriented programming), which are languages that use functions to create conditional expressions to perform specific computations.\n\n\n\n\n\n\nDifferences between functional and object-oriented programming\n\n\n\nFrom this resource some differences are:\n\nBasic elements: The fundamental elements of object-oriented languages are objects and methods, while the elements of functional programming are functions and variables.\nStates: Object-oriented languages can change objects within the program, which means it has states or current modifications that affect the result of inputs. Functional languages do not use imperative programming, so they do not keep track of current states.\nParallel programming: This type of programming involves multiple computational processes occurring at the same time. Object-oriented languages have little support for parallel programming, but functional languages have extensive support for it.\nOrder: In object-oriented programming, computations occur in a specific order. In functional programming, computations can occur in any order.\nIterative data: Object-oriented programming uses loops, meaning repeated execution, for iterative data. Functional programming uses recursion for iterative data, meaning it attempts to solve problems using simpler versions of the same problem.\n\n\n\nA traditional weakness of functional languages are poorer performance and sometimes unpredictable memory usage, but these have been much reduced in recent years."
  },
  {
    "objectID": "readings/03-functional-programming/index.html#characteristics-of-a-functional-language",
    "href": "readings/03-functional-programming/index.html#characteristics-of-a-functional-language",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "There are many definitions for precisely what makes a language functional, but there are two common threads and/or characteristics.\n\n\nAt it is core, functional programming treats functions equally as other data structures, called first class functions.\n\nIn R, this means that you can do many of the things with a function that you can do with a vector: you can assign them to variables, store them in lists, pass them as arguments to other functions, create them inside functions, and even return them as the result of a function.\n\n\n\n\n\n\n\nExamples of cool things you can do with functions in R\n\n\n\n\nAssign a function to a variable (foo):\n\n\nfoo &lt;- function(){\n  return(\"This is foo.\")\n}\nclass(foo)\n\n[1] \"function\"\n\nfoo\n\nfunction () \n{\n    return(\"This is foo.\")\n}\n\nfoo()\n\n[1] \"This is foo.\"\n\n\n\nYou can store functions in a list:\n\n\nfoo_list &lt;- list( \n  fun_1 = function() return(\"foo_1\"),\n  fun_2 = function() return(\"foo_2\")\n)\n\nstr(foo_list)\n\nList of 2\n $ fun_1:function ()  \n $ fun_2:function ()  \n\nfoo_list$fun_1()\n\n[1] \"foo_1\"\n\nfoo_list$fun_2()\n\n[1] \"foo_2\"\n\n\n\nYou can pass functions as arguments to other functions:\n\n\nshell_fn &lt;- function(f) f()\nshell_fn(foo_list$fun_1)\n\n[1] \"foo_1\"\n\nshell_fn(foo_list$fun_2)\n\n[1] \"foo_2\"\n\n\n\nYou can create functions inside of functions and return them as the result of a function\n\n\nfoo_wrap &lt;- function(){\n  foo_2 &lt;- function(){\n    return(\"This is foo_2.\")\n  }\n  return(foo_2)\n}\n\nfoo_wrap()\n\nfunction () \n{\n    return(\"This is foo_2.\")\n}\n&lt;environment: 0x12824dbf8&gt;\n\n(foo_wrap())()\n\n[1] \"This is foo_2.\"\n\n\nThe bottom line, you can manipulate functions as the same way as you can to a vector or a matrix.\n\n\n\n\n\nA function is pure, if it satisfies two properties:\n\nThe output only depends on the inputs, i.e. if you call it again with the same inputs, you get the same outputs. This excludes functions like runif(), read.csv(), or Sys.time() that can return different values.\nThe function has no side-effects, like changing the value of a global variable, writing to disk, or displaying to the screen. This excludes functions like print(), write.csv() and &lt;-.\n\nPure functions are much easier to reason about, but obviously have significant downsides: imagine doing a data analysis where you could not generate random numbers or read files from disk.\n\n\n\n\n\n\nImportant\n\n\n\nTo be clear, R is not formally a functional programming language as it does not require pure functions to be used when writing code.\n\n\nSo you might be asking yourself, why are we talking about this then?\nThe formal definition of a functional programming language introduces a new style of programming, namely a functional style of programming.\n\n\n\n\n\n\nNote\n\n\n\nThe key idea of a functional style is this programming style encourages programmers to write a big function as many smaller isolated functions, where each function addresses one specific task.\n\n\nYou can always adopt a functional style for certain parts of your code! For example, this style of writing code motivates more humanly readable code, and recyclable code.\n\n\"data_set.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()\n\n\"data_set2.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_different_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()"
  },
  {
    "objectID": "readings/03-functional-programming/index.html#functional-style",
    "href": "readings/03-functional-programming/index.html#functional-style",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "At a high-level, a functional style is the concept of decomposing a big problem into smaller components, then solving each piece with a function or combination of functions.\n\nWhen using a functional style, you strive to decompose components of the problem into isolated functions that operate independently.\nEach function taken by itself is simple and straightforward to understand; complexity is handled by composing functions in various ways.\n\n\n\nIn this lecture, we will focus on one type of functional technique, namely functionals, which are functions that take another function as an argument and returns a vector as output.\nFunctionals allow you to take a function that solves the problem for a single input and generalize it to handle any number of inputs. Once you learn about them, you will find yourself using them all the time in data analysis.\n\n\n\n\n\n\nExample of a functional\n\n\n\nHere’s a simple functional: it calls the function provided as input with 1000 random uniform numbers.\n\nrandomise &lt;- function(f) f(runif(1e3))\nrandomise(mean)\n\n[1] 0.5021298\n\nrandomise(mean)\n\n[1] 0.5110258\n\nrandomise(sum)\n\n[1] 518.8307\n\n\n\n\nThe chances are that you have already used a functional. You might have used for-loop replacements like base R’s lapply(), apply(), and tapply() or maybe you have used a mathematical functional like integrate() or optim().\nOne of the most common use of functionals is an alternative to for loops.\nFor loops have a bad rap in R because many people believe they are slow, but the real downside of for loops is that they’re very flexible: a loop conveys that you’re iterating, but not what should be done with the results.\n\n\nTypically it is not the for loop itself that is slow, but what you are doing inside of it. A common culprit of slow loops is modifying a data structure, where each modification generates a copy.\nIf you’re an experienced for loop user, switching to functionals is typically a pattern matching exercise. You look at the for loop and find a functional that matches the basic form. If one does not exist, do not try and torture an existing functional to fit the form you need. Instead, just leave it as a for loop! (Or once you have repeated the same loop two or more times, maybe think about writing your own functional).\nJust as it is better to use while than repeat, and it’s better to use for than while, it is better to use a functional than for.\nEach functional is tailored for a specific task, so when you recognize the functional you immediately know why it’s being used."
  },
  {
    "objectID": "readings/03-functional-programming/index.html#the-map-family",
    "href": "readings/03-functional-programming/index.html#the-map-family",
    "title": "Functional Programming with purrr",
    "section": "The map family",
    "text": "The map family\nThe most fundamental functional in the purrr package is the map(.x, .f) function. It takes a vector (.x) and a function (.f), calls the function once for each element of the vector, and returns the results in a list. In other words, map(1:3, f) is equivalent to list(f(1), f(2), f(3)).\n\nlibrary(purrr)\n\n# we create a function called \"triple\"\ntriple &lt;- function(x) x * 3\n\n# using for loop to iterate over a vector\nloop_ret &lt;- list()\nfor(i in 1:3){\n  loop_ret[i] &lt;- triple(i)\n}\nloop_ret\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 6\n\n[[3]]\n[1] 9\n\n\n\n# map implementation to iterate over a vector\nmap_eg1 &lt;- map(.x = 1:3, .f = triple)\nmap_eg2 &lt;- map(.x = 1:3, .f = function(x) triple(x)) # create an inline anonymous function\nmap_eg3 &lt;- map(.x = 1:3, .f = ~triple(.x)) # same as above, but special purrr syntax with a \"twiddle\"\n\n\nidentical(loop_ret,map_eg1)\n\n[1] TRUE\n\nidentical(loop_ret,map_eg2)\n\n[1] TRUE\n\nidentical(loop_ret,map_eg3)\n\n[1] TRUE\n\n\nOr, graphically this is what map() is doing:\n\n\n\nmap\n\n\n\n\n\n\n\n\nHow does map relate to functional programming in base R?\n\n\n\nmap() returns a list, which makes it the most general of the map family because you can put anything in a list.\nThe base equivalent to map(.x, .f) is lapply(X, FUN).\nBecause the arguments include functions (.f) besides data (.x), map() functions are considered as a convenient interface to implement functional programming.\n\n\n\nmap variants\nSometimes it is inconvenient to return a list when a simpler data structure would do, so there are four more specific variants of map that make it really a family of functions (of syntax map_*()).\n\nmap_lgl()\nmap_int()\nmap_dbl()\nmap_chr()\n\nFor example, purrr uses the convention that suffixes, like _dbl(), refer to the output. Each returns an atomic vector of the specified type:\n\n# map_chr() always returns a character vector\nmap_chr(.x = mtcars, .f = typeof)\n\n     mpg      cyl     disp       hp     drat       wt     qsec       vs \n\"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \n      am     gear     carb \n\"double\" \"double\" \"double\" \n\n# map_lgl() always returns a logical vector\nmap_lgl(.x = mtcars, .f = is.double)\n\n mpg  cyl disp   hp drat   wt qsec   vs   am gear carb \nTRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE \n\n# map_int() always returns a integer vector\nn_unique &lt;- function(x) length(unique(x))\nmap_int(.x = mtcars, .f = n_unique)\n\n mpg  cyl disp   hp drat   wt qsec   vs   am gear carb \n  25    3   27   22   22   29   30    2    2    3    6 \n\n# map_dbl() always returns a double vector\nmap_dbl(.x = mtcars, .f = mean)\n\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nAll map_*() functions can take any type of vector as input. The examples above rely on two facts:\n\nmtcars is a data.frame. In R, data.frame is a special case of list, where each column as one item of the list. Don’t confuse with each row as an item.\n\n\nclass(mtcars)\n\n[1] \"data.frame\"\n\ntypeof(mtcars)\n\n[1] \"list\"\n\n\n\nAll map functions always return an output vector the same length as the input, which implies that each call to .f must return a single value. If it does not, you will get an error:\n\n\npair &lt;- function(x) c(x, x)\nmap_dbl(.x = 1:2, .f = pair)\n\nError in `map_dbl()`:\nℹ In index: 1.\nCaused by error:\n! Result must be length 1, not 2.\n\n\nThis is similar to the error you will get if .f returns the wrong type of result:\n\nmap_dbl(1:2, as.character)\n\nError in `map_dbl()`:\nℹ In index: 1.\nCaused by error:\n! Can't coerce from a string to a double.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s assume I have a dataframe called tmp_dat. How would I use map() to calculate the mean for the columns?\n\ntmp_dat &lt;- data.frame(\n  x = 1:5,\n  y = 6:10\n)\n\n\n## try it out \n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nCan we re-write the map() function above to use tmp_data as input with the |&gt; operator?\n\n## try it out \n\n\n\n\n\nPassing arguments with ...\nIt is often convenient to pass along additional arguments to the function that you are calling.\nFor example, you might want to pass na.rm = TRUE along to mean(). One way to do that is with an anonymous function:\n\nx &lt;- list(1:5, c(1:10, NA))\nmap_dbl(x, ~ mean(.x, na.rm = TRUE))\n\n[1] 3.0 5.5\n\n\nBut because the map functions pass ... along, there is a simpler form available:\n\nmap_dbl(x, mean, na.rm = TRUE)\n\n[1] 3.0 5.5\n\n\nThis is easiest to understand with a picture: any arguments that come after f in the call to map() are inserted after the data in individual calls to f():\n\n\n\nmap\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s important to note that these arguments are not decomposed; or said another way, map() is only vectorised over its first argument.\nIf an argument after f is a vector, it will be passed along as is:\n\n\n\nmap\n\n\n\n\n\n\nStratified analysis with map\nBefore we go on to explore more map variants, let’s take a quick look at how you tend to use multiple purrr functions to solve a moderately realistic problem: fitting a model to each subgroup and extracting a coefficient of the model.\nFor this toy example, I will break the mtcars data set down into groups defined by the number of cylinders, using the base split function:\n\n# different numbers of cylinders\nunique(mtcars$cyl) \n\n[1] 6 4 8\n\n\n\nby_cyl &lt;- split(mtcars, mtcars$cyl)\nlength(by_cyl)\n\n[1] 3\n\nstr(by_cyl)\n\nList of 3\n $ 4:'data.frame':  11 obs. of  11 variables:\n  ..$ mpg : num [1:11] 22.8 24.4 22.8 32.4 30.4 33.9 21.5 27.3 26 30.4 ...\n  ..$ cyl : num [1:11] 4 4 4 4 4 4 4 4 4 4 ...\n  ..$ disp: num [1:11] 108 146.7 140.8 78.7 75.7 ...\n  ..$ hp  : num [1:11] 93 62 95 66 52 65 97 66 91 113 ...\n  ..$ drat: num [1:11] 3.85 3.69 3.92 4.08 4.93 4.22 3.7 4.08 4.43 3.77 ...\n  ..$ wt  : num [1:11] 2.32 3.19 3.15 2.2 1.61 ...\n  ..$ qsec: num [1:11] 18.6 20 22.9 19.5 18.5 ...\n  ..$ vs  : num [1:11] 1 1 1 1 1 1 1 1 0 1 ...\n  ..$ am  : num [1:11] 1 0 0 1 1 1 0 1 1 1 ...\n  ..$ gear: num [1:11] 4 4 4 4 4 4 3 4 5 5 ...\n  ..$ carb: num [1:11] 1 2 2 1 2 1 1 1 2 2 ...\n $ 6:'data.frame':  7 obs. of  11 variables:\n  ..$ mpg : num [1:7] 21 21 21.4 18.1 19.2 17.8 19.7\n  ..$ cyl : num [1:7] 6 6 6 6 6 6 6\n  ..$ disp: num [1:7] 160 160 258 225 168 ...\n  ..$ hp  : num [1:7] 110 110 110 105 123 123 175\n  ..$ drat: num [1:7] 3.9 3.9 3.08 2.76 3.92 3.92 3.62\n  ..$ wt  : num [1:7] 2.62 2.88 3.21 3.46 3.44 ...\n  ..$ qsec: num [1:7] 16.5 17 19.4 20.2 18.3 ...\n  ..$ vs  : num [1:7] 0 0 1 1 1 1 0\n  ..$ am  : num [1:7] 1 1 0 0 0 0 1\n  ..$ gear: num [1:7] 4 4 3 3 4 4 5\n  ..$ carb: num [1:7] 4 4 1 1 4 4 6\n $ 8:'data.frame':  14 obs. of  11 variables:\n  ..$ mpg : num [1:14] 18.7 14.3 16.4 17.3 15.2 10.4 10.4 14.7 15.5 15.2 ...\n  ..$ cyl : num [1:14] 8 8 8 8 8 8 8 8 8 8 ...\n  ..$ disp: num [1:14] 360 360 276 276 276 ...\n  ..$ hp  : num [1:14] 175 245 180 180 180 205 215 230 150 150 ...\n  ..$ drat: num [1:14] 3.15 3.21 3.07 3.07 3.07 2.93 3 3.23 2.76 3.15 ...\n  ..$ wt  : num [1:14] 3.44 3.57 4.07 3.73 3.78 ...\n  ..$ qsec: num [1:14] 17 15.8 17.4 17.6 18 ...\n  ..$ vs  : num [1:14] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ am  : num [1:14] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ gear: num [1:14] 3 3 3 3 3 3 3 3 3 3 ...\n  ..$ carb: num [1:14] 2 4 3 3 3 4 4 4 2 2 ...\n\n\nThis creates a list of three data frames: the cars with 4, 6, and 8 cylinders respectively.\nFirst, imagine we want to fit a linear model to understand how the miles per gallon (mpg) associated with the weight (wt). We can do this for all observations in mtcars using:\n\nlm(mpg ~ wt, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\n\nThe following code shows how you might do that with purrr, which returns a list with output from each lm fit for each cylinder:\n\nby_cyl |&gt;\n  map(.f = ~ lm(mpg ~ wt, data = .x))\n\n$`4`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n     39.571       -5.647  \n\n\n$`6`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n      28.41        -2.78  \n\n\n$`8`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n     23.868       -2.192  \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s say we wanted to extract the second coefficient (i.e. the slope). Using all the observations in mtcars (i.e. ignoring cyl), it would be something like this:\n\nlm.fit &lt;- lm(mpg ~ wt, data = mtcars)\ncoef(lm.fit)\n\n(Intercept)          wt \n  37.285126   -5.344472 \n\ncoef(lm.fit)[2]\n\n       wt \n-5.344472 \n\n\nHow would we do this with the map() family functions if we wanted to stratify the analysis for each cyl?\nHint: you can use two map functions (e.g. map() and map_dbl(2) where you can extract a specific element by a specific name or position).\n\n## try it out \n\n\n\nOr, of course, you could use a for loop:\n\nslopes &lt;- double(length(by_cyl))\nfor (i in seq_along(by_cyl)) {\n  model &lt;- lm(mpg ~ wt, data = by_cyl[[i]])\n  slopes[[i]] &lt;- coef(model)[[2]]\n}\nslopes\n\n[1] -5.647025 -2.780106 -2.192438\n\n\nIt’s interesting to note that as you move from purrr to base apply functions to for loops you tend to do more and more in each iteration.\nIn purrr we iterate 3 times (map(), map(), map_dbl()), and with a for loop we iterate once. I prefer more, but simpler, steps because I think it makes the code easier to understand and later modify.\n\n\n\n\n\n\nQuestion\n\n\n\nNow we are interested in calculating the average mpg for vehicles with different numbers of cylinders. How can we use map functions to do this? You can return a list.\nHint: You can use the syntax x$mpg where x is a dataframe within a map function.\n\n## try it out \n\n\n\n\n\nMatrix as the output\nThe map family include functions that organize the output in different data structures, whose names follow the pattern map_*. As we’ve seen, the map function return a list. The following functions will return a vector of a specific kind, e.g. map_lgl returns a vector of logical variables, map_chr returns a vector of strings.\nIt is also possible to return the the results as data frames by\n\nrow binding (map_dfr) or\ncolumn binding (map_dfc)\n\n\nby_cyl |&gt; \n  map_dbl(.f = ~mean(.x$mpg)) # returns a vector of doubles\n\n       4        6        8 \n26.66364 19.74286 15.10000 \n\nby_cyl |&gt; \n  map_dfr(.f = ~colMeans(.x)) # return a data frame by row binding\n\n# A tibble: 3 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  26.7     4  105.  82.6  4.07  2.29  19.1 0.909 0.727  4.09  1.55\n2  19.7     6  183. 122.   3.59  3.12  18.0 0.571 0.429  3.86  3.43\n3  15.1     8  353. 209.   3.23  4.00  16.8 0     0.143  3.29  3.5 \n\nby_cyl |&gt; \n  map_dfc(.f = ~colMeans(.x)) # return a data frame by col binding\n\n# A tibble: 11 × 3\n       `4`     `6`     `8`\n     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1  26.7    19.7    15.1  \n 2   4       6       8    \n 3 105.    183.    353.   \n 4  82.6   122.    209.   \n 5   4.07    3.59    3.23 \n 6   2.29    3.12    4.00 \n 7  19.1    18.0    16.8  \n 8   0.909   0.571   0    \n 9   0.727   0.429   0.143\n10   4.09    3.86    3.29 \n11   1.55    3.43    3.5"
  },
  {
    "objectID": "readings/03-functional-programming/index.html#more-map-variants",
    "href": "readings/03-functional-programming/index.html#more-map-variants",
    "title": "Functional Programming with purrr",
    "section": "More map variants",
    "text": "More map variants\nThere are 23 primary variants of map(). So far, we have learned about five (map(), map_lgl(), map_int(), map_dbl() and map_chr()). That means that you have got 18 (!!) more to learn. That sounds like a lot, but fortunately the design of purrr means that you only need to learn five new ideas:\n\nOutput same type as input with modify()\nIterate over two inputs with map2().\nIterate with an index using imap()\nReturn nothing with walk().\nIterate over any number of inputs with pmap().\n\nThe map family of functions has orthogonal input and outputs, meaning that we can organise all the family into a matrix, with inputs in the rows and outputs in the columns. Once you have mastered the idea in a row, you can combine it with any column; once you have mastered the idea in a column, you can combine it with any row. That relationship is summarised in the following table:\n\n\n\n\n\n\n\n\n\n\n\nList\nAtomic\nSame type\nNothing\n\n\n\n\nOne argument\nmap()\nmap_lgl(), …\nmodify()\nwalk()\n\n\nTwo arguments\nmap2()\nmap2_lgl(), …\nmodify2()\nwalk2()\n\n\nOne argument + index\nimap()\nimap_lgl(), …\nimodify()\niwalk()\n\n\nN arguments\npmap()\npmap_lgl(), …\n—\npwalk()\n\n\n\n\nmodify()\nImagine you wanted to double every column in a data frame. You might first try using map(), but map() always returns a list:\n\ndf &lt;- data.frame(\n  x = 1:3,\n  y = 6:4\n)\n\nmap(df, ~ .x * 2)\n\n$x\n[1] 2 4 6\n\n$y\n[1] 12 10  8\n\n\nIf you want to keep the output as a data frame, you can use modify(), which always returns the same type of output as the input:\n\nmodify(df, ~ .x * 2)\n\n  x  y\n1 2 12\n2 4 10\n3 6  8\n\n\n\n\n\n\n\n\nNote\n\n\n\nDespite the name, modify() doesn’t modify in place, it returns a modified copy, so if you wanted to permanently modify df, you’d need to assign it:\n\ndf &lt;- modify(df, ~ .x * 2)\n\n\n\n\n\nmap2() and friends\nmap() is vectorised over a single argument, .x.\nThis means it only varies .x when calling .f, and all other arguments are passed along unchanged, thus making it poorly suited for some problems.\nFor example, how would you find a weighted mean when you have a list of observations and a list of weights? Imagine we have the following data:\n\nxs &lt;- map(1:8, ~ runif(10))\nxs[[1]][[1]] &lt;- NA\nws &lt;- map(1:8, ~ rpois(10, 5) + 1)\n\nYou can use map_dbl() to compute the unweighted means:\n\nmap_dbl(.x = xs, .f = mean)\n\n[1]        NA 0.4464825 0.4806867 0.5177861 0.4752695 0.6147369 0.4525804\n[8] 0.5614233\n\n\nBut passing ws as an additional argument does not work because arguments after .f are not transformed:\n\nmap_dbl(x. = xs, .f = weighted.mean, w = ws)\n\nError in map_dbl(x. = xs, .f = weighted.mean, w = ws): argument \".x\" is missing, with no default\n\n\nWe need a new tool: a map2(), which is vectorised over two arguments. This means both .x and .y are varied in each call to .f:\n\nmap2_dbl(.x = xs, .y = ws, .f = weighted.mean)\n\n[1]        NA 0.4548610 0.4449436 0.5327727 0.4077519 0.5728543 0.3940515\n[8] 0.5399974\n\n\nThe arguments to map2() are slightly different to the arguments to map() as two vectors come before the function, rather than one. Additional arguments still go afterwards:\n\nmap2_dbl(.x = xs, .y = ws, .f = weighted.mean, na.rm = TRUE)\n\n[1] 0.5354556 0.4548610 0.4449436 0.5327727 0.4077519 0.5728543 0.3940515\n[8] 0.5399974\n\n\n\n\nwalk() and friends\nMost functions are called for the value that they return, so it makes sense to capture and store the value with a map() function.\nBut some functions are called primarily for their side-effects (e.g. cat(), write.csv(), or ggsave()) and it does not make sense to capture their results.\nLet’s consider the example of saving a dataset. In this case, map will force an output, e.g. NULL. One can consider using walk instead. The function walk (and walk2 for more than two inputs) behaves exactly the same as map but does not output anything.\n\ntmp_fldr &lt;- tempdir()\n\nmap2(.x = by_cyl,\n     .y = 1:length(by_cyl),\n     .f = ~saveRDS(.x, \n                   file = paste0(tmp_fldr, \"/\",.y, \".rds\"))\n)\n\n$`4`\nNULL\n\n$`6`\nNULL\n\n$`8`\nNULL\n\n# No output\nwalk2(.x = by_cyl,\n      .y = (1:length(by_cyl)),\n      .f = ~saveRDS(.x, \n                    file = paste0(tmp_fldr, \"/\",.y, \".rds\"))\n)"
  },
  {
    "objectID": "projects/01-project/index.html",
    "href": "projects/01-project/index.html",
    "title": "Project 1",
    "section": "",
    "text": "Due date: November 8 at 11:59pm\nThe goal of this assignment is to practice some of the skills we have been learning about in class around quarto, command-line, and version control by building and deploying a website. You also are asked to practice with some command-line skills more formally.\n\n\nPlease use this Quarto file (.qmd) and fill in the requested components by adding the URLs pointing to the GitHub repositories and deployed websites. Render this file to a HTML file.\nYou will push the .qmd file and rendered HTML file to a private GitHub repostory on GitHub classroom. The link to create a private GitHub repository for yourself to complete Project 1 will be posted in CoursePlus (Note: this creates an empty repository. You will need to clone the reopository locally, add your code, and push your code from your local repo to the remote repository on GitHub Classroom when ready). Please show all your code, if relevant to a section.\nThe TAs will grade the contents in the GitHub repo by cloning the repo and checking for all the things described below."
  },
  {
    "objectID": "projects/01-project/index.html#create-a-github-repo-for-your-website",
    "href": "projects/01-project/index.html#create-a-github-repo-for-your-website",
    "title": "Project 1",
    "section": "1. Create a GitHub repo for your website",
    "text": "1. Create a GitHub repo for your website\nCreate a new public GitHub repository titled biostat777-intro-&lt;firstname&gt;-&lt;lastname&gt; (where you replace &lt;firstname&gt; with your first name and &lt;lastname&gt; with your last name) in your own personal GitHub account (e.g. https://github.com/&lt;yourgithubusername&gt;/biostat777-intro-&lt;firstname&gt;-&lt;lastname&gt;)."
  },
  {
    "objectID": "projects/01-project/index.html#build-a-website-using-quarto",
    "href": "projects/01-project/index.html#build-a-website-using-quarto",
    "title": "Project 1",
    "section": "2. Build a website using Quarto",
    "text": "2. Build a website using Quarto\nCreate a new project locally within RStudio or VSCode and build a website for yourself. Your website should include the following:\n\nA home/landing page. This is home page that someone will land on your website. At minimum it should include your name, a short summary about yourself (max 2-3 sentences), and a picture of something you enjoy to do for fun (or a picture of yourself if you are comfortable sharing one).\nA page titled ‘About’. This page should describe who you are in greater detail. It could include your professional interests and your educational and/or professional background and/or experience. It could also include any personal information you feel conformable sharing on the website.\nA data analysis page called ‘Example analysis’. You can pick any dataset you wish you analyze. In this webpage, you will analyze a dataset and summarize the results. The requirements for this webpage are the following:\n\nYou must describe what is the question you aim to answer with the data and data analysis.\nYou must describe who is the intended audience for the data analysis.\nYou must describe and link to where the original data come from that you chose.\nYou must include a link to a data dictionary for the data or create one inside the webpage.\nYour analysis must include some minimal form of data wrangling with you using at least five different functions from dplyr or tidyr.\nYour analysis should include at least three plots with you using at least three different geom_*() functions from ggplot2 (or another package with geom_*() functions).\nPlots should have titles, subtitles, captions, and human-understandable axis labels.\nAt least one plot should using a type of faceting (facet_grid() or facet_wrap()).\nYour analysis must include one image or table (not one you created yourself, but one you have saved locally or one from the web).\nYour analysis must include at least two different callout blocks.\nYour analysis must include a .bib file, which you use to reference at least three unique citations. For example, it could be to a website or paper from where the original data came from or it could be to a paper describing a method you are using to analyze the data.\nYour analysis must include the use of at least 1 margin content.\nYou must summarize your analysis and/or results with a paragraph (4-6 sentences).\nAt the end of the data analysis, list out each of the functions you used from each of the packages (dplyr, tidyr, and ggplot2) to help the TA with respect to making sure you met all the requirements described above."
  },
  {
    "objectID": "projects/01-project/index.html#include-a-readme.md-file",
    "href": "projects/01-project/index.html#include-a-readme.md-file",
    "title": "Project 1",
    "section": "3. Include a README.md file",
    "text": "3. Include a README.md file\nYour local repository should include a README.md file describing who is the author of the website and a link to the website after it has been deployed. Other things you might include are the technical details for how the website was created and/or deployed."
  },
  {
    "objectID": "projects/01-project/index.html#deploy-your-website",
    "href": "projects/01-project/index.html#deploy-your-website",
    "title": "Project 1",
    "section": "4. Deploy your website",
    "text": "4. Deploy your website\nDeploy your website e.g. using Quarto Pub, GitHub pages, or Netlify, etc. (Note: Deploying your website to RPubs will not be accepted)."
  },
  {
    "objectID": "projects/01-project/index.html#share-your-website",
    "href": "projects/01-project/index.html#share-your-website",
    "title": "Project 1",
    "section": "5. Share your website",
    "text": "5. Share your website\nGo to the Discussion Board in CoursePlus and write a short post with a link (URL) to your website (and URL to the corresponding GitHub repository) that you created. Also, list the URLs below for the purposes of grading.\nAs you read the introductions from other folks in the class, feel free to comment/reply using Discussion board.\n\nLink to your GitHub repository: [Delete this text and replace the text with the link to the public GitHub repo you created above for your website]\nLink to your deployed website: [Delete this and replace the text with the link to the public deployed website you created above]"
  },
  {
    "objectID": "lectures/03-functional-programming/index.html",
    "href": "lectures/03-functional-programming/index.html",
    "title": "Functional programming",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please install\n\npurrr - this provides a consistent functional programming interface to work with functions and vectors\n\nYou can do this by calling\n\ninstall.packages(\"purrr\")\n\nAnd load the package using:\n\nlibrary(purrr)\n\n\n\nIn addition, please read through\n\nhttps://adv-r.hadley.nz/functionals.html\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/purrr.pdf\n\n\n\n\n\n\n\nHow much should I prepare for before class?"
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#acknowledgements",
    "href": "lectures/03-functional-programming/index.html#acknowledgements",
    "title": "Functional programming",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://adv-r.hadley.nz/fp.html\nhttps://adv-r.hadley.nz/functionals.html\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/purrr.pdf"
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#learning-objectives",
    "href": "lectures/03-functional-programming/index.html#learning-objectives",
    "title": "Functional programming",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nBe familiar with the concept of functional languages and functional styles of programming\nGet comfortable with the major functions in purrr (e.g. the map family of functions)\nWrite your loops with map functions instead of the for loop"
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#slides",
    "href": "lectures/03-functional-programming/index.html#slides",
    "title": "Functional programming",
    "section": "Slides",
    "text": "Slides\n\nTo be added."
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#summary",
    "href": "lectures/03-functional-programming/index.html#summary",
    "title": "Functional programming",
    "section": "Summary",
    "text": "Summary\n\nIntroduction to functional programming.\nThe R package purrr provides a nice interface to functional programming and list manipulation.\nThe function map and its aternative map_* provide a neat way to iterate over a list or vector with the output in different data structures.\nThe function map2 and pmap allow having more than one list as input.\nThe function walk and its alternatives walk2, walk_*, which do not provide any output."
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#additional-practice",
    "href": "lectures/03-functional-programming/index.html#additional-practice",
    "title": "Functional programming",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nUse as_mapper() to explore how purrr generates anonymous functions for the integer, character, and list helpers. What helper allows you to extract attributes? Read the documentation to find out.\nmap(1:3, ~ runif(2)) is a useful pattern for generating random numbers, but map(1:3, runif(2)) is not. Why not? Can you explain why it returns the result that it does?\nCan you write a section of code to demonstrate the central limit theorem primarily using the purrr package and/or using the R base package?\nUse the appropriate map() function to:\n\nCompute the standard deviation of every column in a numeric data frame.\nCompute the standard deviation of every numeric column in a mixed data frame. (Hint: you will need to do it in two steps.)\nCompute the number of levels for every factor in a data frame.\n\nThe following code simulates the performance of a t-test for non-normal data. Extract the p-value from each test, then visualise.\n\ntrials &lt;- map(1:100, ~ t.test(rpois(10, 10), rpois(7, 10)))\n\nUse map() to fit linear models to the mtcars dataset using the formulas stored in this list:\n\ndata(mtcars)\nformulas &lt;- list(\n  mpg ~ disp,\n  mpg ~ I(1 / disp),\n  mpg ~ disp + wt,\n  mpg ~ I(1 / disp) + wt\n)\n\nFit the model mpg ~ disp to each of the bootstrap replicates of mtcars in the list below, then extract the \\(R^2\\) of the model fit (Hint: you can compute the \\(R^2\\) with summary().)\n\nbootstrap &lt;- function(df) {\n  df[sample(nrow(df), replace = TRUE), , drop = FALSE]\n}\n\nbootstraps &lt;- map(1:10, ~ bootstrap(mtcars))"
  },
  {
    "objectID": "lectures/04-data-collection/index.html",
    "href": "lectures/04-data-collection/index.html",
    "title": "Data Collection",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please install the following R packages\n\njsonlite (https://jeroen.cran.dev/jsonlite)\nhttr (https://httr.r-lib.org)\n\n\ninstall.packages(\"jsonlite\")\ninstall.packages(\"httr\")\n\n\n\nIn addition, please read through\n\nData collection with APIs\nData collection from HTMLs"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#acknowledgements",
    "href": "lectures/04-data-collection/index.html#acknowledgements",
    "title": "Data Collection",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://jhu-advdatasci.github.io/2019/lectures/04-gettingdata-api.html\nhttps://aws.amazon.com/what-is/api\nhttps://bookdown.org/paul/apis_for_social_scientists/github.com-api.html\nhttps://statisticsglobe.com/api-in-r"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#learning-objectives",
    "href": "lectures/04-data-collection/index.html#learning-objectives",
    "title": "Data Collection",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nDescribe what the difference is between “raw” vs “clean” data\nLearn about what are JSON files and how we can convert them into data frames in R\nDescribe some best practices on sharing data with collaborators\nKnow what does API mean and state four types of API architectures\nPractice with two APIs: the GitHub API and the openFDA API"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#slides",
    "href": "lectures/04-data-collection/index.html#slides",
    "title": "Data Collection",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#other-good-r-packages-to-know-about",
    "href": "lectures/04-data-collection/index.html#other-good-r-packages-to-know-about",
    "title": "Data Collection",
    "section": "Other good R packages to know about",
    "text": "Other good R packages to know about\n\ngooglesheets4 to interact with Google Sheets in R\ngoogledrive to interact with files on your Google Drive"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#additional-practice",
    "href": "lectures/04-data-collection/index.html#additional-practice",
    "title": "Data Collection",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\n\nUsing the GitHub API, access the repository information and ask how many open github issues you have?\n\nPick another API that we have not discussed here and use httr to retreive data from it."
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "Important reading materials",
    "section": "",
    "text": "The following contains relevant reading materials you should read prior to each class:\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2024-10-24\n\n\nAuthoring projects and websites with Quarto\n\n\nStephanie Hicks\n\n\n\n\n2024-11-05\n\n\nFunctional Programming with purrr\n\n\nStephanie Hicks\n\n\n\n\n2024-11-07\n\n\nScraping data from the web with rvest\n\n\nStephanie Hicks\n\n\n\n\n2024-11-07\n\n\nRetrieving data from APIs with httr\n\n\nStephanie Hicks\n\n\n\n\n2024-11-12\n\n\nRelational databases and SQL basics\n\n\nStephanie Hicks\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/02-project/index.html",
    "href": "projects/02-project/index.html",
    "title": "Project 2",
    "section": "",
    "text": "Background\nDue date: November 15 at 11:59pm\nThe goal of this assignment is to practice some of the skills we have been learning about in class around functional programming and data collection paradigms.\n\nTo submit your project\nPlease use this Quarto file (.qmd). Render this file to a HTML file.\nThe TAs will grade the contents in the GitHub repo by cloning the repo and checking for all the things described below."
  },
  {
    "objectID": "lectures/01-command-line/index.html",
    "href": "lectures/01-command-line/index.html",
    "title": "Introduction to the command-line",
    "section": "",
    "text": "The next lecture falls on 👻 Halloween ! I plan to give the lecture dressed up in a costume. This is entirely optional, but I encourage students to come in costume if you wish! Candy 🍬 will be offered to anyone in costume!"
  },
  {
    "objectID": "lectures/01-command-line/index.html#acknowledgements",
    "href": "lectures/01-command-line/index.html#acknowledgements",
    "title": "Introduction to the command-line",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nSoftware Carpentry: The Unix Shell\nData Science at the Command line\nApplied Computational Genomics"
  },
  {
    "objectID": "lectures/01-command-line/index.html#learning-objectives",
    "href": "lectures/01-command-line/index.html#learning-objectives",
    "title": "Introduction to the command-line",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nUnderstand what is a command shell and why would use one.\nCreate, copy, move, rename, and delete files and folders.\nSearch for regular expressions in files.\nExecute R commands and scripts in the command line.\nRedirect a command’s output to a file with redirect operators (&gt;, &gt;&gt;).\nConstruct command pipelines with two or more stages with the pipe operator (|).\nWrite a loop that applies one or more commands separately to each file in a set of files.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can practice your command-line skills with the Command Challenge"
  },
  {
    "objectID": "lectures/01-command-line/index.html#slides",
    "href": "lectures/01-command-line/index.html#slides",
    "title": "Introduction to the command-line",
    "section": "Slides",
    "text": "Slides\n\nLecture 01: Introduction to the command-line"
  },
  {
    "objectID": "lectures/01-command-line/index.html#summary",
    "href": "lectures/01-command-line/index.html#summary",
    "title": "Introduction to the command-line",
    "section": "Summary",
    "text": "Summary\n\nShell is a text based application for viewing, handling and manipulating files\nIt is also known by the following names\n\nCLI (Command Line Interface)\nTerminal\nBash (Bourne Again Shell)\n\nUse Rscript -e or R -e to execute R scripts from the command line\nRStudio includes a Terminal (from version 1.1.383)\nExecute commands from shell script in RStudio using Ctrl + Enter\nRMarkdown and Quarto supports bash, sh and awk"
  },
  {
    "objectID": "lectures/01-command-line/index.html#additional-practice",
    "href": "lectures/01-command-line/index.html#additional-practice",
    "title": "Introduction to the command-line",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nMove around the computer, get used to moving in and out of directories, see how different file types appear in the Unix shell. Be sure to use the pwd and cd commands, and the different flags for the ls commands.\nPractice using “Tab for Auto-complete” in the shell to autocomplete commands or file names.\nExplore the manual pages of date in the command line to show you what that looks like. Try to figure out what is the argument to print the date since the Unix epoch or 00:00:00 UTC on 1 January 1970 as a function of the number of seconds. Then try to identify what is the argument to display the date in UTC.\nPractice your command line knowledge with Command Challenge."
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Course content",
    "section": "",
    "text": "Course content for each lecture is below:\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2024-10-24\n\n\nWelcome to the course\n\n\nStephanie Hicks\n\n\n\n\n2024-10-29\n\n\nIntroduction to the command-line\n\n\nStephanie Hicks\n\n\n\n\n2024-10-31\n\n\nIntroduction to version control\n\n\nStephanie Hicks\n\n\n\n\n2024-11-05\n\n\nFunctional programming\n\n\nStephanie Hicks\n\n\n\n\n2024-11-07\n\n\nData Collection\n\n\nStephanie Hicks\n\n\n\n\n2024-11-12\n\n\nDatabase programming paradigms\n\n\nStephanie Hicks\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to the Course Website for PH.140.777 Statistical Programming Paradigms and Workflows!"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Welcome",
    "section": "Overview",
    "text": "Overview\nComputing and programming are fundamental skills for applied statisticians to efficiently demonstrate the performance of their models with data, to develop reproducible data analyses or robust software, and to effectively communicate their own research interests. However, these skills are often not taught in the classroom, often making it challenging to learn these skills “on the job”.\nThis hands-on course will cover advanced statistical computing programming paradigms and workflows required for the research and application of statistical methods. Students will be expected to complete readings prior to class, attend lectures to dive deeper into those topics in class, participate in classroom activities, complete projects (both solo and group) practicing and reinforcing the computing and programming skills. There will be a final group project, which will include a major class presentation."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "Welcome",
    "section": "Course Information",
    "text": "Course Information\n\nCourse Staff: Prof. Stephanie Hicks, Joe Sartini, and Wenxuan Lu\nLectures: 1:30-2:50pm Tuesday and Thursday. See CoursePlus for location details.\nOffice Hours: See CoursePlus for location details."
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Welcome",
    "section": "Course Details",
    "text": "Course Details\nAll course details are available on the Course page. The syllabus is available on CoursePlus."
  },
  {
    "objectID": "lectures/00-course-intro/index.html",
    "href": "lectures/00-course-intro/index.html",
    "title": "Welcome to the course",
    "section": "",
    "text": "Before each class, there will be a set of pre-lecture activities and/or readings for you to complete. It is important these activities be done before class so that you can benefit the most from the in-class activities.\nToday we will cover the Pre-reading material about quarto as a way to demonstrate where to find the pre-reading materials going forward. Sometimes, there will not be pre-reading materials here, but rather direct links to external resources that you need to read in advance."
  },
  {
    "objectID": "lectures/00-course-intro/index.html#acknowledgements",
    "href": "lectures/00-course-intro/index.html#acknowledgements",
    "title": "Welcome to the course",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nr4ds book: https://r4ds.hadley.nz/quarto\nQuarto Publishing System: https://quarto.org"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#learning-objectives",
    "href": "lectures/00-course-intro/index.html#learning-objectives",
    "title": "Welcome to the course",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nGet an overview of the course (including staff, format, grading, etc)\nBe able to recognize and operate an Integrated Developer Evironment (IDE) to perform statistial programming and data analysis.\nBe able to describe reasons why having a personal website can be useful.\nRecognize what is Quarto and how it’s different from RMarkdown.\nBe able to create a Quarto project and Quarto website."
  },
  {
    "objectID": "lectures/00-course-intro/index.html#slides",
    "href": "lectures/00-course-intro/index.html#slides",
    "title": "Welcome to the course",
    "section": "Slides",
    "text": "Slides\n\nLecture 00: Welcome and Introductions"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#summary",
    "href": "lectures/00-course-intro/index.html#summary",
    "title": "Welcome to the course",
    "section": "Summary",
    "text": "Summary\n\nAccess all course material on CoursePlus and course website (https://www.stephaniehicks.com/jhustatprogramming2024)\nLectures will be recorded followed by an in-class activity. Later in the course, the in-class activity will be to work on the final project\nAt the end of each class, fill out the reflection card (not graded, but helpful to both the student and instructor)\nIntegrated developer environment (IDEs) can make you more efficient as a programmer!\nQuarto is an open-source scientific and technical publishing system to create reproducible, production quality articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, and more\nYou can think of Quarto as a natural successor to RMarkdown"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#additional-practice",
    "href": "lectures/00-course-intro/index.html#additional-practice",
    "title": "Welcome to the course",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nIn either RStudio or VSCode, create a new Quarto document. Read the instructions. Practice running the chunks individually. Then render the document and practice the appropriate keyboard short cut. Verify that you can modify the code, re-run it, and see modified output.\nCreate one new Quarto document for each of the three built-in formats: HTML, PDF and Word. Render each of the three documents. How do the outputs differ? How do the inputs differ? (You may need to install LaTeX in order to build the PDF output — RStudio will prompt you if this is necessary.)"
  },
  {
    "objectID": "lectures/02-version-control/index.html",
    "href": "lectures/02-version-control/index.html",
    "title": "Introduction to version control",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please follow the instructions on Software Carpentry: Version Control with Git to\n\nInstalling Git\nCreating a GitHub Account\nPreparing Your Working Directory\n\nIn addition, please read through Chapters 1-9.\n\n\n\n\n\n\n\n\nHow much should I prepare for before class?\n\n\n\nYou should be comfortable with the meaning of version control, have git installed, create a GitHub account (if you have not before), prepare your working directory, understand the meaning of most the git commands, and also executing commands on your computer before class starts.\nDuring class, I will give an overview of these topics and then we will practice using version control in groups of two with an in-class activity. I will walk around the class answering questions and helping to address questions as they arise in practice. If you have not installed git, created a GitHub account, and prepared your working directory, it will be challenging to participate in the activity."
  },
  {
    "objectID": "lectures/02-version-control/index.html#acknowledgements",
    "href": "lectures/02-version-control/index.html#acknowledgements",
    "title": "Introduction to version control",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nSoftware Carpentry: Version Control with Git"
  },
  {
    "objectID": "lectures/02-version-control/index.html#learning-objectives",
    "href": "lectures/02-version-control/index.html#learning-objectives",
    "title": "Introduction to version control",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nUnderstand the benefits of an automated version control system.\nUnderstand how to set up git.\nUnderstand how to set up a git repository.\nUnderstand how to track changes, explore history, and ignore files in a git\nUnderstand git remotes.\nUnderstand how to use GitHub.\nUnderstand collaborating."
  },
  {
    "objectID": "lectures/02-version-control/index.html#slides",
    "href": "lectures/02-version-control/index.html#slides",
    "title": "Introduction to version control",
    "section": "Slides",
    "text": "Slides\n\nLecture 02: Introduction to version control"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-1-repository-setup",
    "href": "lectures/02-version-control/index.html#part-1-repository-setup",
    "title": "Introduction to version control",
    "section": "Part 1: Repository Setup",
    "text": "Part 1: Repository Setup\n\nCreate a new repository. One partner (the “Owner” of the GitHub repo) should create a GitHub repository titled bikelanes in their own personal GitHub repository.\nInvite a collaborator. The repository owner needs to invite their partner as a collaborator by going to Settings &gt; Collaborators &gt; Manage Access. Specifically, on GitHub, click the “Settings” button on the right, select “Collaborators”, click “Add people”, and then enter your partner’s GitHub username.\n\nTo accept access to the Owner’s repo, the Collaborator needs to go to https://github.com/notifications or check for email notification. Once there you can accept access to the Owner’s repo.\n\nClone the repository. Both the Owner and Collaborator should clone the repository locally to their respective computers.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf using SSH:\ngit clone git@github.com:&lt;change-to-owners-github-username&gt;/bikelanes.git\nIf using HTTPS:\ngit clone https://github.com/&lt;change-to-owners-github-username&gt;/bikelanes.git"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-2-adding-content-to-the-repository",
    "href": "lectures/02-version-control/index.html#part-2-adding-content-to-the-repository",
    "title": "Introduction to version control",
    "section": "Part 2: Adding content to the repository",
    "text": "Part 2: Adding content to the repository\n\nAdd a CSV file to the local repository. Consider the dataset called bike_lanes_data.csv with the following contents:\n\nLane_ID,Street_Name,Length_km,Type,Year_Installed,City\n1,Main St,1.2,Protected,2018,Springfield\n2,Elm St,0.8,Shared,2016,Springfield\n3,Maple Ave,2.3,Buffered,2020,Springfield\n4,Oak St,1.5,Protected,2019,Springfield\n5,Pine St,0.5,Shared,2015,Springfield\n6,River Rd,3.1,Buffered,2021,Springfield\nThe Owner should create a new CSV locally titled bike_lanes_data.csv and paste the data into the new CSV file. Save the file and commit the file to the local repository using git commands.\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncd bikelanes\ntouch bike_lanes_data.csv # (and paste in the content above)\ngit status\ngit add bike_lanes_data.csv\ngit commit -m \"adding bike lanes data\"\ngit push origin main\n\n\n\n\nCollaborator needs to pull the new changes locally to their computer. Next, the collaborator should pull the changes from the remote bikelanes GitHub repository to their local computer. This should make the new bike_lanes_data.csv appear locally on their computer.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncd bikelanes\ngit pull origin main\n\n\n\n\nAdd a README.md file. The collaborator should create a new file called README.md in the bikelanes repository. Please add the following information to it:\n\n\nThe names of the owner and collaborator of the project\nThe emails of the owner and collaborator of the project\nAnswers to the following questions:\n\nDo you enjoy biking?\nWhat type of biking (e.g. road biking, mountain biking, no biking, etc ) do you enjoy?\nIf not biking, what hobbies do you enjoy doing?\n\n\nAfter the README.md file is complete, add and commit the file to the local repository using git commands. Push the changes to the remote bikelanes repository on GitHub.\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntouch README.md # (add the content)\ngit status\ngit add README.md\ngit commit -m \"adding readme file\"\ngit push\n\n\n\n\nOwner needs to pull the new changes locally to their computer. Next, the owner of the repository should pull the changes from the remote bikelanes GitHub repository to their local computer. This should make the new REAMDE.md appear locally on their computer.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncd bikelanes\ngit pull"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-3-create-github-issues-to-assign-tasks",
    "href": "lectures/02-version-control/index.html#part-3-create-github-issues-to-assign-tasks",
    "title": "Introduction to version control",
    "section": "Part 3: Create GitHub issues to assign tasks",
    "text": "Part 3: Create GitHub issues to assign tasks\nThe partners should create at least one Github Issue for a set of future tasks for the project (e.g., “Add bike lane data from our local area” or “Write code to analyze bike lane usage trends”).\nAssign these issues to each other and set a due date, if desired."
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-4-review-the-git-history",
    "href": "lectures/02-version-control/index.html#part-4-review-the-git-history",
    "title": "Introduction to version control",
    "section": "Part 4: Review the git history",
    "text": "Part 4: Review the git history\nBoth partners should review the commit history using git commands\n\n\n\n\n\n\nSolution\n\n\n\n\n\nExpected commands: git log"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-5-switch-roles-and-repeat-process",
    "href": "lectures/02-version-control/index.html#part-5-switch-roles-and-repeat-process",
    "title": "Introduction to version control",
    "section": "Part 5: Switch roles and repeat process",
    "text": "Part 5: Switch roles and repeat process\nSwitch roles and repeat the whole process."
  },
  {
    "objectID": "lectures/02-version-control/index.html#reflection-questions",
    "href": "lectures/02-version-control/index.html#reflection-questions",
    "title": "Introduction to version control",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nWhat challenges did you encounter when collaborating on GitHub?\nHow did using Issues help you coordinate work?\nIn what ways could GitHub features be useful for larger projects, such as full bike lane data studies?"
  },
  {
    "objectID": "lectures/02-version-control/index.html#additional-practice",
    "href": "lectures/02-version-control/index.html#additional-practice",
    "title": "Introduction to version control",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nInitialize a new Git repository.\n\nCreate a new folder on your computer.\nUse the git init command to turn it into a Git repository.\nConfigure your name and email using git config –global user.name “Your Name”andgit config –global user.email “you@example.com”`.\n\n\nGoal: Learn to set up Git for the first time and understand how Git tracks your identity.\n\nCreate a new file and commit it.\n\nCreate a simple text file in your repository (e.g., README.md).\nUse git add &lt;filename&gt; to stage the file.\nUse git commit -m \"Initial commit\" to commit it to the repository.\n\n\nGoal: Understand how to add and commit files in Git.\n\nModify a file and create a new commit.\n\nMake changes to the file (e.g., add some text to the README.md).\nStage the changes and commit them using git add and git commit.\nUse git log to see the history of your commits.\n\n\nGoal: Learn how to track changes over time and inspect the commit history.\n\nWork with branches.\n\nCreate a new branch using git checkout -b feature-branch.\nMake changes to a file, stage, and commit them.\nSwitch back to the main branch (git checkout main).\nMerge your changes from feature-branch into main using git merge feature-branch.\n\n\nGoal: Understand how branching works and how to merge changes from different branches.\n\nSimulate and resolve a merge conflict.\n\nOn the main branch, edit a line in a file and commit the change.\nSwitch to a new branch (git checkout -b conflicting-branch), edit the same line differently, and commit it.\nMerge the conflicting-branch back into main and resolve the merge conflict manually.\nUse git status to see the files with conflicts and edit them to resolve.\nCommit the resolved changes.\n\n\nGoal: Learn how to handle merge conflicts and understand conflict markers."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2024-11-05\n\n\nProject 2\n\n\nStephanie Hicks\n\n\n\n\n2024-10-31\n\n\nProject 4\n\n\nStephanie Hicks\n\n\n\n\n2024-10-24\n\n\nProject 1\n\n\nStephanie Hicks\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/04-project/index.html",
    "href": "projects/04-project/index.html",
    "title": "Project 4",
    "section": "",
    "text": "The purpose of Project 4 is to work together as a team to design and implement a data analytic product (e.g. a data analysis, a software package, a dashboard, simulation tool, etc) that integrates multiple programming paradigms. The project is intentionally open-ended with the goal it will give you and your team the chance to follow your own curiosity.\n\n\nUnder the Schedule on Course Plus, there will be Google Forms posted to submit the various components of the Final Project.\n\nForm a team (Due Friday November 8th at 11:59pm) and submit the names of your team members using a Google Form on CoursePlus. You should aim to have minimum 3, but ideally 4 (max) people on your team. Please identify a team leader who will fill out this form only on behalf of all team members. This data is very important because we will start scheduling meetings with teams for the week of Nov 18-22 based on the information provided by Nov 8th.\nSubmit a final project proposal (Due Friday November 15th at 11:59pm) using a Google Form on CoursePlus. The team leader who was identified in Part 1 of the Final project should fill out this form only on behalf of all team members. You will need to upload a PDF of your project proposal answering the questions below describing what should be in the project proposal.\nMeet with the instructor or TAs the week of November 18-22, 2024. The instructor or TAs will contact teams individuall to schedule a time to meet. The purpose of this meeting is to make sure the project is feasible, not too big or small in scope, data is accessible, etc.\nPrepare a final project presentation (Due Wednesday December 11th at 11:59pm) and upload a PDF of the presentation using a Google Form on CoursePlus. Your team also will need to sign up for a date to present as a team on either December 12th or December 17th in class. You are expected to present as a team on that date. The sign up for the schedule will be posted soon. The content of what should be in the presentation is described below.\nSubmit a final project write up (Due Thursday December 19th at 11:59pm) to GitHub Classroom. You will also submit a link to the GitHub Classroom repository using a Google Form on CoursePlus. Please prepare a write up of your final project and upload the write up. The content of what should be in the write up is described below.\nSubmit group participation evaluation (Due Thursday December 19th at 11:59pm) using a Google Form on CoursePlus. This will include both a self-evaluation and a peer-evaluation on your team member.\n\n\n\n\nThe breakdown for how the components in the final project will be weighted towards the final project (or Project 4) grade:\n\nSubmit names of team members (5%)\nSubmit project proposal (20%)\nMeet with the instructor or TAs to discuss project proposal as a team (15%)\nProject presentation as a team (25%)\nFinal project write up via GitHub Classroom (25%)\nGroup participation (self- and peer-evaluation) (10%)\n\n\n\n\n\n\n\nImportant\n\n\n\nTeam members will recieve the same grade for everything except the group participation. This will be evaluated separately for each individual depending on their level of participation and contribution to the team. We will ask each of you to self-evaluation your participation and we will ask your team members to evaluate your particiption.\nIf you all contribute to the project, this should be an easy 10%. If you let your team members do all the work and you don’t contribute, this will reflect in your final project grade.\n\n\n\n\n\nUsing quarto, write up a project proposal and submit the PDF. The final project proposal should include the following information:\n\nThe title of your project and the team members names\nYou should describe a research or data analysis question and explain its importance\nYou should summarize work that already exists (if it does)\nYou should outline the work you plan to do\nYou should demonstrate you have access to the data, describe the data, and propose how you will collect the data\nYou should describe the programming paradigms you plan to use and why it makes sense to combine them for your project\nYou should describe any packages and/or software you plan to use\nYou should briefly describe the data analytic product you plan to build\nYou should describe a tentative timeline for the proposal\nYou should describe how the tasks will be split amongst the team members\n\n\n\nYour final project must demonstrate collecting data from a source in a non-trival way. An example of something trival might be to simply read in a CSV file. In class, we talked about extracting data from APIs, HTML, or SQL databases. These are not the only ways to collect data, but the final project should include either one of the following paradigms around data / database collection or the team could propose another (non-trivial) data collection paradigm they would like to propose for the project.\n\nData collection paradigms\nDatabase programming paradigms\n\n\n\n\nYour final project must use at least two (or more is OK too, but at minimum two) of the following programming paradigms we discussed in class:\n\nProgramming in the command line (e.g. shell scripting)\nFunctional programming paradigms\nObject oriented programming paradigms\nParallel computing paradigms\nMachine learning paradigms\n\n\n\n\nYour final project must include building a data analytic products, such as:\n\nA data analysis summarized in a deployed quarto website\nAn R package with a deployed pkgdown website\nA deployed dashboard (e.g. using flexdashboard or shiny)\n\n\n\n\nHere are some example ideas for potential projects:\n\nBuild a custom SQL database to track outcomes for a particular disease and then build machine learning models to predict disease spread allowing for functional modules for data cleaning.\nBuild an R package (i.e. object oriented programming) around pulling data from the Open Baltimore API, which includes writing functions leveraging functional programming paradigms.\nBuild machine learning models leveraging parallel computing for distributed data (e.g. data not all in one place or data that can’t be read into memory at once).\nExtract data from an API and build a dashboard to tackle a statistical problem that might leverage functional programming and parallel computing paradigms.\nBuild an R package to help customer retention for a business using shell scripts to run simulations.\n\nAgain, the goal is for your team to investigate a question of interest with data of your choice that integrates multiple programming paradigms and finally builds some type of data analytic product. It is intentionally open and broad, but hopefully more fun for your team!\n\n\n\n\nDepending on how many teams are formed, this will determine how long teams have to present, but given the size of the class, it will likely be around 10-15 mins in length. You will be asked to turn in slides for your presentation before you present.\nGive a presentation explaining the importance of the project, an overview of the technical challenges, and what you learned. Plan for a few minutes of questions at the end. Also consider the following:\n\nPresentation quality: Is the presentation clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Are the slides readable? Do the figures have large enough legends and figure titles? Did you describe the data?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?\n\n\n\n\nWrite up a summary of your final project and submit it to GitHub classroom.\nPlease explain the importance of the project, give an overview of the technical challenges, and what you learned. Also consider the following:\n\nWrite up quality: Is the write up clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Do the figures have large enough legends and figure titles? Did you describe the data?\nIs there a README.md in the repo you push to GitHub classroom summarizing key details about the project, including team members and an overview of the final project?\nHave you linked to all code and data needed to reproduce your work?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?"
  },
  {
    "objectID": "projects/04-project/index.html#deliverables",
    "href": "projects/04-project/index.html#deliverables",
    "title": "Project 4",
    "section": "",
    "text": "Under the Schedule on Course Plus, there will be Google Forms posted to submit the various components of the Final Project.\n\nForm a team (Due Friday November 8th at 11:59pm) and submit the names of your team members using a Google Form on CoursePlus. You should aim to have minimum 3, but ideally 4 (max) people on your team. Please identify a team leader who will fill out this form only on behalf of all team members. This data is very important because we will start scheduling meetings with teams for the week of Nov 18-22 based on the information provided by Nov 8th.\nSubmit a final project proposal (Due Friday November 15th at 11:59pm) using a Google Form on CoursePlus. The team leader who was identified in Part 1 of the Final project should fill out this form only on behalf of all team members. You will need to upload a PDF of your project proposal answering the questions below describing what should be in the project proposal.\nMeet with the instructor or TAs the week of November 18-22, 2024. The instructor or TAs will contact teams individuall to schedule a time to meet. The purpose of this meeting is to make sure the project is feasible, not too big or small in scope, data is accessible, etc.\nPrepare a final project presentation (Due Wednesday December 11th at 11:59pm) and upload a PDF of the presentation using a Google Form on CoursePlus. Your team also will need to sign up for a date to present as a team on either December 12th or December 17th in class. You are expected to present as a team on that date. The sign up for the schedule will be posted soon. The content of what should be in the presentation is described below.\nSubmit a final project write up (Due Thursday December 19th at 11:59pm) to GitHub Classroom. You will also submit a link to the GitHub Classroom repository using a Google Form on CoursePlus. Please prepare a write up of your final project and upload the write up. The content of what should be in the write up is described below.\nSubmit group participation evaluation (Due Thursday December 19th at 11:59pm) using a Google Form on CoursePlus. This will include both a self-evaluation and a peer-evaluation on your team member."
  },
  {
    "objectID": "projects/04-project/index.html#grading",
    "href": "projects/04-project/index.html#grading",
    "title": "Project 4",
    "section": "",
    "text": "The breakdown for how the components in the final project will be weighted towards the final project (or Project 4) grade:\n\nSubmit names of team members (5%)\nSubmit project proposal (20%)\nMeet with the instructor or TAs to discuss project proposal as a team (15%)\nProject presentation as a team (25%)\nFinal project write up via GitHub Classroom (25%)\nGroup participation (self- and peer-evaluation) (10%)\n\n\n\n\n\n\n\nImportant\n\n\n\nTeam members will recieve the same grade for everything except the group participation. This will be evaluated separately for each individual depending on their level of participation and contribution to the team. We will ask each of you to self-evaluation your participation and we will ask your team members to evaluate your particiption.\nIf you all contribute to the project, this should be an easy 10%. If you let your team members do all the work and you don’t contribute, this will reflect in your final project grade."
  },
  {
    "objectID": "projects/04-project/index.html#final-project-proposal",
    "href": "projects/04-project/index.html#final-project-proposal",
    "title": "Project 4",
    "section": "",
    "text": "Using quarto, write up a project proposal and submit the PDF. The final project proposal should include the following information:\n\nThe title of your project and the team members names\nYou should describe a research or data analysis question and explain its importance\nYou should summarize work that already exists (if it does)\nYou should outline the work you plan to do\nYou should demonstrate you have access to the data, describe the data, and propose how you will collect the data\nYou should describe the programming paradigms you plan to use and why it makes sense to combine them for your project\nYou should describe any packages and/or software you plan to use\nYou should briefly describe the data analytic product you plan to build\nYou should describe a tentative timeline for the proposal\nYou should describe how the tasks will be split amongst the team members\n\n\n\nYour final project must demonstrate collecting data from a source in a non-trival way. An example of something trival might be to simply read in a CSV file. In class, we talked about extracting data from APIs, HTML, or SQL databases. These are not the only ways to collect data, but the final project should include either one of the following paradigms around data / database collection or the team could propose another (non-trivial) data collection paradigm they would like to propose for the project.\n\nData collection paradigms\nDatabase programming paradigms\n\n\n\n\nYour final project must use at least two (or more is OK too, but at minimum two) of the following programming paradigms we discussed in class:\n\nProgramming in the command line (e.g. shell scripting)\nFunctional programming paradigms\nObject oriented programming paradigms\nParallel computing paradigms\nMachine learning paradigms\n\n\n\n\nYour final project must include building a data analytic products, such as:\n\nA data analysis summarized in a deployed quarto website\nAn R package with a deployed pkgdown website\nA deployed dashboard (e.g. using flexdashboard or shiny)\n\n\n\n\nHere are some example ideas for potential projects:\n\nBuild a custom SQL database to track outcomes for a particular disease and then build machine learning models to predict disease spread allowing for functional modules for data cleaning.\nBuild an R package (i.e. object oriented programming) around pulling data from the Open Baltimore API, which includes writing functions leveraging functional programming paradigms.\nBuild machine learning models leveraging parallel computing for distributed data (e.g. data not all in one place or data that can’t be read into memory at once).\nExtract data from an API and build a dashboard to tackle a statistical problem that might leverage functional programming and parallel computing paradigms.\nBuild an R package to help customer retention for a business using shell scripts to run simulations.\n\nAgain, the goal is for your team to investigate a question of interest with data of your choice that integrates multiple programming paradigms and finally builds some type of data analytic product. It is intentionally open and broad, but hopefully more fun for your team!"
  },
  {
    "objectID": "projects/04-project/index.html#final-project-presentation",
    "href": "projects/04-project/index.html#final-project-presentation",
    "title": "Project 4",
    "section": "",
    "text": "Depending on how many teams are formed, this will determine how long teams have to present, but given the size of the class, it will likely be around 10-15 mins in length. You will be asked to turn in slides for your presentation before you present.\nGive a presentation explaining the importance of the project, an overview of the technical challenges, and what you learned. Plan for a few minutes of questions at the end. Also consider the following:\n\nPresentation quality: Is the presentation clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Are the slides readable? Do the figures have large enough legends and figure titles? Did you describe the data?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?"
  },
  {
    "objectID": "projects/04-project/index.html#final-project-write-up",
    "href": "projects/04-project/index.html#final-project-write-up",
    "title": "Project 4",
    "section": "",
    "text": "Write up a summary of your final project and submit it to GitHub classroom.\nPlease explain the importance of the project, give an overview of the technical challenges, and what you learned. Also consider the following:\n\nWrite up quality: Is the write up clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Do the figures have large enough legends and figure titles? Did you describe the data?\nIs there a README.md in the repo you push to GitHub classroom summarizing key details about the project, including team members and an overview of the final project?\nHave you linked to all code and data needed to reproduce your work?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Location: In person for Fall 2024\nCourse time: Tuesdays and Thursdays from 1:30-2:50pm (Eastern Daylight Time zone)\nCourse location: W4030\nAssignments: Four projects\n\n\n\n\nStephanie C. Hicks (https://www.stephaniehicks.com)\n\nOffice Location: E3545, Wolfe Street building\nEmail: shicks19@jhu.edu\n\n\nI am an Associate Professor in the Department of Biostatistics at the Bloomberg School of Public Health and Department of Biomedical Engineering in the Whiting School of Engineering at Johns Hopkins University, a faculty member of the Johns Hopkins Data Science Lab, and have affiliations with the Malone Center for Engineering in Healthcare, Center for Computational Biology, the Department of Genetic Medicine, and the Department of Biochemistry and Molecular Biology.\nMy research focuses on developing fast, scalable, statistical methodology and open-source software for genomics and biomedical data analysis for human health and disease. My research is problem-forward: I develop statistical methods and software that are motivated by concrete problems, often with real-world, noisy, messy data. I’m also interested in developing theory for how to incorporate design thinking (alongside statistical thinking) in practice of data analysis.\nIf you want, you can find me on Twitter. I’m also a co-host of the The Corresponding Author podcast, member of the Editorial Board for Genome Biology, an Associate Editor for Reproducibility at the Journal of the American Statistical Association, and co-founder of R-Ladies Baltimore.\n\n\n\nJoe Sartini (jsartin1@jhu.edu) is a third year Ph.D. student in Biostatistics, with interest in models for precision medicine applications. Currently, the focus of his work is extracting meaningful insights from time-series produced by Continuous Glucose Monitoring and other devices worn by Type 2 diabetics. Outside of research, he enjoys participating in endurance sports and weightlifting.\nAngela Zhao (azhao29@jh.edu) is a second year ScM student in Biostatistics interested in functional data analysis and stochastic models. Her main projects involve using physical activity data derived from wearable devices to predict time-to-event outcomes. For leisure, she enjoys bouldering and stand-up comedy.\nInstructor and TA office hours are announced on CoursePlus. If there are conflicts and/or need to cancel office hours, announcements will be made on CoursePlus.\n\n\n\n\nCourse website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023\n\n\n\n\nUpon successfully completing this course, students will be able to:\n\nWrite unix code with command-line tools\nInstall and configure software necessary for a statistical programming environment and with version control\nWrite code for advanced programming topics in R, Python, SQL, and tidyverse\nBuild and organize a software package with documentation for publishing on the internet\nWrite code using functional or other programming paradigms and discuss strategies for getting data from APIs or working with large data\nBuild an interactive web application using Shiny or other dashboard tools"
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus",
    "section": "",
    "text": "Stephanie C. Hicks (https://www.stephaniehicks.com)\n\nOffice Location: E3545, Wolfe Street building\nEmail: shicks19@jhu.edu\n\n\nI am an Associate Professor in the Department of Biostatistics at the Bloomberg School of Public Health and Department of Biomedical Engineering in the Whiting School of Engineering at Johns Hopkins University, a faculty member of the Johns Hopkins Data Science Lab, and have affiliations with the Malone Center for Engineering in Healthcare, Center for Computational Biology, the Department of Genetic Medicine, and the Department of Biochemistry and Molecular Biology.\nMy research focuses on developing fast, scalable, statistical methodology and open-source software for genomics and biomedical data analysis for human health and disease. My research is problem-forward: I develop statistical methods and software that are motivated by concrete problems, often with real-world, noisy, messy data. I’m also interested in developing theory for how to incorporate design thinking (alongside statistical thinking) in practice of data analysis.\nIf you want, you can find me on Twitter. I’m also a co-host of the The Corresponding Author podcast, member of the Editorial Board for Genome Biology, an Associate Editor for Reproducibility at the Journal of the American Statistical Association, and co-founder of R-Ladies Baltimore."
  },
  {
    "objectID": "syllabus.html#teaching-assistants",
    "href": "syllabus.html#teaching-assistants",
    "title": "Syllabus",
    "section": "",
    "text": "Joe Sartini (jsartin1@jhu.edu) is a third year Ph.D. student in Biostatistics, with interest in models for precision medicine applications. Currently, the focus of his work is extracting meaningful insights from time-series produced by Continuous Glucose Monitoring and other devices worn by Type 2 diabetics. Outside of research, he enjoys participating in endurance sports and weightlifting.\nAngela Zhao (azhao29@jh.edu) is a second year ScM student in Biostatistics interested in functional data analysis and stochastic models. Her main projects involve using physical activity data derived from wearable devices to predict time-to-event outcomes. For leisure, she enjoys bouldering and stand-up comedy.\nInstructor and TA office hours are announced on CoursePlus. If there are conflicts and/or need to cancel office hours, announcements will be made on CoursePlus."
  },
  {
    "objectID": "syllabus.html#important-links",
    "href": "syllabus.html#important-links",
    "title": "Syllabus",
    "section": "",
    "text": "Course website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023"
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "",
    "text": "Upon successfully completing this course, students will be able to:\n\nWrite unix code with command-line tools\nInstall and configure software necessary for a statistical programming environment and with version control\nWrite code for advanced programming topics in R, Python, SQL, and tidyverse\nBuild and organize a software package with documentation for publishing on the internet\nWrite code using functional or other programming paradigms and discuss strategies for getting data from APIs or working with large data\nBuild an interactive web application using Shiny or other dashboard tools"
  },
  {
    "objectID": "syllabus.html#courseplus",
    "href": "syllabus.html#courseplus",
    "title": "Syllabus",
    "section": "Courseplus",
    "text": "Courseplus\nThe primary communication for the class will go through Courseplus. That is where we will post course announcements, share resources, host most of our asynchronous course discussion, and as the primary means of communication between course participants and course instructors\n\n\n\n\n\n\nImportant\n\n\n\nIf you are registered for the course, you should have access to Courseplus now. Once you have access you will also be able to find all material and dates/times of drop-in hours. Any zoom links will be posted on Courseplus.\n\n\nThe course will make use of the CoursePlus Discussion Forum in order to ask and answer questions regarding any of the course materials. The Instructor and the Teaching Assistant will monitor the discussion boards and answer questions when appropriate."
  },
  {
    "objectID": "syllabus.html#github",
    "href": "syllabus.html#github",
    "title": "Syllabus",
    "section": "GitHub",
    "text": "GitHub\nYou can access all course materials (e.g. lectures, project assignments) here\n\nCourse website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023"
  },
  {
    "objectID": "syllabus.html#lectures",
    "href": "syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nThis is course has only one section ending in .01, which means it is an Onsite Synchronous course. This means you are expected to attend class in person. While, I will record the lectures via a zoom recording, I do not plan to post the recordings on CoursePlus. If you have an unexpected / emergency event that comes up and you are unable to attend the lecture in person, you can email me to ask for the recording. I just ask that you briefly provide 1 sentence explanation.\nAttendance is not taken, but I strongly encourage you to attend class to ask questions and participate in class exercises. You will get as much out of the course as you put into it."
  },
  {
    "objectID": "syllabus.html#getting-help",
    "href": "syllabus.html#getting-help",
    "title": "Syllabus",
    "section": "Getting help",
    "text": "Getting help\nIn order of preference, here is a preferred list of ways to get help:\n\nWe strongly encourage you to use Courseplus to ask questions first, before joining office hours. The reason for this is so that other students in the class (who likely have similar questions) can also benefit from the questions and answers asked by your colleagues.\nYou are welcome to join office hours to get more group interactive feedback.\nIf you are not able to make the office hours, appointments can be made by email with the instructor."
  },
  {
    "objectID": "syllabus.html#textbook-and-other-course-material",
    "href": "syllabus.html#textbook-and-other-course-material",
    "title": "Syllabus",
    "section": "Textbook and Other Course Material",
    "text": "Textbook and Other Course Material\nThere is no required textbook. We will make use of several freely available textbooks and other materials. All course materials will be provided. We will use the R and Python software for data analysis, which is freely available for download."
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus",
    "section": "Software",
    "text": "Software\nWe will make heavy use of R in this course, so you should have R installed. You can obtain R from the Comprehensive R Archive Network. There are versions available for Mac, Windows, and Unix/Linux. This software is required for this course.\nIt is important that you have the latest version of R installed. For this course we will be using R version 4.4.1. You can determine what version of R you have by starting up R and typing into the console R.version.string and hitting the return/enter key. If you do not have this version of R installed, go to CRAN and download and install the latest version.\nWe will also make use of the RStudio interactive development environment (IDE). RStudio requires that R be installed, and so is an “add-on” to R. You can obtain the RStudio Desktop for free from the RStudio web site. In particular, we will make heavy use of it when developing R packages. It is also essential that you have the latest release of RStudio. You can determine the version of RStudio by looking at menu item Help &gt; About RStudio. You should be using RStudio version 2023.09.1+494 (2023.09.1+494) or higher, which requires R version 3.3.0 or higher."
  },
  {
    "objectID": "syllabus.html#projects",
    "href": "syllabus.html#projects",
    "title": "Syllabus",
    "section": "Projects",
    "text": "Projects\nThere will be 4 assignments, due every 2–3 weeks. Projects will be submitted electronically via the Drop Box on the CoursePlus web site (unless otherwise specified).\nThe project assignments will be due on\n\nProject 1: Friday November 10, 11:59pm\nProject 2: Tuesday November 28, 11:59pm\nProject 3: Tuesday December 12, 11:59pm\nProject 4: Friday December 22, 11:59pm\n\n\nProject collaboration\nPlease feel free to study together and talk to one another about project assignments. The mutual instruction that students give each other is among the most valuable that can be achieved.\nHowever, it is expected that project assignments will be implemented and written up independently unless otherwise specified. Specifically, please do not share analytic code or output. Please do not collaborate on write-up and interpretation. Please do not access or use solutions from any source before your project assignment is submitted for grading."
  },
  {
    "objectID": "syllabus.html#exams",
    "href": "syllabus.html#exams",
    "title": "Syllabus",
    "section": "Exams",
    "text": "Exams\nThere are no exams in this course."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nGrades in the course will be based on Projects 1–4. Grades for the projects and the final grade will be issued via the CoursePlus grade book.\n\nRelative weights\nThe grades are based on four projects. The breakdown of grading will be\n\n25% for Project 1\n25% for Project 2\n25% for Project 3\n25% for Project 4"
  },
  {
    "objectID": "syllabus.html#policy-for-submitted-projects-late",
    "href": "syllabus.html#policy-for-submitted-projects-late",
    "title": "Syllabus",
    "section": "Policy for submitted projects late",
    "text": "Policy for submitted projects late\n\n\n\n\n\n\nImportant\n\n\n\nThe instructor and TA(s) will not accept email late day policy requests.\n\n\nThis is the policy for late submissions that applies to Projects 1-4.\n\nEach student will be given three “free late days” for the rest of the course.\nA late day extends the individual project deadline by 24 hours without penalty.\nThe late days can be applied to just one project (e.g. two late days for Project 2), or they can be split across the two projects (one late day for Project 2 and one late day for Project 3). This is entirely left up to the discretion of the student.\nA max of two “free late days” can be applied to any one project.\nFree late days are intended to give you flexibility: you can use them for any reason no questions asked.\nYou do not get any bonus points for not using your late days.\n\nAlthough the each student is only given a total of three “free late days”, we will be accepting homework from students that pass this limit.\n\nWe will deduct 5% off the 100% starting point for each day the assignment is late.\nIf you use two “free late days” for project, but need a 3rd day, there will be no penalty for the first two late days and there will be a 5% penalty for the 3rd late day.\nIf you do not have any more late days for the term, we will deduct 5% for the assignment that is &lt;24 hours late, 10% points for the assignment that is 24-48 hours late, and 15% points for the assignment that is 48-72 hours late.\n\n\n\n\n\n\n\nImportant\n\n\n\nWe will not grade assignments that are more than 3 days (or more than 72 hours) past the original due date.\n\n\n\nRegrading Policy\nIt is very important to us that all assignments are properly graded. If you believe there is an error in your assignment grading, please send an email to the instructor within 7 days of receiving the grade. No re-grade requests will be accepted orally, and no regrade requests will be accepted more than 7 days after you receive the grade for the assignment."
  },
  {
    "objectID": "syllabus.html#use-of-ai-tools",
    "href": "syllabus.html#use-of-ai-tools",
    "title": "Syllabus",
    "section": "Use of AI tools",
    "text": "Use of AI tools\nUse of AI tools (including ChatGPT, Bard, Microsoft Copilot, etc) to assist in completing this assignment/exam is permitted with your writing and/or programming. Be aware, however, that such tools often introduce errors or fabricate information; it is your responsibility to ensure the factual accuracy of whatever you claim as your writing/code. I recommend using such tools particularly for learning to code, just make sure the code does what it is supposed to, and that you understand what the code does.\nWith respect to writing, as with all sources, proper references and use of quotation marks should be used (if precise language generated by the software is used). The reference must include the website and specific prompts used to generate the referenced output."
  },
  {
    "objectID": "syllabus.html#academic-ethics-and-student-conduct-code",
    "href": "syllabus.html#academic-ethics-and-student-conduct-code",
    "title": "Syllabus",
    "section": "Academic Ethics and Student Conduct Code",
    "text": "Academic Ethics and Student Conduct Code\nStudents enrolled in the Bloomberg School of Public Health of The Johns Hopkins University assume an obligation to conduct themselves in a manner appropriate to the University’s mission as an institution of higher education. A student is obligated to refrain from acts which he or she knows, or under the circumstances has reason to know, impair the academic integrity of the University. Violations of academic integrity include, but are not limited to: cheating; plagiarism; knowingly furnishing false information to any agent of the University for inclusion in the academic record; violation of the rights and welfare of animal or human subjects in research; and misconduct as a member of either School or University committees or recognized groups or organizations.\nStudents should be familiar with the policies and procedures specified under Policy and Procedure Manual Student-01 (Academic Ethics), available on the school’s portal.\nThe faculty, staff and students of the Bloomberg School of Public Health and the Johns Hopkins University have the shared responsibility to conduct themselves in a manner that upholds the law and respects the rights of others. Students enrolled in the School are subject to the Student Conduct Code (detailed in Policy and Procedure Manual Student-06) and assume an obligation to conduct themselves in a manner which upholds the law and respects the rights of others. They are responsible for maintaining the academic integrity of the institution and for preserving an environment conducive to the safe pursuit of the School’s educational, research, and professional practice missions.\n\nCourse code of Conduct\nWe are committed to providing a welcoming, inclusive, and harassment-free experience for everyone, regardless of gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion (or lack thereof), political beliefs/leanings, or technology choices. We do not tolerate harassment of course participants in any form. Sexual language and imagery is not appropriate for any work event, including group meetings, conferences, talks, parties, Twitter and other online media. This code of conduct applies to all course participants, including instructors and TAs, and applies to all modes of interaction, both in-person and online, including GitHub project repos, Slack channels, and Twitter.\nCourse participants violating these rules will be referred to leadership of the Department of Biostatistics and the Title IX coordinator at JHU and may face expulsion from the class.\nAll class participants agree to:\n\nBe considerate in speech and actions, and actively seek to acknowledge and respect the boundaries of other members.\nBe respectful. Disagreements happen, but do not require poor behavior or poor manners. Frustration is inevitable, but it should never turn into a personal attack. A community where people feel uncomfortable or threatened is not a productive one. Course participants should be respectful both of the other course participants and those outside the course.\nRefrain from demeaning, discriminatory, or harassing behavior and speech. Harassment includes, but is not limited to: deliberate intimidation; stalking; unwanted photography or recording; sustained or willful disruption of talks or other events; inappropriate physical contact; use of sexual or discriminatory imagery, comments, or jokes; and unwelcome sexual attention. If you feel that someone has harassed you or otherwise treated you inappropriately, please alert Stephanie Hicks.\nTake care of each other. Refrain from advocating for, or encouraging, any of the above behavior. And, if someone asks you to stop, then stop. Alert Stephanie Hicks if you notice a dangerous situation, someone in distress, or violations of this code of conduct, even if they seem inconsequential.\n\n\n\nNeed Help?\nPlease speak with Stephanie Hicks or one of the TAs. You can also reach out to Karen Bandeen-Roche, chair of the department of Biostatistics or Margaret Taub, Ombudsman for the Department of Biostatistics.\nYou may also reach out to any Hopkins resource for sexual harassment, discrimination, or misconduct:\n\nJHU Sexual Assault Helpline, 410-516-7333 (confidential)\n\nUniversity Sexual Assault Response and Prevention website\nJohns Hopkins Compliance Hotline, 844-SPEAK2US (844-733-2528)\nHopkins Policies Online\nJHU Office of Institutional Equity 410-516-8075 (nonconfidential)\nJohns Hopkins Student Assistance Program (JHSAP), 443-287-7000\nUniversity Health Services, 410-955-1892\nThe Faculty and Staff Assistance Program (FASAP), 443-997-7000"
  },
  {
    "objectID": "syllabus.html#license-and-attribution",
    "href": "syllabus.html#license-and-attribution",
    "title": "Syllabus",
    "section": "License and attribution",
    "text": "License and attribution\nThis Code of Conduct is distributed under a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license. Portions of above text comprised of language from the Codes of Conduct adopted by rOpenSci and Django, which are licensed by CC BY-SA 4.0 and CC BY 3.0. This work was further inspired by Ada Initiative’s ‘’how to design a code of conduct for your community’’ and Geek Feminism’s Code of conduct evaluations and expanded by Ashley Johnson and Shannon Ellis in the Jeff Leek group."
  },
  {
    "objectID": "syllabus.html#disability-support-service",
    "href": "syllabus.html#disability-support-service",
    "title": "Syllabus",
    "section": "Disability Support Service",
    "text": "Disability Support Service\nStudents requiring accommodations for disabilities should register with Student Disability Service (SDS). It is the responsibility of the student to register for accommodations with SDS. Accommodations take effect upon approval and apply to the remainder of the time for which a student is registered and enrolled at the Bloomberg School of Public Health. Once a student has been approved for accommodations, the student will receive formal notification and the student will be encouraged to reach out to the instructor.\nIf you have questions about requesting accommodations, please contact BSPH.dss@jhu.edu."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nPrerequisite for the course is Biostatistics 140.776 or knowledge of material from 140.776 is assumed.\nIf you did not take the above course, please contact course instructor to get permission to enroll."
  },
  {
    "objectID": "syllabus.html#general-disclaimers",
    "href": "syllabus.html#general-disclaimers",
    "title": "Syllabus",
    "section": "General Disclaimers",
    "text": "General Disclaimers\nThis syllabus is a general plan, deviations announced to the class by the instructor may be necessary."
  },
  {
    "objectID": "syllabus.html#typos-and-corrections",
    "href": "syllabus.html#typos-and-corrections",
    "title": "Syllabus",
    "section": "Typos and corrections",
    "text": "Typos and corrections\nFeel free to submit typos/errors/etc via the github repository associated with the class: https://github.com/stephaniehicks/jhustatprogramming2023. You will have the thanks of your grateful instructor!"
  },
  {
    "objectID": "lectures/05-database-programming/index.html",
    "href": "lectures/05-database-programming/index.html",
    "title": "Database programming paradigms",
    "section": "",
    "text": "Important\n\n\n\nFor this lecture, we will use Unix shell, plus SQLite3 or DB Browser for SQLite.\nYou can see if the command-line tool sqlite3 (also known as “SQLite”) is already installed with\n\nsqlite3 --version\n\n3.43.2 2023-10-10 13:08:14 1b37c146ee9ebb7acd0160c0ab1fd11017a419fa8a3187386ed8cb32b709aapl (64-bit)\n\n\nIf not, you can install with homebrew or follow the instructions here:\n\nhttps://swcarpentry.github.io/sql-novice-survey/setup.html\n\nAlso, you will need to install these R packages:\n\ninstall.packages(\"DBI\")\ninstall.packages(\"RSQLite\")\ninstall.packages(\"dbplyr\")\n\n\n\nIn addition, please read through\n\nhttps://swcarpentry.github.io/sql-novice-survey\nhttps://dbi.r-dbi.org\nhttps://solutions.posit.co/connections/db/databases/sqlite/\nhttps://dbplyr.tidyverse.org\n\n\n\n\n\n\n\nHow much should I prepare for before class?"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#acknowledgements",
    "href": "lectures/05-database-programming/index.html#acknowledgements",
    "title": "Database programming paradigms",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://www.stephaniehicks.com/jhuads2021/posts/2021-12-06-sql-basics\nhttps://swcarpentry.github.io/sql-novice-survey"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#learning-objectives",
    "href": "lectures/05-database-programming/index.html#learning-objectives",
    "title": "Database programming paradigms",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nExplain the difference between a table, a record, and a field in relational databases\nExplain the difference between a database and a database manager\nWrite a query to select all values for specific fields from a single table\nWrite queries that display results in a particular order\nWrite queries that eliminate duplicate values from data\nWrite queries that select records that satisfy user-specified conditions\nLearn about the DBI, RSQLite, dbplyr packages for making SQL queries in R"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#slides",
    "href": "lectures/05-database-programming/index.html#slides",
    "title": "Database programming paradigms",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#additional-practice",
    "href": "lectures/05-database-programming/index.html#additional-practice",
    "title": "Database programming paradigms",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\nUsing the survey.db database:\n\nUse .schema to identify column that contains integers\nWrite a query that selects only the name column from the Site table.\nMany people format queries in the following two ways. What style do you find easiest to read, and why?\n\nSELECT personal, family FROM person;\nor\nselect Personal, Family from PERSON;\n\nWrite a query that selects distinct dates from the Visited table.\nWrite a query that displays the full names of the scientists in the Person table, ordered by family name."
  },
  {
    "objectID": "readings/00-quarto/index.html",
    "href": "readings/00-quarto/index.html",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "Quarto provides a unified authoring framework for data science, combining your code, its results, and your prose.\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.\n\n\n\n\n\n\n\nImportant\n\n\n\nQuarto is a command line interface tool, not an R package.\nThis means that help is, by-and-large, not available through ? in the R console.\nAnd not to add to the confusion, but there is an quarto R package that has helper functions for you to use in R to e.g. check the Quarto version installed, etc.\n\n\nFormally, Quarto is a publishing system built on Pandoc that allows users to create dynamic content using R, Python, Julia, and ObservableJS (with plans to add more languages too!).\n\n\n\nA schematic representing the multi-language input versatility of Quarto\n\n\n\n\nArt by Allison Horst. Be sure to check out the rest of Allison’s seriously cute Quarto penguin art in the #rstudioconf2022 keynote talk, Hello Quarto, by Julie Lowndes & Mine Çetinkaya-Rundel!\n\n\n\nYou need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed.\n\nhttps://quarto.org/docs/get-started\nhttps://formulae.brew.sh/cask/quarto (this is my preferred way using home brew)"
  },
  {
    "objectID": "readings/00-quarto/index.html#introduction",
    "href": "readings/00-quarto/index.html#introduction",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "Quarto provides a unified authoring framework for data science, combining your code, its results, and your prose.\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.\n\n\n\n\n\n\n\nImportant\n\n\n\nQuarto is a command line interface tool, not an R package.\nThis means that help is, by-and-large, not available through ? in the R console.\nAnd not to add to the confusion, but there is an quarto R package that has helper functions for you to use in R to e.g. check the Quarto version installed, etc.\n\n\nFormally, Quarto is a publishing system built on Pandoc that allows users to create dynamic content using R, Python, Julia, and ObservableJS (with plans to add more languages too!).\n\n\n\nA schematic representing the multi-language input versatility of Quarto\n\n\n\n\nArt by Allison Horst. Be sure to check out the rest of Allison’s seriously cute Quarto penguin art in the #rstudioconf2022 keynote talk, Hello Quarto, by Julie Lowndes & Mine Çetinkaya-Rundel!"
  },
  {
    "objectID": "readings/00-quarto/index.html#prerequisites",
    "href": "readings/00-quarto/index.html#prerequisites",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "You need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed.\n\nhttps://quarto.org/docs/get-started\nhttps://formulae.brew.sh/cask/quarto (this is my preferred way using home brew)"
  },
  {
    "objectID": "readings/00-quarto/index.html#qmd-files",
    "href": "readings/00-quarto/index.html#qmd-files",
    "title": "Authoring projects and websites with Quarto",
    "section": ".qmd files",
    "text": ".qmd files\nQuarto files end in a .qmd. This is short for quarto markdown.\n\n\n\n\n\n\nNote\n\n\n\nThese files are decoupled from RStudio IDE and there are plugins to work with .qmd files for\n\nVSCode\nJupyterLab\nRStudio\n\n\n\n\nRendering\nUse the  Render button in the RStudio IDE to render the file and preview the output with a single click or keyboard shortcut (⇧⌘K).\n\n\n\n\n\nIf you prefer to automatically render whenever you save, you can check the Render on Save option on the editor toolbar. The preview will update whenever you re-render the document. Side-by-side preview works for both HTML and PDF outputs.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDocuments can also be rendered from the R console via the quarto package:\n\n\nCode run in the R Console\n\ninstall.packages(\"quarto\")\nquarto::quarto_render(\"hello.qmd\")\n\nAnd documents can also be rendered from the command line:\n\n\nCode run in the command line\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles\n\n\n\n\nHow rendering works\nWhen you render a Quarto document, first knitr executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated is then processed by pandoc, which creates the finished format. The Render button encapsulates these actions and executes them in the right order for you.\n\n\n\n\n\nWhen rendering, Quarto generates a new file that contains selected text, code, and results from the .qmd file. The new file can be an HTML, PDF, MS Word document, presentation, website, book, interactive document, or other format.\n\n\n\nAuthoring\nIn the image below we can see the same document in the two modes of the RStudio editor:\n\nvisual (on the left)\nsource (on the right)\n\nRStudio’s visual editor offers an WYSIWYM authoring experience for markdown. For formatting (e.g. bolding text) you can use the toolbar, a keyboard shortcut (⌘B), or the markdown construct (**bold**).\nYou can toggle back and forth these two modes by clicking on Source and Visual in the editor toolbar (or using the keyboard shortcut ⌘⇧ F4).\n\n\n\n\n\n\n\nHow does multi-language support work?\n\n\n\n\n\n\nQuarto supports multiple languages\n\n\n\nThese languages include\n\nR\nPython\nJulia\nObservable javascript\n\nQuarto can also interchange between languages using Apache Arrow.\n\n\nThe idea behind how quarto supports multi-language code is that the code output is “frozen” after it is rendered.\nIn this way, code output is not recomputed, unless you want it to."
  },
  {
    "objectID": "readings/00-quarto/index.html#r-markdown-vs-quarto",
    "href": "readings/00-quarto/index.html#r-markdown-vs-quarto",
    "title": "Authoring projects and websites with Quarto",
    "section": "R Markdown vs Quarto",
    "text": "R Markdown vs Quarto\nSome high-level differences include\n\nStandardized YAML across formats\nDecoupled from RStudio\nMore consistent presentation across formats\nTab Panels\nCode Highlighting\n\n\nCode block options\nAnother noticeable difference are options for code blocks. Rather than being in the header of the code block, options are moved to within the code block using the #| (hash-pipe) for each line.\nThis is a code block for R Markdown:\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(tidytext)\n```\nThis is a code block for Quarto:\n```{r}\n#| label: \"setup\"\n#| include: false\nlibrary(tidyverse)\nlibrary(tidytext)\n```\n\n\nOutput Options\nThere are a wide variety of output options available for customizing output from executed code.\nAll of these options can be specified either\n\nglobally (in the document front-matter) or\nper code-block\n\nFor example, here’s a modification of the Python example to specify that we don’t want to “echo” the code into the output document:\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\nNote that we can override this option on a per code-block basis. For example:\n```{python}\n#| echo: true\n\nimport matplotlib.pyplot as plt\nplt.plot([1,2,3,4])\nplt.show()\n```\nCode block options available for customizing output include:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output (note that this implies that errors executing code will not halt processing of the document).\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\nHere’s a example with r code blocks and some of these additional options included:\n---\ntitle: \"Knitr Document\"\nexecute:\n  echo: false\n---\n\n```{r}\n#| warning: false\n\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)\n```\n\n```{r}\nsummary(airquality)\n```\n\n\n\n\n\n\nTip\n\n\n\nWhen using the Knitr engine, you can also use any of the available native options (e.g. collapse, tidy, comment, etc.).\nSee the Knitr options documentation for additional details. You can include these native options in option comment blocks as shown above, or on the same line as the {r} as shown in the Knitr documentation.\n\n\n\n\nMargin content\nYou can place content within the right margin of Quarto document. For example, here we use the .column-margin class to place an image in the margin:\n::: {.column-margin}\nWe know from *the first fundamental theorem of calculus* that for $x$ in $[a, b]$:\n\n$$\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).$$\n:::\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]\n\n\nMargin Figures\nFigures that you create using code blocks can be placed in the margin by using the column: margin code block option.\nIf the code produces more than one figure, each of the figures will be placed in the margin.\n\n```{r}\n#| label: fig-mtcars\n#| fig-cap: \"MPG vs horsepower, colored by transmission.\"\n#| column: margin\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\n```\n\n\n\n\n\n\n\n\nFigure 1: MPG vs horsepower, colored by transmission.\n\n\n\n\n\n\nMargin Tables\nYou an also place tables in the margin of your document by specifying column: margin.\n\n```{r}\n#| column: margin\nknitr::kable(\n  mtcars[1:6, 1:3]\n)\n```\n\n\n\n\n\n\nmpg\ncyl\ndisp\n\n\n\n\nMazda RX4\n21.0\n6\n160\n\n\nMazda RX4 Wag\n21.0\n6\n160\n\n\nDatsun 710\n22.8\n4\n108\n\n\nHornet 4 Drive\n21.4\n6\n258\n\n\nHornet Sportabout\n18.7\n8\n360\n\n\nValiant\n18.1\n6\n225\n\n\n\n\n\n\nCode line numbers\nIf you want to display line numbers alongside the code block, add the code-line-numbers option. For example:\nformat:\n  html:\n    code-line-numbers: true\nHere’s how a code block with line numbers would display throughout the document:\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\nYou can also enable line numbers for an individual code block using the code-line-numbers attribute.\n\n\nShould you switch to quarto?\n\nShould you switch to Quarto? Not necessarily. If you find R Markdown meets your need, you can definitely stay there. It is not imperative to switch. - Yihui Xie\n\n\n\nhttps://yihui.org/en/2022/04/quarto-r-markdown/"
  },
  {
    "objectID": "readings/00-quarto/index.html#project",
    "href": "readings/00-quarto/index.html#project",
    "title": "Authoring projects and websites with Quarto",
    "section": "Project",
    "text": "Project\nHere are the general steps for creating a Quarto project in RStudio:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the project"
  },
  {
    "objectID": "readings/00-quarto/index.html#website",
    "href": "readings/00-quarto/index.html#website",
    "title": "Authoring projects and websites with Quarto",
    "section": "Website",
    "text": "Website\nHere are the general steps for creating a Quarto website:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the website\nDeploy the website\n\n\n\n\n\n\n\nDeploying a website\n\n\n\nquarto publish can push and update a number of different kinds of webhosts. You will need credentials to publish to each of these.\nquarto publish gh-pages    # GitHub Pages\nquarto publish quarto-pub  # Quarto.pub \nquarto publish netlify     # Netlify\nquarto publish connect     # RStudio Connect"
  },
  {
    "objectID": "readings/00-quarto/index.html#freeze-results-and-avoid-recomputing",
    "href": "readings/00-quarto/index.html#freeze-results-and-avoid-recomputing",
    "title": "Authoring projects and websites with Quarto",
    "section": "Freeze Results and avoid recomputing",
    "text": "Freeze Results and avoid recomputing\nFreezing code output is generally used when you have either\n\nA large number of collaborators or\nMany computational documents created over a longer period of time\nA project with different types of file formats from different languages (e.g. .qmd, .ipynb, .Rmd)\n\nIn the above cases, it can be challenging to fully re-execute every document when you render the site.\nThis could be because some documents have esoteric or environment-specific requirements (e.g. require access/authentication to a data source) or due to general fragility of dependencies over time.\nUsing freeze ensures that you can always reproducibly render your site.\nThe computational results of documents executed with freeze are stored in the _freeze/ directory, and re-used when needed to fulfill document renders.\nYou should check the contents of _freeze/ into version control so that others rendering the project don’t need to reproduce your computational environment to render it in their environment.\n\n\n\n\n\n\nNote\n\n\n\nYou will still want to take care to fully re-render your project when things outside of source code change (e.g. input data).\nYou can remove previously frozen output by deleting the _freeze folder at the root of your project.\n\n\nFor example, consider the _quarto.yml file.\nOne argument in the file is the freeze option to denote that computational documents should never be re-rendered during a global project render, or alternatively only be re-rendered when their source file changes:\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n  \nexecute:\n  freeze: true  # never re-render during project render\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n\nexecute:\n  freeze: auto  # re-render only when source changes\n\n\n\n\n\n\nNote\n\n\n\nThe freeze option in the _quarto.yml file controls whether execution occurs during global project renders.\nIf you do an incremental render of either a single document or a project sub-directory then code is always executed. For example:\n\n\nTerminal\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles"
  },
  {
    "objectID": "readings/05-database-programming/index.html",
    "href": "readings/05-database-programming/index.html",
    "title": "Relational databases and SQL basics",
    "section": "",
    "text": "We will load them here before kicking off the lecture.\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RSQLite)\nlibrary(dbplyr)"
  },
  {
    "objectID": "readings/05-database-programming/index.html#languages",
    "href": "readings/05-database-programming/index.html#languages",
    "title": "Relational databases and SQL basics",
    "section": "Languages",
    "text": "Languages\nWe write queries in a language called Structured Query Language (SQL), which provides hundreds of different ways to analyze and recombine data.\nMany database managers understand SQL but each stores data in a different way, so a database created with one cannot be used directly by another.\nHowever, every database manager can import and export data in a variety of formats like .csv, .sql, so it is possible to move information from one to another.\nNext, we will some example SQL queries that are common tasks for data scientists."
  },
  {
    "objectID": "readings/05-database-programming/index.html#example-data",
    "href": "readings/05-database-programming/index.html#example-data",
    "title": "Relational databases and SQL basics",
    "section": "Example data",
    "text": "Example data\nBefore we get into using SQLite to select the data, let’s take a look at the tables of the database we will use in our examples:\n\n\nPerson: People who took readings, id being the unique identifier for that person.\n\n\n\nid\npersonal\nfamily\n\n\n\n\ndyer\nWilliam\nDyer\n\n\npb\nFrank\nPabodie\n\n\nlake\nAnderson\nLake\n\n\nroe\nValentina\nRoerich\n\n\ndanforth\nFrank\nDanforth\n\n\n\nSite: Locations of the sites where readings were taken.\n\n\n\nname\nlat\nlong\n\n\n\n\nDR-1\n-49.85\n-128.57\n\n\nDR-3\n-47.15\n-126.72\n\n\nMSK-4\n-48.87\n-123.4\n\n\n\nVisited: Specific identification id of the precise locations where readings were taken at the sites and dates.\n\n\n\nid\nsite\ndated\n\n\n\n\n619\nDR-1\n1927-02-08\n\n\n622\nDR-1\n1927-02-10\n\n\n734\nDR-3\n1930-01-07\n\n\n735\nDR-3\n1930-01-12\n\n\n751\nDR-3\n1930-02-26\n\n\n752\nDR-3\n-null-\n\n\n837\nMSK-4\n1932-01-14\n\n\n844\nDR-1\n1932-03-22\n\n\n\n\n\nSurvey: The measurements taken at each precise location on these sites. They are identified as taken. The field quant is short for quantity and indicates what is being measured. The values are rad, sal, and temp referring to ‘radiation’, ‘salinity’ and ‘temperature’, respectively.\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n619\ndyer\nrad\n9.82\n\n\n619\ndyer\nsal\n0.13\n\n\n622\ndyer\nrad\n7.8\n\n\n622\ndyer\nsal\n0.09\n\n\n734\npb\nrad\n8.41\n\n\n734\nlake\nsal\n0.05\n\n\n734\npb\ntemp\n-21.5\n\n\n735\npb\nrad\n7.22\n\n\n735\n-null-\nsal\n0.06\n\n\n735\n-null-\ntemp\n-26.0\n\n\n751\npb\nrad\n4.35\n\n\n751\npb\ntemp\n-18.5\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nrad\n2.19\n\n\n752\nlake\nsal\n0.09\n\n\n752\nlake\ntemp\n-16.0\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nrad\n1.46\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5\n\n\n844\nroe\nrad\n11.25"
  },
  {
    "objectID": "readings/05-database-programming/index.html#sql-.tables-and-.schema",
    "href": "readings/05-database-programming/index.html#sql-.tables-and-.schema",
    "title": "Relational databases and SQL basics",
    "section": "SQL .tables and .schema",
    "text": "SQL .tables and .schema\nIn an interactive sqlite3 session,\n\nType .tables to list the tables in the database\nType .schema to see the SQL statements used to create the tables in the database. The statements will have a list of the columns and the data types each column stores.\n\n\n\n\n\n\n\nMore about .schema\n\n\n\nThe output from .schema is formatted as &lt;columnName dataType&gt;.\n\n\nOutput\n\nCREATE TABLE Person (id text, personal text, family text);\nCREATE TABLE Site (name text, lat real, long real);\nCREATE TABLE Survey (taken integer, person text, quant text, reading real);\nCREATE TABLE Visited (id integer, site text, dated text);\n\nThus we can see from the first line that the table Person has three columns:\n\nid with type text\npersonal with type text\nfamily with type text\n\n\n\nThe available data types vary based on the database manager - you can search online for what data types are supported."
  },
  {
    "objectID": "readings/05-database-programming/index.html#more-about-select",
    "href": "readings/05-database-programming/index.html#more-about-select",
    "title": "Relational databases and SQL basics",
    "section": "More about SELECT",
    "text": "More about SELECT\nRow and columns in a database table are not actually stored in any particular order.\nThey will always be displayed in some order, but we can control that in various ways.\n\n\n\n\n\n\nExample\n\n\n\nWe could swap the columns in the output by writing our query as:\n\n\nSQL\n\nSELECT personal, family FROM Person;\n\n\n\nOutput\n\n|personal |family  |\n|---------|--------|\n|William  |Dyer    |\n|Frank    |Pabodie |\n|Anderson |Lake    |\n|Valentina|Roerich |\n|Frank    |Danforth|\n\nor even repeat columns:\n\n\nSQL\n\nSELECT id, id, id FROM Person;\n\n\n\nOutput\n\n|id      |id      |id      |\n|--------|--------|--------|\n|dyer    |dyer    |dyer    |\n|pb      |pb      |pb      |\n|lake    |lake    |lake    |\n|roe     |roe     |roe     |\n|danforth|danforth|danforth|\n\n\n\n\nThe * operator\nAs a shortcut, we can select all of the columns in a table using *:\n\n\nSQL\n\nSELECT * FROM Person;\n\n\n\nOutput\n\n|id      |personal |family  |\n|--------|---------|--------|\n|dyer    |William  |Dyer    |\n|pb      |Frank    |Pabodie |\n|lake    |Anderson |Lake    |\n|roe     |Valentina|Roerich |\n|danforth|Frank    |Danforth|"
  },
  {
    "objectID": "readings/05-database-programming/index.html#sorting-and-removing-duplicates",
    "href": "readings/05-database-programming/index.html#sorting-and-removing-duplicates",
    "title": "Relational databases and SQL basics",
    "section": "Sorting and removing duplicates",
    "text": "Sorting and removing duplicates\nIn this section, we will explore the following questions of the Antarctic data\n\nWhat are the unique types of measurements taken in Survey?\nWhich scientists took measurements on the expedition?\n\nTo answer the first question, we will extract the values in column quant (short for quantity) from Survey, which contains values rad, sal, and temp referring to ‘radiation’, ‘salinity’ and ‘temperature’, respectively.\nHowever, we only want the unique value labels.\nThe following will extract the quant column from the Survey table, but not return unique / distinct labels.\n\n\nSQL\n\nSELECT quant FROM Survey;\n\nBut, adding the DISTINCT keyword to our query eliminates the redundant output to make the result more readable:\n\n\nSQL\n\nSELECT DISTINCT quant FROM Survey;\n\n\n\nOutput\n\n|quant|\n|-----|\n|rad  |\n|sal  |\n|temp |\n\nYou can also use the DISTINCT keyword on multiple columns.\nIf we select more than one column, distinct sets of values are returned (in this case pairs, because we are selecting two columns) and duplicates are removed:\n\n\nSQL\n\nSELECT DISTINCT taken, quant FROM Survey;\n\n\n\nOutput\n\n|taken|quant|\n|-----|-----|\n|619  |rad  |\n|619  |sal  |\n|622  |rad  |\n|622  |sal  |\n|734  |rad  |\n|734  |sal  |\n|734  |temp |\n|735  |rad  |\n|735  |sal  |\n|735  |temp |\n|751  |rad  |\n|751  |temp |\n|751  |sal  |\n|752  |rad  |\n|752  |sal  |\n|752  |temp |\n|837  |rad  |\n|837  |sal  |\n|844  |rad  |\n\nNext, we will look at the Person table and sort the scientists names.\nDatabase records are not necessarily sorted in any particular order.\nIf you want to have the table returned sorted in a particular way, you add the ORDER BY clause to our query:\n\n\nSQL\n\nSELECT * FROM Person ORDER BY id;\n\n\n\nOutput\n\n|id     |personal |family  |\n|-------|---------|--------|\n|danfort|Frank    |Danforth|\n|dyer   |William  |Dyer    |\n|lake   |Anderson |Lake    |\n|pb     |Frank    |Pabodie |\n|roe    |Valentina|Roerich |\n\nThe default is to sort in an ascending order, but we can sort in a descending order using DESC (for “descending”):\n\n\nSQL\n\nSELECT * FROM person ORDER BY id DESC;\n\n\n\nOutput\n\n|id     |personal |family  |\n|-------|---------|--------|\n|roe    |Valentina|Roerich |\n|pb     |Frank    |Pabodie |\n|lake   |Anderson |Lake    |\n|dyer   |William  |Dyer    |\n|danfort|Frank    |Danforth|\n\n(And if we want to make it clear that we’re sorting in ascending order, we can use ASC instead of DESC.)\n\n\n\n\n\n\nExample\n\n\n\nLet’s look at which scientist (person) measured what quantities (quant) during each visit (taken) with the Survey table.\nWe also want to sort by two columns at once\n\nSort results first in ascending order by taken\nAnd then in descending order by person within each group of equal taken values:\n\n\n\nSQL\n\nSELECT taken, person, quant FROM Survey ORDER BY taken ASC, person DESC;\n\n\n\nOutput\n\n|taken|person|quant|\n|-----|------|-----|\n|619  |dyer  |rad  |\n|619  |dyer  |sal  |\n|622  |dyer  |rad  |\n|622  |dyer  |sal  |\n|734  |pb    |rad  |\n|734  |pb    |temp |\n|734  |lake  |sal  |\n|735  |pb    |rad  |\n|735  |-null-|sal  |\n|735  |-null-|temp |\n|751  |pb    |rad  |\n|751  |pb    |temp |\n|751  |lake  |sal  |\n|752  |roe   |sal  |\n|752  |lake  |rad  |\n|752  |lake  |sal  |\n|752  |lake  |temp |\n|837  |roe   |sal  |\n|837  |lake  |rad  |\n|837  |lake  |sal  |\n|844  |roe   |rad  |\n\nThis query gives us a good idea of which scientist was involved in which visit, and what measurements they performed during the visit.\n\n\nLooking at the table, it seems like some scientists specialized in certain kinds of measurements.\nWe can examine which scientists performed which measurements by selecting the appropriate columns and removing duplicates.\n\n\nSQL\n\nSELECT DISTINCT quant, person FROM Survey ORDER BY quant ASC;\n\n\n\nOutput\n\n|quant|person|\n|-----|------|\n|rad  |dyer  |\n|rad  |pb    |\n|rad  |lake  |\n|rad  |roe   |\n|sal  |dyer  |\n|sal  |lake  |\n|sal  |-null-|\n|sal  |roe   |\n|temp |pb    |\n|temp |-null-|\n|temp |lake  |"
  },
  {
    "objectID": "readings/05-database-programming/index.html#other-important-tasks",
    "href": "readings/05-database-programming/index.html#other-important-tasks",
    "title": "Relational databases and SQL basics",
    "section": "Other important tasks",
    "text": "Other important tasks\nThere are many other tasks you can do with SQL, but for purposes of the lecture, I will leave you to work through this carpentries tutorial if you want to know more:\n\nhttps://swcarpentry.github.io/sql-novice-survey\n\n\nFiltering\nHow can you select subsets of data? You use WHERE.\nHere is an example of filtering for all rows that contain “dyer” in the Person column.\n\n\nSQL\n\nSELECT * FROM Survey WHERE person = \"dyer\";\n\n\n\nOutput\n\n619|dyer|rad|9.82\n619|dyer|sal|0.13\n622|dyer|rad|7.8\n622|dyer|sal|0.09\n\nFor more information about filtering, read through this tutorial:\n\nhttps://swcarpentry.github.io/sql-novice-survey/03-filter\n\n\n\nAnd more\nThe carpentries tutorial has so much more including how to:\n\nCalculating new values (https://swcarpentry.github.io/sql-novice-survey/04-calc)\nHow to deal with missing data (https://swcarpentry.github.io/sql-novice-survey/05-null)\nHow to aggregate data to calculate summaries (https://swcarpentry.github.io/sql-novice-survey/06-agg)\nHow to write queries that joins together two tables (https://swcarpentry.github.io/sql-novice-survey/07-join)\nHow to create tables or modify exisiting data in tables (https://swcarpentry.github.io/sql-novice-survey/09-create)"
  },
  {
    "objectID": "readings/05-database-programming/index.html#connect-to-the-sql-database",
    "href": "readings/05-database-programming/index.html#connect-to-the-sql-database",
    "title": "Relational databases and SQL basics",
    "section": "Connect to the SQL database",
    "text": "Connect to the SQL database\nThe main workhorse packages that we will use are the DBI and RSQLite packages.\n\nDBI is an R package that connects R to database management systems (DBMS). DBI separates the connectivity to the DBMS into a “front-end” and a “back-end”. The package defines an interface that is implemented by DBI backends such as RPostgres, RMariaDB, RSQLite, odbc, bigrquery, and more!\nRSQLite is an R package that embeds the SQLite database engine in R, providing a DBI-compliant interface. SQLite is a public-domain, single-user, very light-weight database engine that implements a decent subset of the SQL 92 standard, including the core table creation, updating, insertion, and selection operations, plus transaction management."
  },
  {
    "objectID": "readings/05-database-programming/index.html#example-workflow",
    "href": "readings/05-database-programming/index.html#example-workflow",
    "title": "Relational databases and SQL basics",
    "section": "Example workflow",
    "text": "Example workflow\n\n\n\n\n\n\nExample\n\n\n\nHere’s a short R program that sorts the scientists names in a descending order from from an SQLite database stored in a file called survey.db:\n\nlibrary(RSQLite)\nconnection &lt;- dbConnect(drv = RSQLite::SQLite(), \n                        dbname = here::here(\"readings\",\"05-database-programming\", \"data\", \"survey.db\"))\nresults &lt;- dbGetQuery(connection, \"SELECT * FROM Person ORDER BY id DESC;\")\nprint(results)\n\n        id  personal   family\n1      roe Valentina  Roerich\n2       pb     Frank  Pabodie\n3     lake  Anderson     Lake\n4     dyer   William     Dyer\n5 danforth     Frank Danforth\n\ndbDisconnect(connection)\n\n\n\nLet’s break this down.\nThe program starts by importing the RSQLite library.\nIf we were connecting to MySQL, DB2, or some other database, we would import a different library, but all of them provide the same functions, so that the rest of our program does not have to change (at least, not much) if we switch from one database to another.\nLine 2 establishes a connection to the database.\nSince we’re using SQLite, all we need to specify is the name of the database file. Other systems may require us to provide a username and password as well.\nOn line 3, we retrieve the results from an SQL query.\nIt’s our job to make sure that SQL is properly formatted; if it isn’t, or if something goes wrong when it is being executed, the database will report an error.\nThis result is a data.frame with one row for each entry and one column for each column in the database.\nFinally, the last line closes our connection, since the database can only keep a limited number of these open at one time.\nSince establishing a connection takes time, though, we should not open a connection, do one operation, then close the connection, only to reopen it a few microseconds later to do another operation.\nInstead, it’s normal to create one connection that stays open for the lifetime of the program.\nQueries in real applications will often depend on values provided by users.\nFor example, this function takes a user’s ID as a parameter and returns only the rows with their ID:\n\nlibrary(RSQLite)\nconnection &lt;- dbConnect(drv = SQLite(), \n                        dbname = here::here(\"readings\",\"05-database-programming\", \"data\", \"survey.db\"))\n\ngetName &lt;- function(personID) {\n  query &lt;- paste0(\"SELECT * FROM Survey WHERE person ='\", \n                  personID, \"';\")\n  return(dbGetQuery(connection, query))\n}\n\ngetName(\"dyer\")\n\n  taken person quant reading\n1   619   dyer   rad    9.82\n2   619   dyer   sal    0.13\n3   622   dyer   rad    7.80\n4   622   dyer   sal    0.09\n\ndbDisconnect(connection)\n\nWe use string concatenation on the first line of this function to construct a query containing the user ID we have been given."
  },
  {
    "objectID": "readings/05-database-programming/index.html#database-helper-functions-in-r",
    "href": "readings/05-database-programming/index.html#database-helper-functions-in-r",
    "title": "Relational databases and SQL basics",
    "section": "Database helper functions in R",
    "text": "Database helper functions in R\nR’s database interface packages (like RSQLite) all share a common set of helper functions useful for exploring databases and reading/writing entire tables at once.\nTo view all tables in a database, we can use dbListTables():\n\nconnection &lt;- dbConnect(SQLite(), \n                        here::here(\"readings\", \"05-database-programming\", \"data\", \"survey.db\"))\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\"\n\n\nTo view all column names of a table, use dbListFields():\n\ndbListFields(connection, \"Survey\")\n\n[1] \"taken\"   \"person\"  \"quant\"   \"reading\"\n\n\nTo read an entire table as a dataframe, use dbReadTable():\n\ndbReadTable(connection, \"Person\")\n\n        id  personal   family\n1     dyer   William     Dyer\n2       pb     Frank  Pabodie\n3     lake  Anderson     Lake\n4      roe Valentina  Roerich\n5 danforth     Frank Danforth\n\n\nFinally, to write an entire table to a database, you can use dbWriteTable().\n\n\n\n\n\n\nNote\n\n\n\nWe will always want to use the row.names = FALSE argument or R will write the row names as a separate column.\n\n\n\ndbWriteTable(connection, \"iris\", iris, row.names = FALSE)\nhead(dbReadTable(connection, \"iris\"))\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nIn this example we will write R’s built-in iris dataset as a table in survey.db.\nWhich you can see here:\n\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\" \"iris\"   \n\n\nWe can remove iris as a table with dbRemoveTable() and check it’s been removed with dbListTables().\n\ndbRemoveTable(connection, \"iris\")\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\"\n\n\nAnd as always, remember to close the database connection when done!\n\ndbDisconnect(connection)"
  },
  {
    "objectID": "readings/05-database-programming/index.html#example-album-covers",
    "href": "readings/05-database-programming/index.html#example-album-covers",
    "title": "Relational databases and SQL basics",
    "section": "Example: album covers",
    "text": "Example: album covers\nWe will use the\n\nchinook sqlite database\n\nThe database represents a “digital media store, including tables for artists, albums, media tracks, invoices and customers”.\nFrom the Readme.md file:\n\nSample Data\nMedia related data was created using real data from an iTunes Library. … Customer and employee information was manually created using fictitious names, addresses that can be located on Google maps, and other well formatted data (phone, fax, email, etc.). Sales information is auto generated using random data for a four year period.\n\nThe data are saved in our /data folder:\n\nlibrary(here)\n\nhere() starts at /Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024\n\nlist.files(here(\"readings\", \"05-database-programming\", \"data\"))\n\n[1] \"Chinook.sqlite\" \"survey.db\""
  },
  {
    "objectID": "readings/05-database-programming/index.html#connect-to-the-sqlite-database",
    "href": "readings/05-database-programming/index.html#connect-to-the-sqlite-database",
    "title": "Relational databases and SQL basics",
    "section": "Connect to the SQLite database",
    "text": "Connect to the SQLite database\nLet’s connect to the Chinook.sqlite file\n\nconnection &lt;- dbConnect(SQLite(), \n                        here(\"readings\", \"05-database-programming\", \"data\", \"Chinook.sqlite\"))\n\nSo we have opened up a connection with the SQLite database. Next, we can see what tables are available in the database using the dbListTables() function:\n\ndbListTables(connection)\n\n [1] \"Album\"         \"Artist\"        \"Customer\"      \"Employee\"     \n [5] \"Genre\"         \"Invoice\"       \"InvoiceLine\"   \"MediaType\"    \n [9] \"Playlist\"      \"PlaylistTrack\" \"Track\"        \n\n\nI have shown you how to write SQL queries with dbGetQuery().\nAn alternative approach to interact with SQL databases is to leverage the dplyr framework.\n\n“The dplyr package now has a generalized SQL backend for talking to databases, and the new dbplyr package translates R code into database-specific variants. As of this writing, SQL variants are supported for the following databases: Oracle, Microsoft SQL Server, PostgreSQL, Amazon Redshift, Apache Hive, and Apache Impala. More will follow over time.\n\nSo if we want to query a SQL databse with dplyr, the benefit of using dbplyr is:\n\n“You can write your code in dplyr syntax, and dplyr will translate your code into SQL. There are several benefits to writing queries in dplyr syntax: you can keep the same consistent language both for R objects and database tables, no knowledge of SQL or the specific SQL variant is required, and you can take advantage of the fact that dplyr uses lazy evaluation.\n\nLet’s take a closer look at the conn database that we just connected to:\n\nlibrary(dbplyr)\nsrc_dbi(connection)\n\nsrc:  sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/readings/05-database-programming/data/Chinook.sqlite]\ntbls: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine,\n  MediaType, Playlist, PlaylistTrack, Track\n\n\nYou can think of the multiple tables similar to having multiple worksheets in a spreadsheet.\nLet’s try interacting with one."
  },
  {
    "objectID": "readings/05-database-programming/index.html#using-dplyr",
    "href": "readings/05-database-programming/index.html#using-dplyr",
    "title": "Relational databases and SQL basics",
    "section": "Using dplyr",
    "text": "Using dplyr\nFirst, let’s look at the first ten rows in the Album table using the tbl() function from dplyr:\n\ntbl(connection, \"Album\") %&gt;%\n  head(n=10)\n\n# Source:   SQL [10 x 3]\n# Database: sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/readings/05-database-programming/data/Chinook.sqlite]\n   AlbumId Title                                 ArtistId\n     &lt;int&gt; &lt;chr&gt;                                    &lt;int&gt;\n 1       1 For Those About To Rock We Salute You        1\n 2       2 Balls to the Wall                            2\n 3       3 Restless and Wild                            2\n 4       4 Let There Be Rock                            1\n 5       5 Big Ones                                     3\n 6       6 Jagged Little Pill                           4\n 7       7 Facelift                                     5\n 8       8 Warner 25 Anos                               6\n 9       9 Plays Metallica By Four Cellos               7\n10      10 Audioslave                                   8\n\n\nThe output looks just like a data.frame that we are familiar with. But it’s important to know that it’s not really a data frame. For example, what about if we use the dim() function?\n\ntbl(connection, \"Album\") %&gt;%\n  dim()\n\n[1] NA  3\n\n\nInteresting! We see that the number of rows returned is NA. This is because these functions are different than operating on datasets in memory (e.g. loading data into memory using read_csv()).\nInstead, dplyr communicates differently with a SQLite database.\nLet’s consider our example. If we were to use straight SQL, the following SQL query returns the first 10 rows from the Album table:\n\n\nSQL\n\nSELECT * FROM Album LIMIT 10;\n\n\n\nOutput\n\n1|For Those About To Rock We Salute You|1\n2|Balls to the Wall|2\n3|Restless and Wild|2\n4|Let There Be Rock|1\n5|Big Ones|3\n6|Jagged Little Pill|4\n7|Facelift|5\n8|Warner 25 Anos|6\n9|Plays Metallica By Four Cellos|7\n10|Audioslave|8\n\nIn the background, dplyr does the following:\n\ntranslates your R code into SQL\nsubmits it to the database\ntranslates the database’s response into an R data frame\n\nTo better understand the dplyr code, we can use the show_query() function:\n\nAlbum &lt;- tbl(connection, \"Album\")\nshow_query(head(Album, n = 10))\n\n&lt;SQL&gt;\nSELECT `Album`.*\nFROM `Album`\nLIMIT 10\n\n\nThis is nice because instead of having to write the SQL query our self, we can just use the dplyr and R syntax that we are used to.\nHowever, the downside is that dplyr never gets to see the full Album table. It only sends our query to the database, waits for a response and returns the query.\nHowever, in this way we can interact with large datasets!\nMany of the usual dplyr functions are available too:\n\nselect()\nfilter()\nsummarize()\n\nand many join functions.\nOk let’s try some of the functions out. First, let’s count how many albums each artist has made.\n\ntbl(connection, \"Album\") %&gt;%\n  group_by(ArtistId) %&gt;% \n  summarize(n = count(ArtistId)) %&gt;% \n  head(n=10)\n\n# Source:   SQL [10 x 2]\n# Database: sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/readings/05-database-programming/data/Chinook.sqlite]\n   ArtistId     n\n      &lt;int&gt; &lt;int&gt;\n 1        1     2\n 2        2     2\n 3        3     1\n 4        4     1\n 5        5     1\n 6        6     2\n 7        7     1\n 8        8     3\n 9        9     1\n10       10     1"
  },
  {
    "objectID": "readings/05-database-programming/index.html#data-viz",
    "href": "readings/05-database-programming/index.html#data-viz",
    "title": "Relational databases and SQL basics",
    "section": "data viz",
    "text": "data viz\nNext, let’s plot it.\n\ntbl(connection, \"Album\") %&gt;%\n  group_by(ArtistId) %&gt;% \n  summarize(n = count(ArtistId)) %&gt;% \n  arrange(desc(n)) %&gt;% \n  ggplot(aes(x = ArtistId, y = n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nLet’s also extract the first letter from each album and plot the frequency of each letter.\n\ntbl(connection, \"Album\") %&gt;%\n  mutate(first_letter = str_sub(Title, end = 1)) %&gt;% \n  ggplot(aes(first_letter)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nIf you decide to make an album, you should try picking a less frequently used letter like E, J, K, Q, U, W, or Z!"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html",
    "href": "readings/04-data-collection-html/index.html",
    "title": "Scraping data from the web with rvest",
    "section": "",
    "text": "Material for this lecture was borrowed and adopted from\n\nhttps://rvest.tidyverse.org\n\n\n\n\nBefore we begin, you will need to install the rvest package\n\ninstall.packages(\"rvest\")\n\nNow we load a few R packages\n\nlibrary(tidyverse)\nlibrary(rvest)"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#html-basics",
    "href": "readings/04-data-collection-html/index.html#html-basics",
    "title": "Scraping data from the web with rvest",
    "section": "HTML basics",
    "text": "HTML basics\nHTML stands for “HyperText Markup Language” and looks like this:\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Page title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='first'&gt;A heading&lt;/h1&gt;\n  &lt;p&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\nHTML has a hierarchical structure formed by elements which consist of a start tag (e.g. &lt;tag&gt;), optional attributes (id='first'), an end tag (like &lt;/tag&gt;), and contents (everything in between the start and end tag).\n\n\n\n\n\n\nNote\n\n\n\nA number of tags (including &lt;p&gt; and &lt;li&gt;) don’t require end tags, but I think it’s best to include them because it makes seeing the structure of the HTML a little easier.\n\n\n\nElements\nAll up, there are over 100 HTML elements. Some of the most important are:\n\nEvery HTML page must be must be in an &lt;html&gt; element, and it must have two children:\n\n&lt;head&gt;, which contains document metadata like the page title\n&lt;body&gt;, which contains the content you see in the browser\n\nBlock tags like &lt;h1&gt; (heading 1), &lt;p&gt; (paragraph), and &lt;ol&gt; (ordered list) form the overall structure of the page.\nInline tags like &lt;b&gt; (bold), &lt;i&gt; (italics), and &lt;a&gt; (links) formats text inside block tags.\n\nIf you encounter a tag that you have never seen before, you can find out what it does with a little googling.\nI recommend the MDN Web Docs which are produced by Mozilla, the company that makes the Firefox web browser.\n\n\nContents\nMost elements can have content in between their start and end tags. This content can either be text or more elements. For example, the following HTML contains paragraph of text, with one word in bold.\n&lt;p&gt;\n  Hi! My &lt;b&gt;name&lt;/b&gt; is Stephanie.\n&lt;/p&gt;\nThe children of a node refers only to elements, so the &lt;p&gt; element above has one child, the &lt;b&gt; element. The &lt;b&gt; element has no children, but it does have contents (the text “name”).\nSome elements, like &lt;img&gt; can’t have children. These elements depend solely on attributes for their behavior.\n\n\nAttributes\nTags can have named attributes which look like name1='value1' name2='value2'.\nTwo of the most important attributes are id and class, which are used in conjunction with CSS (Cascading Style Sheets) to control the visual appearance of the page.\nThese are often useful when scraping data off a page."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#reading-html-with-rvest",
    "href": "readings/04-data-collection-html/index.html#reading-html-with-rvest",
    "title": "Scraping data from the web with rvest",
    "section": "Reading HTML with rvest",
    "text": "Reading HTML with rvest\nYou will usually start the scraping process with read_html(). This returns a xml_document object which you will then manipulate using rvest functions:\n\n\n\n\n\n\nNote\n\n\n\nThis xml_document class comes from the xml2 package, which is a low-level package that rvest builds on top of.\n\n\n\nhtml &lt;- read_html(\"http://rvest.tidyverse.org/\")\nclass(html)\n\n[1] \"xml_document\" \"xml_node\"    \n\n\nFor examples and experimentation, rvest also includes a function (minimal_html()) that lets you create an xml_document from literal HTML:\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;This is a paragraph&lt;p&gt;\n  &lt;ul&gt;\n    &lt;li&gt;This is a bulleted list&lt;/li&gt;\n  &lt;/ul&gt;\n\")\nclass(html)\n\n[1] \"xml_document\" \"xml_node\"    \n\nhtml\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n&lt;p&gt;This is a paragraph&lt;/p&gt;\\n&lt;p&gt;\\n  &lt;/p&gt;\\n&lt;ul&gt;\\n&lt;li&gt;This is a bull ...\n\n\nRegardless of how you get the HTML, you will need some way to identify the elements that contain the data you care about.\nrvest provides two options:\n\nCSS selectors\nXPath expressions\n\nHere I will focus on CSS selectors because they are simpler, but still sufficiently powerful for most scraping tasks."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#css-selectors",
    "href": "readings/04-data-collection-html/index.html#css-selectors",
    "title": "Scraping data from the web with rvest",
    "section": "CSS selectors",
    "text": "CSS selectors\nCSS is short for cascading style sheets, and is a tool for defining the visual styling of HTML documents.\nCSS includes a miniature language for selecting elements on a page called CSS selectors.\nCSS selectors define patterns for locating HTML elements, and are useful for scraping because they provide a concise way of describing which elements you want to extract.\nCSS selectors can be quite complex, but fortunately you only need the simplest for rvest, because you can also write R code for more complicated situations.\nThe four most important selectors are:\n\np: selects all &lt;p&gt; elements.\n.title: selects all elements with class “title”.\np.special: selects all &lt;p&gt; elements with class “special”.\n#title: selects the element with the id attribute that equals “title”. Id attributes must be unique within a document, so this will only ever select a single element.\n\nIf you want to learn more CSS selectors, I recommend starting with the fun CSS dinner tutorial and then referring to the MDN web docs.\nLets try out the most important selectors with a simple example:\n\nhtml &lt;- minimal_html(\"\n  &lt;h1&gt;This is a heading&lt;/h1&gt;\n  &lt;p id='first'&gt;This is a paragraph&lt;/p&gt;\n  &lt;p class='important'&gt;This is an important paragraph&lt;/p&gt;\n\")\n\nIn rvest you can extract\n\na single element with html_element() or\nall matching elements with html_elements()\n\nBoth functions take a document (or another element) and a css selector:\n\nhtml %&gt;% html_elements(\"h1\")\n\n{xml_nodeset (1)}\n[1] &lt;h1&gt;This is a heading&lt;/h1&gt;\n\nhtml %&gt;% html_elements(\"p\")\n\n{xml_nodeset (2)}\n[1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n[2] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\n\nhtml %&gt;% html_elements(\".important\")\n\n{xml_nodeset (1)}\n[1] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\n\nhtml %&gt;% html_elements(\"#first\")\n\n{xml_nodeset (1)}\n[1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nIf you don’t know exactly what selector you need, I highly recommend using SelectorGadget, which lets you automatically generate the selector you need by supplying positive and negative examples in the browser"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#extracting-data",
    "href": "readings/04-data-collection-html/index.html#extracting-data",
    "title": "Scraping data from the web with rvest",
    "section": "Extracting data",
    "text": "Extracting data\nNow that you have got the elements you care about, you will need to get data out of them.\nYou will usually get the data from either the text contents or an attribute. But, sometimes (if you’re lucky!), the data you need will be in an HTML table.\n\nText\nUse html_text2() to extract the plain text contents of an HTML element:\n\nhtml &lt;- minimal_html(\"\n  &lt;ol&gt;\n    &lt;li&gt;apple &amp; pear&lt;/li&gt;\n    &lt;li&gt;banana&lt;/li&gt;\n    &lt;li&gt;pineapple&lt;/li&gt;\n  &lt;/ol&gt;\n\")\nhtml %&gt;% \n  html_elements(\"li\") %&gt;% \n  html_text2()\n\n[1] \"apple & pear\" \"banana\"       \"pineapple\"   \n\n\nNote that the escaped ampersand is automatically converted to &; you will only ever see HTML escapes in the source HTML, not in the data returned by rvest.\nYou might wonder why I used html_text2(), since it seems to give the same result as html_text():\n\nhtml %&gt;% \n  html_elements(\"li\") %&gt;% \n  html_text()\n\n[1] \"apple & pear\" \"banana\"       \"pineapple\"   \n\n\nThe main difference is how the two functions handle white space.\nIn HTML, white space is largely ignored, and it is the structure of the elements that defines how text is laid out.\nhtml_text2() does its best to follow the same rules, giving you something similar to what you’d see in the browser. Take this example which contains a bunch of white space that HTML ignores.\n\nhtml &lt;- minimal_html(\"&lt;body&gt;\n  &lt;p&gt;\n  This is\n  a\n  paragraph.&lt;/p&gt;&lt;p&gt;This is another paragraph.\n  \n  It has two sentences.&lt;/p&gt;\n\")\n\nhtml_text2() gives you what you expect: two paragraphs of text separated by a blank line.\n\nhtml %&gt;% \n  html_element(\"body\") %&gt;% \n  html_text2() %&gt;% \n  cat()\n\nThis is a paragraph.\n\nThis is another paragraph. It has two sentences.\n\n\nWhereas html_text() returns the garbled raw underlying text:\n\nhtml %&gt;% \n  html_element(\"body\") %&gt;% \n  html_text() %&gt;% \n  cat()\n\n\n  \n  This is\n  a\n  paragraph.This is another paragraph.\n  \n  It has two sentences.\n\n\n\n\nAttributes\nAttributes are used to record the destination of links (the href attribute of &lt;a&gt; elements) and the source of images (the src attribute of the &lt;img&gt; element):\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Cat'&gt;cats&lt;/a&gt;&lt;/p&gt;\n  &lt;img src='https://cataas.com/cat' width='100' height='200'&gt;\n\")\n\nThe value of an attribute can be retrieved with html_attr():\n\nhtml %&gt;% \n  html_elements(\"a\") %&gt;% \n  html_attr(\"href\")\n\n[1] \"https://en.wikipedia.org/wiki/Cat\"\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"src\")\n\n[1] \"https://cataas.com/cat\"\n\n\nNote that html_attr() always returns a string, so you may need to post-process with as.integer()/readr::parse_integer() or similar.\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"width\")\n\n[1] \"100\"\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"width\") %&gt;% \n  as.integer()\n\n[1] 100\n\n\n\n\nTables\nHTML tables are composed four main elements:\n\n&lt;table&gt;\n&lt;tr&gt; (table row)\n&lt;th&gt; (table heading)\nand &lt;td&gt; (table data)\n\nHere’s a simple HTML table with two columns and three rows:\n\nhtml &lt;- minimal_html(\"\n  &lt;table&gt;\n    &lt;tr&gt;\n      &lt;th&gt;x&lt;/th&gt;\n      &lt;th&gt;y&lt;/th&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;1.5&lt;/td&gt;\n      &lt;td&gt;2.7&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;4.9&lt;/td&gt;\n      &lt;td&gt;1.3&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;7.2&lt;/td&gt;\n      &lt;td&gt;8.1&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/table&gt;\n  \")\n\nBecause tables are a common way to store data, rvest includes the handy html_table() which converts a table into a data frame:\n\nhtml %&gt;% \n  html_node(\"table\") %&gt;% \n  html_table()\n\n# A tibble: 3 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1   1.5   2.7\n2   4.9   1.3\n3   7.2   8.1"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#element-vs-elements",
    "href": "readings/04-data-collection-html/index.html#element-vs-elements",
    "title": "Scraping data from the web with rvest",
    "section": "Element vs elements",
    "text": "Element vs elements\nWhen using rvest, your eventual goal is usually to build up a data frame, and you want each row to correspond some repeated unit on the HTML page.\nIn this case, you should generally\n\nstart by using html_elements() to select the elements that contain each observation\nthen, use html_element() to extract the variables from each observation\n\nThis guarantees that you will get the same number of values for each variable because html_element() always returns the same number of outputs as inputs.\nTo illustrate this problem take a look at this simple example I constructed using a few entries from dplyr::starwars:\n\nhtml &lt;- minimal_html(\"\n  &lt;ul&gt;\n    &lt;li&gt;&lt;b&gt;C-3PO&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;167 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R2-D2&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;96 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;Yoda&lt;/b&gt; weighs &lt;span class='weight'&gt;66 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R4-P17&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n  \")\n\nIf you try to extract name, species, and weight directly, you end up with one vector of length four and two vectors of length three, and no way to align them:\n\nhtml %&gt;% html_elements(\"b\") %&gt;% html_text2()\n\n[1] \"C-3PO\"  \"R2-D2\"  \"Yoda\"   \"R4-P17\"\n\nhtml %&gt;% html_elements(\"i\") %&gt;% html_text2()\n\n[1] \"droid\" \"droid\" \"droid\"\n\nhtml %&gt;% html_elements(\".weight\") %&gt;% html_text2()\n\n[1] \"167 kg\" \"96 kg\"  \"66 kg\" \n\n\nInstead, use html_elements() to find a element that corresponds to each character, then use html_element() to extract each variable for all observations:\n\ncharacters &lt;- html %&gt;% html_elements(\"li\")\n\ncharacters %&gt;% html_element(\"b\") %&gt;% html_text2()\n\n[1] \"C-3PO\"  \"R2-D2\"  \"Yoda\"   \"R4-P17\"\n\ncharacters %&gt;% html_element(\"i\") %&gt;% html_text2()\n\n[1] \"droid\" \"droid\" NA      \"droid\"\n\ncharacters %&gt;% html_element(\".weight\") %&gt;% html_text2()\n\n[1] \"167 kg\" \"96 kg\"  \"66 kg\"  NA      \n\n\nhtml_element() automatically fills in NA when no elements match, keeping all of the variables aligned and making it easy to create a data frame:\n\ndata.frame(\n  name = characters %&gt;% html_element(\"b\") %&gt;% html_text2(),\n  species = characters %&gt;% html_element(\"i\") %&gt;% html_text2(),\n  weight = characters %&gt;% html_element(\".weight\") %&gt;% html_text2()\n)\n\n    name species weight\n1  C-3PO   droid 167 kg\n2  R2-D2   droid  96 kg\n3   Yoda    &lt;NA&gt;  66 kg\n4 R4-P17   droid   &lt;NA&gt;"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#installation",
    "href": "readings/04-data-collection-html/index.html#installation",
    "title": "Scraping data from the web with rvest",
    "section": "Installation",
    "text": "Installation\nTo install it, open this page in your browser, and then drag the following link to your bookmark bar: SelectorGadget."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#use",
    "href": "readings/04-data-collection-html/index.html#use",
    "title": "Scraping data from the web with rvest",
    "section": "Use",
    "text": "Use\nTo use it, open the page you want to scrape, then:\n\nClick the SelectorGadget entry in your bookmark bar.\nClick on the element you want to select. SelectorGadget will make a first guess at what css selector you want. It’s likely to be bad since it only has one example to learn from, but it’s a start. Elements that match the selector will be highlighted in yellow.\nClick on elements that should not be selected. They will turn red. Click on elements that should be selected. They will turn green.\nIterate until only the elements you want are selected. SelectorGadget is not perfect and sometimes will not be able to find a useful css selector. Sometimes starting from a different element helps."
  }
]
[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Location: In person for Fall 2024\nCourse time: Tuesdays and Thursdays from 1:30-2:50pm (Eastern Daylight Time zone)\nCourse location: W4030\nAssignments: Four projects\n\n\n\n\nStephanie C. Hicks (https://www.stephaniehicks.com)\n\nOffice Location: E3545, Wolfe Street building\nEmail: shicks19@jhu.edu\n\n\nI am an Associate Professor in the Department of Biostatistics at the Bloomberg School of Public Health and Department of Biomedical Engineering in the Whiting School of Engineering at Johns Hopkins University, a faculty member of the Johns Hopkins Data Science Lab, and have affiliations with the Malone Center for Engineering in Healthcare, Center for Computational Biology, the Department of Genetic Medicine, and the Department of Biochemistry and Molecular Biology.\nMy research focuses on developing fast, scalable, statistical methodology and open-source software for genomics and biomedical data analysis for human health and disease. My research is problem-forward: I develop statistical methods and software that are motivated by concrete problems, often with real-world, noisy, messy data. I’m also interested in developing theory for how to incorporate design thinking (alongside statistical thinking) in practice of data analysis.\nIf you want, you can find me on Twitter. I’m also a co-host of the The Corresponding Author podcast, member of the Editorial Board for Genome Biology, an Associate Editor for Reproducibility at the Journal of the American Statistical Association, and co-founder of R-Ladies Baltimore.\n\n\n\nJoe Sartini (jsartin1@jhu.edu) is a third year Ph.D. student in Biostatistics, with interest in models for precision medicine applications. Currently, the focus of his work is extracting meaningful insights from time-series produced by Continuous Glucose Monitoring and other devices worn by Type 2 diabetics. Outside of research, he enjoys participating in endurance sports and weightlifting.\nAngela Zhao (azhao29@jh.edu) is a second year ScM student in Biostatistics interested in functional data analysis and stochastic models. Her main projects involve using physical activity data derived from wearable devices to predict time-to-event outcomes. For leisure, she enjoys bouldering and stand-up comedy.\nInstructor and TA office hours are announced on CoursePlus. If there are conflicts and/or need to cancel office hours, announcements will be made on CoursePlus.\n\n\n\n\nCourse website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023\n\n\n\n\nUpon successfully completing this course, students will be able to:\n\nWrite unix code with command-line tools\nInstall and configure software necessary for a statistical programming environment and with version control\nWrite code for advanced programming topics in R, Python, SQL, and tidyverse\nBuild and organize a software package with documentation for publishing on the internet\nWrite code using functional or other programming paradigms and discuss strategies for getting data from APIs or working with large data\nBuild an interactive web application using Shiny or other dashboard tools"
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus",
    "section": "",
    "text": "Stephanie C. Hicks (https://www.stephaniehicks.com)\n\nOffice Location: E3545, Wolfe Street building\nEmail: shicks19@jhu.edu\n\n\nI am an Associate Professor in the Department of Biostatistics at the Bloomberg School of Public Health and Department of Biomedical Engineering in the Whiting School of Engineering at Johns Hopkins University, a faculty member of the Johns Hopkins Data Science Lab, and have affiliations with the Malone Center for Engineering in Healthcare, Center for Computational Biology, the Department of Genetic Medicine, and the Department of Biochemistry and Molecular Biology.\nMy research focuses on developing fast, scalable, statistical methodology and open-source software for genomics and biomedical data analysis for human health and disease. My research is problem-forward: I develop statistical methods and software that are motivated by concrete problems, often with real-world, noisy, messy data. I’m also interested in developing theory for how to incorporate design thinking (alongside statistical thinking) in practice of data analysis.\nIf you want, you can find me on Twitter. I’m also a co-host of the The Corresponding Author podcast, member of the Editorial Board for Genome Biology, an Associate Editor for Reproducibility at the Journal of the American Statistical Association, and co-founder of R-Ladies Baltimore."
  },
  {
    "objectID": "syllabus.html#teaching-assistants",
    "href": "syllabus.html#teaching-assistants",
    "title": "Syllabus",
    "section": "",
    "text": "Joe Sartini (jsartin1@jhu.edu) is a third year Ph.D. student in Biostatistics, with interest in models for precision medicine applications. Currently, the focus of his work is extracting meaningful insights from time-series produced by Continuous Glucose Monitoring and other devices worn by Type 2 diabetics. Outside of research, he enjoys participating in endurance sports and weightlifting.\nAngela Zhao (azhao29@jh.edu) is a second year ScM student in Biostatistics interested in functional data analysis and stochastic models. Her main projects involve using physical activity data derived from wearable devices to predict time-to-event outcomes. For leisure, she enjoys bouldering and stand-up comedy.\nInstructor and TA office hours are announced on CoursePlus. If there are conflicts and/or need to cancel office hours, announcements will be made on CoursePlus."
  },
  {
    "objectID": "syllabus.html#important-links",
    "href": "syllabus.html#important-links",
    "title": "Syllabus",
    "section": "",
    "text": "Course website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023"
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "",
    "text": "Upon successfully completing this course, students will be able to:\n\nWrite unix code with command-line tools\nInstall and configure software necessary for a statistical programming environment and with version control\nWrite code for advanced programming topics in R, Python, SQL, and tidyverse\nBuild and organize a software package with documentation for publishing on the internet\nWrite code using functional or other programming paradigms and discuss strategies for getting data from APIs or working with large data\nBuild an interactive web application using Shiny or other dashboard tools"
  },
  {
    "objectID": "syllabus.html#courseplus",
    "href": "syllabus.html#courseplus",
    "title": "Syllabus",
    "section": "Courseplus",
    "text": "Courseplus\nThe primary communication for the class will go through Courseplus. That is where we will post course announcements, share resources, host most of our asynchronous course discussion, and as the primary means of communication between course participants and course instructors\n\n\n\n\n\n\nImportant\n\n\n\nIf you are registered for the course, you should have access to Courseplus now. Once you have access you will also be able to find all material and dates/times of drop-in hours. Any zoom links will be posted on Courseplus.\n\n\nThe course will make use of the CoursePlus Discussion Forum in order to ask and answer questions regarding any of the course materials. The Instructor and the Teaching Assistant will monitor the discussion boards and answer questions when appropriate."
  },
  {
    "objectID": "syllabus.html#github",
    "href": "syllabus.html#github",
    "title": "Syllabus",
    "section": "GitHub",
    "text": "GitHub\nYou can access all course materials (e.g. lectures, project assignments) here\n\nCourse website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023"
  },
  {
    "objectID": "syllabus.html#lectures",
    "href": "syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nThis is course has only one section ending in .01, which means it is an Onsite Synchronous course. This means you are expected to attend class in person. While, I will record the lectures via a zoom recording, I do not plan to post the recordings on CoursePlus. If you have an unexpected / emergency event that comes up and you are unable to attend the lecture in person, you can email me to ask for the recording. I just ask that you briefly provide 1 sentence explanation.\nAttendance is not taken, but I strongly encourage you to attend class to ask questions and participate in class exercises. You will get as much out of the course as you put into it."
  },
  {
    "objectID": "syllabus.html#getting-help",
    "href": "syllabus.html#getting-help",
    "title": "Syllabus",
    "section": "Getting help",
    "text": "Getting help\nIn order of preference, here is a preferred list of ways to get help:\n\nWe strongly encourage you to use Courseplus to ask questions first, before joining office hours. The reason for this is so that other students in the class (who likely have similar questions) can also benefit from the questions and answers asked by your colleagues.\nYou are welcome to join office hours to get more group interactive feedback.\nIf you are not able to make the office hours, appointments can be made by email with the instructor."
  },
  {
    "objectID": "syllabus.html#textbook-and-other-course-material",
    "href": "syllabus.html#textbook-and-other-course-material",
    "title": "Syllabus",
    "section": "Textbook and Other Course Material",
    "text": "Textbook and Other Course Material\nThere is no required textbook. We will make use of several freely available textbooks and other materials. All course materials will be provided. We will use the R and Python software for data analysis, which is freely available for download."
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus",
    "section": "Software",
    "text": "Software\nWe will make heavy use of R in this course, so you should have R installed. You can obtain R from the Comprehensive R Archive Network. There are versions available for Mac, Windows, and Unix/Linux. This software is required for this course.\nIt is important that you have the latest version of R installed. For this course we will be using R version 4.4.1. You can determine what version of R you have by starting up R and typing into the console R.version.string and hitting the return/enter key. If you do not have this version of R installed, go to CRAN and download and install the latest version.\nWe will also make use of the RStudio interactive development environment (IDE). RStudio requires that R be installed, and so is an “add-on” to R. You can obtain the RStudio Desktop for free from the RStudio web site. In particular, we will make heavy use of it when developing R packages. It is also essential that you have the latest release of RStudio. You can determine the version of RStudio by looking at menu item Help &gt; About RStudio. You should be using RStudio version 2023.09.1+494 (2023.09.1+494) or higher, which requires R version 3.3.0 or higher."
  },
  {
    "objectID": "syllabus.html#projects",
    "href": "syllabus.html#projects",
    "title": "Syllabus",
    "section": "Projects",
    "text": "Projects\nThere will be 4 assignments, due every 2–3 weeks. Projects will be submitted electronically via the Drop Box on the CoursePlus web site (unless otherwise specified).\nThe project assignments will be due on\n\nProject 1: Friday November 10, 11:59pm\nProject 2: Tuesday November 28, 11:59pm\nProject 3: Tuesday December 12, 11:59pm\nProject 4: Friday December 22, 11:59pm\n\n\nProject collaboration\nPlease feel free to study together and talk to one another about project assignments. The mutual instruction that students give each other is among the most valuable that can be achieved.\nHowever, it is expected that project assignments will be implemented and written up independently unless otherwise specified. Specifically, please do not share analytic code or output. Please do not collaborate on write-up and interpretation. Please do not access or use solutions from any source before your project assignment is submitted for grading."
  },
  {
    "objectID": "syllabus.html#exams",
    "href": "syllabus.html#exams",
    "title": "Syllabus",
    "section": "Exams",
    "text": "Exams\nThere are no exams in this course."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nGrades in the course will be based on Projects 1–4. Grades for the projects and the final grade will be issued via the CoursePlus grade book.\n\nRelative weights\nThe grades are based on four projects. The breakdown of grading will be\n\n25% for Project 1\n25% for Project 2\n25% for Project 3\n25% for Project 4"
  },
  {
    "objectID": "syllabus.html#policy-for-submitted-projects-late",
    "href": "syllabus.html#policy-for-submitted-projects-late",
    "title": "Syllabus",
    "section": "Policy for submitted projects late",
    "text": "Policy for submitted projects late\n\n\n\n\n\n\nImportant\n\n\n\nThe instructor and TA(s) will not accept email late day policy requests.\n\n\nThis is the policy for late submissions that applies to Projects 1-4.\n\nEach student will be given three “free late days” for the rest of the course.\nA late day extends the individual project deadline by 24 hours without penalty.\nThe late days can be applied to just one project (e.g. two late days for Project 2), or they can be split across the two projects (one late day for Project 2 and one late day for Project 3). This is entirely left up to the discretion of the student.\nA max of two “free late days” can be applied to any one project.\nFree late days are intended to give you flexibility: you can use them for any reason no questions asked.\nYou do not get any bonus points for not using your late days.\n\nAlthough the each student is only given a total of three “free late days”, we will be accepting homework from students that pass this limit.\n\nWe will deduct 5% off the 100% starting point for each day the assignment is late.\nIf you use two “free late days” for project, but need a 3rd day, there will be no penalty for the first two late days and there will be a 5% penalty for the 3rd late day.\nIf you do not have any more late days for the term, we will deduct 5% for the assignment that is &lt;24 hours late, 10% points for the assignment that is 24-48 hours late, and 15% points for the assignment that is 48-72 hours late.\n\n\n\n\n\n\n\nImportant\n\n\n\nWe will not grade assignments that are more than 3 days (or more than 72 hours) past the original due date.\n\n\n\nRegrading Policy\nIt is very important to us that all assignments are properly graded. If you believe there is an error in your assignment grading, please send an email to the instructor within 7 days of receiving the grade. No re-grade requests will be accepted orally, and no regrade requests will be accepted more than 7 days after you receive the grade for the assignment."
  },
  {
    "objectID": "syllabus.html#use-of-ai-tools",
    "href": "syllabus.html#use-of-ai-tools",
    "title": "Syllabus",
    "section": "Use of AI tools",
    "text": "Use of AI tools\nUse of AI tools (including ChatGPT, Bard, Microsoft Copilot, etc) to assist in completing this assignment/exam is permitted with your writing and/or programming. Be aware, however, that such tools often introduce errors or fabricate information; it is your responsibility to ensure the factual accuracy of whatever you claim as your writing/code. I recommend using such tools particularly for learning to code, just make sure the code does what it is supposed to, and that you understand what the code does.\nWith respect to writing, as with all sources, proper references and use of quotation marks should be used (if precise language generated by the software is used). The reference must include the website and specific prompts used to generate the referenced output."
  },
  {
    "objectID": "syllabus.html#academic-ethics-and-student-conduct-code",
    "href": "syllabus.html#academic-ethics-and-student-conduct-code",
    "title": "Syllabus",
    "section": "Academic Ethics and Student Conduct Code",
    "text": "Academic Ethics and Student Conduct Code\nStudents enrolled in the Bloomberg School of Public Health of The Johns Hopkins University assume an obligation to conduct themselves in a manner appropriate to the University’s mission as an institution of higher education. A student is obligated to refrain from acts which he or she knows, or under the circumstances has reason to know, impair the academic integrity of the University. Violations of academic integrity include, but are not limited to: cheating; plagiarism; knowingly furnishing false information to any agent of the University for inclusion in the academic record; violation of the rights and welfare of animal or human subjects in research; and misconduct as a member of either School or University committees or recognized groups or organizations.\nStudents should be familiar with the policies and procedures specified under Policy and Procedure Manual Student-01 (Academic Ethics), available on the school’s portal.\nThe faculty, staff and students of the Bloomberg School of Public Health and the Johns Hopkins University have the shared responsibility to conduct themselves in a manner that upholds the law and respects the rights of others. Students enrolled in the School are subject to the Student Conduct Code (detailed in Policy and Procedure Manual Student-06) and assume an obligation to conduct themselves in a manner which upholds the law and respects the rights of others. They are responsible for maintaining the academic integrity of the institution and for preserving an environment conducive to the safe pursuit of the School’s educational, research, and professional practice missions.\n\nCourse code of Conduct\nWe are committed to providing a welcoming, inclusive, and harassment-free experience for everyone, regardless of gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion (or lack thereof), political beliefs/leanings, or technology choices. We do not tolerate harassment of course participants in any form. Sexual language and imagery is not appropriate for any work event, including group meetings, conferences, talks, parties, Twitter and other online media. This code of conduct applies to all course participants, including instructors and TAs, and applies to all modes of interaction, both in-person and online, including GitHub project repos, Slack channels, and Twitter.\nCourse participants violating these rules will be referred to leadership of the Department of Biostatistics and the Title IX coordinator at JHU and may face expulsion from the class.\nAll class participants agree to:\n\nBe considerate in speech and actions, and actively seek to acknowledge and respect the boundaries of other members.\nBe respectful. Disagreements happen, but do not require poor behavior or poor manners. Frustration is inevitable, but it should never turn into a personal attack. A community where people feel uncomfortable or threatened is not a productive one. Course participants should be respectful both of the other course participants and those outside the course.\nRefrain from demeaning, discriminatory, or harassing behavior and speech. Harassment includes, but is not limited to: deliberate intimidation; stalking; unwanted photography or recording; sustained or willful disruption of talks or other events; inappropriate physical contact; use of sexual or discriminatory imagery, comments, or jokes; and unwelcome sexual attention. If you feel that someone has harassed you or otherwise treated you inappropriately, please alert Stephanie Hicks.\nTake care of each other. Refrain from advocating for, or encouraging, any of the above behavior. And, if someone asks you to stop, then stop. Alert Stephanie Hicks if you notice a dangerous situation, someone in distress, or violations of this code of conduct, even if they seem inconsequential.\n\n\n\nNeed Help?\nPlease speak with Stephanie Hicks or one of the TAs. You can also reach out to Karen Bandeen-Roche, chair of the department of Biostatistics or Margaret Taub, Ombudsman for the Department of Biostatistics.\nYou may also reach out to any Hopkins resource for sexual harassment, discrimination, or misconduct:\n\nJHU Sexual Assault Helpline, 410-516-7333 (confidential)\n\nUniversity Sexual Assault Response and Prevention website\nJohns Hopkins Compliance Hotline, 844-SPEAK2US (844-733-2528)\nHopkins Policies Online\nJHU Office of Institutional Equity 410-516-8075 (nonconfidential)\nJohns Hopkins Student Assistance Program (JHSAP), 443-287-7000\nUniversity Health Services, 410-955-1892\nThe Faculty and Staff Assistance Program (FASAP), 443-997-7000"
  },
  {
    "objectID": "syllabus.html#license-and-attribution",
    "href": "syllabus.html#license-and-attribution",
    "title": "Syllabus",
    "section": "License and attribution",
    "text": "License and attribution\nThis Code of Conduct is distributed under a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license. Portions of above text comprised of language from the Codes of Conduct adopted by rOpenSci and Django, which are licensed by CC BY-SA 4.0 and CC BY 3.0. This work was further inspired by Ada Initiative’s ‘’how to design a code of conduct for your community’’ and Geek Feminism’s Code of conduct evaluations and expanded by Ashley Johnson and Shannon Ellis in the Jeff Leek group."
  },
  {
    "objectID": "syllabus.html#disability-support-service",
    "href": "syllabus.html#disability-support-service",
    "title": "Syllabus",
    "section": "Disability Support Service",
    "text": "Disability Support Service\nStudents requiring accommodations for disabilities should register with Student Disability Service (SDS). It is the responsibility of the student to register for accommodations with SDS. Accommodations take effect upon approval and apply to the remainder of the time for which a student is registered and enrolled at the Bloomberg School of Public Health. Once a student has been approved for accommodations, the student will receive formal notification and the student will be encouraged to reach out to the instructor.\nIf you have questions about requesting accommodations, please contact BSPH.dss@jhu.edu."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nPrerequisite for the course is Biostatistics 140.776 or knowledge of material from 140.776 is assumed.\nIf you did not take the above course, please contact course instructor to get permission to enroll."
  },
  {
    "objectID": "syllabus.html#general-disclaimers",
    "href": "syllabus.html#general-disclaimers",
    "title": "Syllabus",
    "section": "General Disclaimers",
    "text": "General Disclaimers\nThis syllabus is a general plan, deviations announced to the class by the instructor may be necessary."
  },
  {
    "objectID": "syllabus.html#typos-and-corrections",
    "href": "syllabus.html#typos-and-corrections",
    "title": "Syllabus",
    "section": "Typos and corrections",
    "text": "Typos and corrections\nFeel free to submit typos/errors/etc via the github repository associated with the class: https://github.com/stephaniehicks/jhustatprogramming2023. You will have the thanks of your grateful instructor!"
  },
  {
    "objectID": "readings/10-flexdashboard/index.html",
    "href": "readings/10-flexdashboard/index.html",
    "title": "Building dashboards with flexdashboard",
    "section": "",
    "text": "If we were not familiar with data dashboards before the pandemic, many of us learned just how useful they are for displaying data in a way that is visual, concise and easy to update.\nDashboards like JHU’s COVID-19 trackers were an amazing resource for anyone interested in understanding more about the progression of the pandemic, from cases to vaccine rates to emerging variants. One of the creators, Lauren Gardner, recently won a prestigious award for her work, acknowledging the importance of good data communication to the broad public to improve public health.\nData dashboards allow you to communicate large amounts of information visually and quickly with the added benefit of allowing the user to interact with the data directly in the dashboard.\n\n\n\n\n\n\nImportant\n\n\n\nflexdashboard is a method of creating dashboards using R Markdown with panels and pages. The dashboard content can be\n\ntext\nstatic figures/tables\ninteractive graphics\n\n\n\n\n\n\n\n\n\nAdvantages of flexdashboard\n\n\n\n\nIt requires minimal non-standard R coding - with very little practice you can quickly create a dashboard.\nThe dashboard can usually be emailed to colleagues as a self-contained HTML file - no server required.\nYou can combine flexdashboard with shiny, ggplotly, and other “html widgets” to add interactivity.\n\n\n\n\n\n\n\n\n\nDisadvantages of flexdashboard\n\n\n\n\nLess customization as compared to using shiny alone to create a dashboard\n\n\n\n\n\nHere’s an example of what a flexdashboard might look like:\n\n\n\nA screenshot of a dashboard created with flexdashboard\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more examples of flexdashboard dashboards, check out here:\n\nhttps://pkgs.rstudio.com/flexdashboard/articles/examples\n\n\n\n\n\n\nTo author a flexdashboard you create an R Markdown document within RStudio using the New R Markdown dialog:\n\n\n\nA screenshot of opening a new RMarkdown with a flexdashboard template\n\n\nTo create a new dashboard, use the menus at the top of RStudio:\n\nSelect File\nSelect New File\nSelect R Markdown…\n\nChoose From Template in the box on the left\nSelect Flex Dashboard from the box on the right\nThen click OK\n\nThis will open up a dashboard template.\n\n\n\n\n\n\nNote\n\n\n\nThis option will only appear once you have installed the flexdashboard package.\n\n\nYou can knit this file just as you would a regular R Markdown document.\n\n\n\n\n\n\nTry it out\n\n\n\nLet’s try this out. We will:\n\nCreate a new Project.\nCreate a new R Markdown with the flexdashbard template following instructions above.\nKnit the file and take a look at what we get!\n\nNote: you will have to save this file first before knitting. Save it in your project directory as trial_dashboard.Rmd when prompted."
  },
  {
    "objectID": "readings/10-flexdashboard/index.html#examples",
    "href": "readings/10-flexdashboard/index.html#examples",
    "title": "Building dashboards with flexdashboard",
    "section": "",
    "text": "Here’s an example of what a flexdashboard might look like:\n\n\n\nA screenshot of a dashboard created with flexdashboard\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more examples of flexdashboard dashboards, check out here:\n\nhttps://pkgs.rstudio.com/flexdashboard/articles/examples"
  },
  {
    "objectID": "readings/10-flexdashboard/index.html#getting-started",
    "href": "readings/10-flexdashboard/index.html#getting-started",
    "title": "Building dashboards with flexdashboard",
    "section": "",
    "text": "To author a flexdashboard you create an R Markdown document within RStudio using the New R Markdown dialog:\n\n\n\nA screenshot of opening a new RMarkdown with a flexdashboard template\n\n\nTo create a new dashboard, use the menus at the top of RStudio:\n\nSelect File\nSelect New File\nSelect R Markdown…\n\nChoose From Template in the box on the left\nSelect Flex Dashboard from the box on the right\nThen click OK\n\nThis will open up a dashboard template.\n\n\n\n\n\n\nNote\n\n\n\nThis option will only appear once you have installed the flexdashboard package.\n\n\nYou can knit this file just as you would a regular R Markdown document.\n\n\n\n\n\n\nTry it out\n\n\n\nLet’s try this out. We will:\n\nCreate a new Project.\nCreate a new R Markdown with the flexdashbard template following instructions above.\nKnit the file and take a look at what we get!\n\nNote: you will have to save this file first before knitting. Save it in your project directory as trial_dashboard.Rmd when prompted."
  },
  {
    "objectID": "readings/10-flexdashboard/index.html#a-quick-view",
    "href": "readings/10-flexdashboard/index.html#a-quick-view",
    "title": "Building dashboards with flexdashboard",
    "section": "A quick view",
    "text": "A quick view\nLet’s explore the R Markdown a bit.\n\nYAML\nSimilar to other R Markdown and Quarto documents, there is a YAML at the top of the file. The YAML parameter output: is required and specifies the type of file to be produced (e.g. html_document, pdf_document, word_document, or powerpoint_presentation).\nFor flexdashboard, output must be set as output:flexdashboard::flex_dashboard, which is a bit confusing looking.\nTo make thing even more confusing, there is often an additional colon and indented sub-parameter (see orientation: and vertical_layout: parameters below).\n\ntitle: \"Untitled\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\n\n\n\n\n\n\n\nNote\n\n\n\n\nTwo spaces are important to define the subparameters.\nUse an additional colon after things like key:value if you want to further define subparameters.\nIf appropriate, logical values should be given in YAML in lowercase (true, false, null).\n\n\n\n\n\nCode chunks and text\nSimilar to other R Markdown files, these files also can contain multiple code chunks.\nThey are structured in the same way you would structure them with three back-ticks and curly brackets with a lowercase “r” within.\nYou can write narrative text similarly as well with all the markdown syntax you are already familiar with with italics, bold, bullets, numbering, etc.\n\n\nHeadings\nNotice the layout of the blank document is given by the hash (#) signs. In general:\n\nEach level 1 header (#) begins a new page in the dashboard.\nEach level 2 header (##) begins a new column or a row depending on your orientation: parameter.\nEach level 3 header (###) create panels for plots, charts, tables, text, etc.\n\n# First-level heading (page)\n\n## Second level heading (row or column)  \n\n### Third-level heading (pane for plot, chart, etc.)\nIn our blank document, you see the blank output with the title: \"Untitled\" and then three rows of charts (Chart A, Chart B, and Chart C.\nThe code in the three sections with these three titles are all blank.\n\n\nSection attributes\nAnother thing you might notice is that you can specify section attributes to apply to parts of the dashboard in a key=value structure after the heading and within curly brackets { }.\nFor example, the {data-width=} and {data-height=} attributes set relative size of charts, columns, rows laid out in the same dimension (horizontal or vertical).\n## Column {data-width=650}\n\n\n\n\n\n\nNote\n\n\n\n\nThese attributes are written after a heading in a text portion of the script.\nThese are different than the knitr options inserted within at the top of R code chunks, such as out.height =.\n\n\n\nSome section attributes specific to flexdashboard include:\n\n{data-orientation=} Set to either rows or columns. If your dashboard has multiple pages, add this attribute to each page to indicate orientation.\n\n{data-width=} and {data-height=} set relative size of charts, columns, rows laid out in the same dimension (horizontal or vertical).\n\nHeight of charts also depends on whether you set the YAML parameter vertical_layout: fill or vertical_layout: scroll. If set to scroll, figure height will reflect the traditional fig.height = option in the R code chunk.\n\nSee complete size documentation at the flexdashboard website\n\n\n{.hidden} Use this to exclude a specific page from the navigation bar\n\n{data-navbar=} Use this in a page-level heading to nest it within a navigation bar drop-down menu. Provide the name (in quotes) of the drop-down menu. See example below.\n\n\n\n\n\n\n\nGroup exercise\n\n\n\nFor the next 5 minutes, pair up with a partner (or try it alone) and explore the template dashboard and adjust the layout in the following ways:\n\nTry adding pages, columns/rows, and charts with R Markdown headings (e.g. #, ##, or ###)\n\nAdjust the orientation using the YAML parameter orientation: to either rows or columns\nSpecify whether the layout fills the browser or allows for a scrolling layout\nAdd tabs to a particular section heading using the {.tabset} attribute\nAdd a navigation menu or side bar using the {data-navmenu} attribute or the {.sidebar} attribute, respectively.\n\nBe sure to open the resulting dashboard in a browser window to really see it; you won’t be able to view it very well in the small viewer pane within RStudio.\n\n\n\n\nDiamonds dashboard\nThere are several example dashboards included in the folder containing today’s lecture.\nHere is is a dashboard using the diamonds dataset in the ggplot2 package:\n\n\n---\ntitle: \"Diamonds distribution dashboard\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\n---\n\n```{r setup, include = FALSE}\nlibrary(ggplot2)\nlibrary(dplyr)\nknitr::opts_chunk$set(fig.width = 5, fig.asp = 1/3)\n```\n\n## Column 1\n\n### Carat\n\n```{r}\ndiamonds |&gt; \n  ggplot(aes(carat)) + \n  geom_histogram(binwidth = 0.1)\n```\n\n### Cut\n\n```{r}\ndiamonds |&gt; \n  ggplot(aes(cut)) + \n  geom_bar()\n```\n\n### Colour\n\n```{r}\ndiamonds |&gt; \n  ggplot(aes(color)) + \n  geom_bar()\n```\n\n## Column 2\n\n### The largest diamonds\n\n```{r}\ndiamonds %&gt;% \n  arrange(desc(carat)) %&gt;% \n  head(100) %&gt;% \n  select(carat, cut, color, price) %&gt;% \n  DT::datatable()\n```\n\n\nAbove, you can see there are two columns (designated by ##) and various rows within each column (designated with ###).\n\n\n\n\n\n\nTip\n\n\n\nThis code relies on the DT package, which is an interface to the DataTables JavaScript library.\nThe DT package provides a nice way to display R matrices or data frames as interactive HTML tables that support filtering, pagination, and sorting.\n\n\n\n\n\n\n\n\nGroup exercise\n\n\n\nFor the next 5 minutes, pair up with a partner (or try it alone), open the file Diamond_dashboard_example.Rmd and knit it. Explore to see if you can make the following changes:\n\nCan you change the titles of each of the graphs in the column on the left?\nHow could you change the first graph on the left to be a histogram of prices instead of carats?\nOr could you add a fourth graph to the dashboard that shows price?\n\nNote that to get access to the diamonds dataset that the dashboard uses, you will have to have loaded the ggplot2 package, which is part of the tidyverse. You can see that the dashboard uses this package by looking at the first set-up code chunk in the dashboard .Rmd file."
  },
  {
    "objectID": "readings/10-flexdashboard/index.html#section",
    "href": "readings/10-flexdashboard/index.html#section",
    "title": "Building dashboards with flexdashboard",
    "section": "",
    "text": "Embedding shiny in flexdashboard is however, a fundamental change to your flexdashboard. It will no longer produce an HTML output that you can send by email and anyone could open and view.\nInstead, it will be an “app”. The “Knit” button at the top of the script will be replaced by a “Run document” icon, which will open an instance of the interactive the dashboard locally on your computer.\nSharing your dashboard will now require that you either:\n\nSend the Rmd script to the viewer, they open it in R on their computer, and run the app, or\n\nThe app/dashboard is hosted on a server accessible to the viewer (most typical scenario)\n\nThus, there are benefits to integrating shiny, but also complications.\n\n\n\n\n\n\nDeploy on a server\n\n\n\nShiny documents need to be deployed to a Shiny Server to be shared broadly.\nSee instructions for creating a free account at http://www.shinyapps.io/ and instructions on how to publish to the web."
  },
  {
    "objectID": "readings/10-flexdashboard/index.html#settings",
    "href": "readings/10-flexdashboard/index.html#settings",
    "title": "Building dashboards with flexdashboard",
    "section": "Settings",
    "text": "Settings\nTo embed shiny reactivity into flexdashboard, you need only make a few changes to your flexdashboard R Markdown script.\nSpecifically, you need to add the YAML parameter runtime: shiny at the same indentation level as output:, as below:\n---\ntitle: \"Outbreak dashboard (Shiny demo)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---\nIt is also convenient to enable a “side bar” to hold the shiny input widgets that will collect information from the user.\n\n\n\n\n\n\nPro-tip\n\n\n\nCreate a column and indicate the {.sidebar} option to create a side bar on the left side.\nYou can add text and R chunks containing the shiny input commands within this column.\n\n\nIf your app/dashboard is hosted on a server and may have multiple simultaneous users, name the first R code chunk as global.\n\nInclude the commands to import/load your data in this chunk.\nThis special named chunk is treated differently, and the data imported within it are only imported once (not continuously) and are available for all users.\nThis improves the start-up speed of the app."
  },
  {
    "objectID": "readings/10-flexdashboard/index.html#shiny-syntax",
    "href": "readings/10-flexdashboard/index.html#shiny-syntax",
    "title": "Building dashboards with flexdashboard",
    "section": "Shiny syntax",
    "text": "Shiny syntax\nYou can have input that is text, numeric, selecting from a menu, or checking a box, as shown below. (Don’t run this code, it’s just there to show you what the syntax looks like!)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\nselectInput(\"variable\", \"Variable:\",\n                  c(\"Cylinders (cyl)\" = \"cyl\",\n                    \"Transmission (am)\" = \"am\",\n                    \"Gears (gear)\" = \"gear\"))\ncheckboxInput(\"outliers\", \"Show outliers\", TRUE)\n\nWhat is happening above?\n\nThe first argument\nThe input values are stored in the object given by the first argument of these input functions. For example,\n\nThe text input is stored in an object called name\nThe numeric input is stored in an object called age\n\nYou can then refer to the values with input$name and input$age, and the code that uses them will be automatically re-run whenever they change.\n\n\nThe second argument\nThe second argument gives the text that is displayed to the user to prompt their input. For example,\n\nThe input area for name will show “What is your name?” and so on.\n\nLater arguments for each type give additional information about that input, such as minimum and maximum allowed values for numeric input and menu options for the select input.\n\n\n\n\n\n\nShiny best practices\n\n\n\nTo add Shiny components to a flex dashboard you will want to do the following:\n\nAdd runtime: shiny to the YAML header at the top of the document.\nAdd the {.sidebar} attribute to the first column of the dashboard to make it a host for Shiny input controls (note this step isn’t strictly required, but many Shiny based dashboards will want to do this).\nAdd Shiny inputs and outputs as appropriate using the input functions.\nWhen including plots, be sure to wrap them in a call to renderPlot. This is important not only for dynamically responding to changes but also to ensure that they are automatically re-sized when their container changes."
  },
  {
    "objectID": "readings/10-flexdashboard/index.html#examples-1",
    "href": "readings/10-flexdashboard/index.html#examples-1",
    "title": "Building dashboards with flexdashboard",
    "section": "Examples",
    "text": "Examples\nThere are a couple examples of simple flex dashboards that use Shiny in the following files that are included with this lecture.\nOpen each one of these files and run it by clicking the “Run document” button that is where the “Knit” button usually is.\nShiny apps must be run rather than knitted, but the idea is the same! Be sure to open the output in a browser tab.\n\nGeyser dashboard\nHere is a dashboard using the faithful dataset in base R, which contains the waiting time between eruptions and the duration of the eruption for the Old Faithful geyser in Yellowstone National Park, Wyoming, USA.\n\n\n---\ntitle: \"Old Faithful Eruptions\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\nruntime: shiny\n---\n\n```{r global, include=FALSE}\n# load data in 'global' chunk so it can be shared by all users of the dashboard\nlibrary(datasets)\ndata(faithful)\n```\n\n## Column {.sidebar}\n\nWaiting time between eruptions and the duration of the eruption for the\nOld Faithful geyser in Yellowstone National Park, Wyoming, USA.\n\n```{r}\nselectInput(\"n_breaks\", label = \"Number of bins:\",\n            choices = c(10, 20, 35, 50), selected = 20)\n\nsliderInput(\"bw_adjust\", label = \"Bandwidth adjustment:\",\n            min = 0.2, max = 2, value = 1, step = 0.2)\n```\n\n## Column\n\n### Geyser Eruption Duration\n\n```{r}\nrenderPlot({\n  hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),\n       xlab = \"Duration (minutes)\", main = \"Geyser Eruption Duration\")\n  \n  dens &lt;- density(faithful$eruptions, adjust = input$bw_adjust)\n  lines(dens, col = \"blue\")\n})\n```\n\n\n\n\n\n\n\n\nGroup exercise\n\n\n\nFor the next 5 minutes, pair up with a partner (or try it alone) and explore Geyser flexdashboard, which includes interactive elements from Shiny.\n\nPlay with the user input options in the left hand sidebar to see how the user can interact with the data through the dashboard.\nThen look at both the code and the output to see how the code relates to what is shown in the dashboard.\nPlay around with the options in the code chunks to see if you can get a sense of what they are doing.\n\n\n\n\n\nMile per gallon dashboard\nOne thing to point out in the MPGFlexDashboard.Rmd file is the following chunk of code:\n\nformulaText &lt;- reactive({\n    paste(\"mpg ~\", input$variable)\n  })\n\nThis chunk of code allows the title of the graph to change depending on the input given by the user.\nIt uses the reactive() function to specify that the text is not static but will change depending on what is selected by the user.\nYou can see here the object formulaText will contain text consisting of pasting together “mpg ~” and the variable value selected from the user in the drop-down menu.\nThen, this formulaText object is used as the title in the plot! And even more importantly, it is used in the call to the boxplot function, to determine which variable to display in the plot.\nSuper cool!"
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html",
    "href": "readings/07-strategies-big-data/index.html",
    "title": "Strategies for dealing with large data",
    "section": "",
    "text": "First, we load a few R packages\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(dbplyr)\nlibrary(rsample)\n\nFor most data analyses in R, data you encounter can easily be read into memory in R (either locally or on a cluster of sorts) and analyzed in a standard way.\nHowever, if you do encounter data that is too big to be read into memory, you might start to search for strategies on how to deal with this data.\nFor most of people, it might be obvious why you would want to use R with big data, but it not obvious how.\nNow, you might say advances in hardware make this less and less of a problem as most laptops come with &gt;8-32Gb of memory and it is easy to get instances on cloud providers with terabytes of RAM.\nThat’s definitely true. But there might be some problems that you will run into.\n\n\nLet’s say you are able load part of the data into the RAM on your machine (in-memory).\nIf you had something like a zipped .csv file, you could always try loading just the first few lines into memory (see n_max = 8 below) to see what is inside the files, but eventually you will likely need a different strategy.\n\nread_csv(readr_example(\"mtcars.csv.bz2\"), \n         skip = 0, n_max = 8, progress = show_progress())\n\n# A tibble: 8 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n\n\n\n\n\nYou have to keep in mind that you will need to do something with the data too (typically need 2-3 times the RAM of the size of your data).\nThis may or may not be a problem for your hardware that you are working with.\n\n\n\nIf you are working with data on a server that needs to be transferred somewhere to do the processing or computation once the data has been transferred.\nFor example, the time it takes to make a call over the internet from San Francisco to New York City takes over 4 times longer than reading from a standard hard drive and over 200 times longer than reading from a solid state hard drive.\n\n\n\n\n\n\n\n\n\n[image source]\nThis is an especially big problem early in developing a model or performing a data analysis, when data might have to be pulled repeatedly.\nToday we are going to discuss some strategies (and R packages) for working with big data in R. We will also go through some examples of how to execute these strategies in R."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#loading-data-into-memory",
    "href": "readings/07-strategies-big-data/index.html#loading-data-into-memory",
    "title": "Strategies for dealing with large data",
    "section": "",
    "text": "Let’s say you are able load part of the data into the RAM on your machine (in-memory).\nIf you had something like a zipped .csv file, you could always try loading just the first few lines into memory (see n_max = 8 below) to see what is inside the files, but eventually you will likely need a different strategy.\n\nread_csv(readr_example(\"mtcars.csv.bz2\"), \n         skip = 0, n_max = 8, progress = show_progress())\n\n# A tibble: 8 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2"
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#memory-for-calculations",
    "href": "readings/07-strategies-big-data/index.html#memory-for-calculations",
    "title": "Strategies for dealing with large data",
    "section": "",
    "text": "You have to keep in mind that you will need to do something with the data too (typically need 2-3 times the RAM of the size of your data).\nThis may or may not be a problem for your hardware that you are working with."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#transfer-speeds-can-be-slow",
    "href": "readings/07-strategies-big-data/index.html#transfer-speeds-can-be-slow",
    "title": "Strategies for dealing with large data",
    "section": "",
    "text": "If you are working with data on a server that needs to be transferred somewhere to do the processing or computation once the data has been transferred.\nFor example, the time it takes to make a call over the internet from San Francisco to New York City takes over 4 times longer than reading from a standard hard drive and over 200 times longer than reading from a solid state hard drive.\n\n\n\n\n\n\n\n\n\n[image source]\nThis is an especially big problem early in developing a model or performing a data analysis, when data might have to be pulled repeatedly.\nToday we are going to discuss some strategies (and R packages) for working with big data in R. We will also go through some examples of how to execute these strategies in R."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#sqlite-databases",
    "href": "readings/07-strategies-big-data/index.html#sqlite-databases",
    "title": "Strategies for dealing with large data",
    "section": "SQLite databases",
    "text": "SQLite databases\nOK so as mentioned above, let’s use the SQLite format to demonstrate the strategies for dealing with large data. However, they can easily transfer other data formats.\nReminder: There are several ways to query SQL or SQLite databases in R.\nOk, we will set up the SQLite database using the nycflights13_sqlite() function in the dbplyr package.\n\nlibrary(nycflights13)\nif(!file.exists(here(\"data\", \"nycflights13\", \"nycflights13.sqlite\"))){\n  dir.create(here(\"data\", \"nycflights13\"))\n  dbplyr::nycflights13_sqlite(path=here(\"data\", \"nycflights13\"))\n}\n\nWe can check to see what file has been created\n\nlist.files(here(\"data\", \"nycflights13\"))\n\n[1] \"nycflights13.sqlite\"\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow can we use the DBI::dbConnect() function with RSQLite::SQLite() backend to connect to the SQLite database?\n\nlibrary(DBI)\n# try it yourself \n\n\n\nClick here for the answer.\n\n\nlibrary(DBI)\nconn &lt;- dbConnect(RSQLite::SQLite(), \n                  here(\"data\", \"nycflights13\", \"nycflights13.sqlite\"))\nconn\n\n&lt;SQLiteConnection&gt;\n  Path: /Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/data/nycflights13/nycflights13.sqlite\n  Extensions: TRUE\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nNext, let’s use the dplyr::tbl() function returns something that feels like a data frame with the flights dataset. Finally, show the first 10 rows of the data frame.\n\n# try it yourself \n\n\n\nClick here for the answer.\n\n\ntbl(conn, \"flights\")  |&gt; \n  head(n=10)\n\n# Source:   SQL [10 x 19]\n# Database: sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/data/nycflights13/nycflights13.sqlite]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt;\n\n\n\n\n\nBefore we jump into the next section, let’s save this data frame as flights_df and count the number of rows using dplyr::tally():\n\nflights_df &lt;- dplyr::tbl(conn, \"flights\")\nflights_df |&gt; \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/data/nycflights13/nycflights13.sqlite]\n       n\n   &lt;int&gt;\n1 336776\n\n\nEven though it only has a few hundred thousand rows, it is still useful to demonstrate some strategies for dealing with big data in R."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#advantages",
    "href": "readings/07-strategies-big-data/index.html#advantages",
    "title": "Strategies for dealing with large data",
    "section": "Advantages",
    "text": "Advantages\n\nSpeed. Relative to working on your entire data set, working on just a sample can drastically decrease run times and increase iteration speed.\nPrototyping. Even if you will eventually have to run your model on the entire data set, this can be a good way to refine hyperparameters and do feature engineering for your model.\nPackages. Since you are working on a regular, in-memory data set, you can use all your favorite R packages."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#disadvantages",
    "href": "readings/07-strategies-big-data/index.html#disadvantages",
    "title": "Strategies for dealing with large data",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nSampling. Downsampling is not terribly difficult, but does need to be done with care to ensure that the sample is valid and that you have pulled enough points from the original data set.\nScaling. If you are using sample and model to prototype something that will later be run on the full data set, you will need to have a strategy (such as pushing compute to the data) for scaling your prototype version back to the full data set.\nTotals. Business Intelligence (BI) – or strategies and technologies used by enterprises for the data analysis of business information (e.g. data mining, reporting, predictive analytics, etc) – tasks frequently answer questions about totals, like the count of all sales in a month. One of the other strategies is usually a better fit in this case."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#example",
    "href": "readings/07-strategies-big-data/index.html#example",
    "title": "Strategies for dealing with large data",
    "section": "Example",
    "text": "Example\nLet’s say we want to model whether flights will be delayed or not. We will start with some minor cleaning of the data.\nFirst, we will create a is_delayed column in the database:\n\nflights_df &lt;- \n  flights_df |&gt;\n    dplyr::mutate(is_delayed = arr_delay &gt; 0,\n                  hour = sched_dep_time / 100) |&gt; # Get just hour (currently formatted so 6 pm = 1800)\n    # Remove small carriers that make modeling difficult\n    dplyr::filter(!is.na(is_delayed) & !carrier %in% c(\"OO\", \"HA\"))\n\nHere are the total number of flights that were delayed or not:\n\nflights_df |&gt; \n  dplyr::count(is_delayed)\n\n# Source:   SQL [2 x 2]\n# Database: sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/data/nycflights13/nycflights13.sqlite]\n  is_delayed      n\n       &lt;int&gt;  &lt;int&gt;\n1          0 194078\n2          1 132897\n\n\nThese classes are reasonably well balanced, but we going to use logistic regression, so I will load a perfectly balanced sample of 40,000 data points.\nFor most databases, random sampling methods do not work smoothly with R.\n\nflights_df |&gt; \n  dplyr::sample_n(size = 1000)\n\nError in `dplyr::sample_n()`:\n! `tbl` must be a data frame, not a\n  &lt;tbl_SQLiteConnection/tbl_dbi/tbl_sql/tbl_lazy/tbl&gt; object.\n\n\nSo it is not suggested to use dplyr::sample_n() or dplyr::sample_frac(). So we will have to be a little more manual.\n\nset.seed(1234)\n\nn_rows &lt;- flights_df |&gt; tally() |&gt; pull()\nidx &lt;- sample(0:n_rows, replace = FALSE)\n\n# Create a modeling data set \n# df_mod &lt;- \n  \n  df_mod &lt;- flights_df |&gt;\n    mutate(x = runif(n()))\n\n\n\n\n\n\n\nNote\n\n\n\ndplyr::collect() forces a computation of a database query and retrieves data into a local tibble\nSo, here, we take the first 5% for each class for training set:\n\ndf_train &lt;- df_mod |&gt;\n  group_by(is_delayed) |&gt;\n  filter(x &lt;= .05) |&gt;\n  collect() \n\n\n\nThen, we take next 5% for test set:\n\ndf_test &lt;- df_mod |&gt;\n  group_by(is_delayed) |&gt;\n  filter(x &gt; .05 & x &lt;= .10) |&gt;\n  collect() # again, this data is now loaded locally\n\n\n# How many are in each group\ncount(df_train, is_delayed)\n\n# A tibble: 2 × 2\n# Groups:   is_delayed [2]\n  is_delayed     n\n       &lt;int&gt; &lt;int&gt;\n1          0  9675\n2          1  6657\n\ncount(df_test, is_delayed)\n\n# A tibble: 2 × 2\n# Groups:   is_delayed [2]\n  is_delayed     n\n       &lt;int&gt; &lt;int&gt;\n1          0 18418\n2          1 12715\n\n\nNow let’s build a model – let’s see if we can predict whether there will be a delay or not by the combination of the carrier, and the month of the flight.\n\nSys.time()\n\n[1] \"2024-11-17 22:21:50 EST\"\n\nmod &lt;- glm(is_delayed ~ carrier + as.factor(month),\n           family = \"binomial\", data = df_train)\nSys.time()\n\n[1] \"2024-11-17 22:21:50 EST\"\n\n\n\nsummary(mod)\n\n\nCall:\nglm(formula = is_delayed ~ carrier + as.factor(month), family = \"binomial\", \n    data = df_train)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.399306   0.089350  -4.469 7.86e-06 ***\ncarrierAA          -0.302241   0.089997  -3.358 0.000784 ***\ncarrierAS          -0.087842   0.389817  -0.225 0.821713    \ncarrierB6           0.213814   0.081816   2.613 0.008966 ** \ncarrierDL          -0.145930   0.083416  -1.749 0.080218 .  \ncarrierEV           0.380412   0.082140   4.631 3.63e-06 ***\ncarrierF9           1.529445   0.451841   3.385 0.000712 ***\ncarrierFL           0.909857   0.176743   5.148 2.63e-07 ***\ncarrierMQ           0.410547   0.091937   4.466 7.99e-06 ***\ncarrierUA          -0.049704   0.081516  -0.610 0.542034    \ncarrierUS          -0.051941   0.097201  -0.534 0.593091    \ncarrierVX          -0.141036   0.147859  -0.954 0.340157    \ncarrierWN           0.289082   0.108175   2.672 0.007532 ** \ncarrierYV           0.115797   0.375339   0.309 0.757693    \nas.factor(month)2   0.005372   0.082110   0.065 0.947837    \nas.factor(month)3  -0.055996   0.079086  -0.708 0.478918    \nas.factor(month)4   0.141712   0.079987   1.772 0.076445 .  \nas.factor(month)5  -0.280750   0.079604  -3.527 0.000421 ***\nas.factor(month)6   0.193407   0.080313   2.408 0.016033 *  \nas.factor(month)7   0.226854   0.077735   2.918 0.003519 ** \nas.factor(month)8  -0.063908   0.078887  -0.810 0.417869    \nas.factor(month)9  -0.781032   0.084538  -9.239  &lt; 2e-16 ***\nas.factor(month)10 -0.411235   0.079944  -5.144 2.69e-07 ***\nas.factor(month)11 -0.305348   0.080815  -3.778 0.000158 ***\nas.factor(month)12  0.511325   0.078883   6.482 9.05e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 22080  on 16331  degrees of freedom\nResidual deviance: 21457  on 16307  degrees of freedom\nAIC: 21507\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# Out-of-Sample AUROC\ndf_test$pred &lt;- predict(mod, newdata = df_test)\nauc &lt;- suppressMessages(pROC::auc(df_test$is_delayed, df_test$pred))\nauc\n\nArea under the curve: 0.607\n\n\nAs you can see, this is not a great model, but that’s not the point here!\nInstead, we showed how to build a model on a small subset of a big data set. Including sampling time, this took my laptop a second to run, making it easy to iterate quickly as I want to improve the model. After I’m happy with this model, I could pull down a larger sample or even the entire data set if it is feasible, or do something with the model from the sample."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#advantages-1",
    "href": "readings/07-strategies-big-data/index.html#advantages-1",
    "title": "Strategies for dealing with large data",
    "section": "Advantages",
    "text": "Advantages\n\nFull data set. The entire data set gets used.\nParallelization. If the chunks are run separately, the problem is easy to treat as embarassingly parallel and make use of parallelization to speed runtimes."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#disadvantages-1",
    "href": "readings/07-strategies-big-data/index.html#disadvantages-1",
    "title": "Strategies for dealing with large data",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nNeed Chunks. Your data needs to have separable chunks for chunk and pull to be appropriate.\nPull All Data. Eventually have to pull in all data, which may still be very time and memory intensive.\nStale Data. The data may require periodic refreshes from the database to stay up-to-date since you’re saving a version on your local machine."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#example-1",
    "href": "readings/07-strategies-big-data/index.html#example-1",
    "title": "Strategies for dealing with large data",
    "section": "Example",
    "text": "Example\nIn this case, I want to build another model of on-time arrival, but I want to do it per-carrier. This is exactly the kind of use case that is ideal for chunk and pull.\nI am going to separately pull the data in by carrier and run the model on each carrier’s data.\nI am going to start by just getting the complete list of the carriers.\n\n# Get all unique carriers\ncarriers &lt;- flights_df |&gt; \n  select(carrier) |&gt; \n  distinct() |&gt; \n  pull(carrier)\n\ncarriers\n\n [1] \"9E\" \"AA\" \"AS\" \"B6\" \"DL\" \"EV\" \"F9\" \"FL\" \"MQ\" \"UA\" \"US\" \"VX\" \"WN\" \"YV\"\n\n\nNow, I will write a function that\n\ntakes the name of a carrier as input\npulls the data for that carrier into R\nsplits the data into training and test\ntrains the model\noutputs the out-of-sample AUROC (a common measure of model quality)\n\n\ncarrier_model &lt;- function(carrier_name) {\n  # Pull a chunk of data\n  df_mod &lt;- flights_df |&gt;\n    filter(carrier == carrier_name) |&gt;\n    collect()\n  \n  # Split into training and test\n  split &lt;- df_mod |&gt;\n    rsample::initial_split(prop = 0.9, strata = \"is_delayed\") |&gt; \n    suppressMessages()\n  \n  # Get training data\n  df_train &lt;- split |&gt; \n                rsample::training()\n  \n  # Train model\n  mod &lt;- glm(is_delayed ~ as.factor(month),\n             family = \"binomial\", data = df_train)\n  \n  # Get out-of-sample AUROC\n  df_test &lt;- split |&gt; \n                rsample::testing()\n  df_test$pred &lt;- predict(mod, newdata = df_test)\n  suppressMessages(auc &lt;- pROC::auc(df_test$is_delayed ~ df_test$pred))\n  \n  auc\n}\n\nNow, I am going to actually run the carrier model function across each of the carriers. This code runs pretty quickly, and so I do not think the overhead of parallelization would be worth it.\n\nset.seed(1234)\nmods &lt;- lapply(carriers, carrier_model) |&gt;\n  suppressMessages()\n\nnames(mods) &lt;- carriers\n\nLet’s look at the results.\n\nmods\n\n$`9E`\nArea under the curve: 0.5711\n\n$AA\nArea under the curve: 0.5731\n\n$AS\nArea under the curve: 0.5597\n\n$B6\nArea under the curve: 0.6208\n\n$DL\nArea under the curve: 0.5817\n\n$EV\nArea under the curve: 0.588\n\n$F9\nArea under the curve: 0.5134\n\n$FL\nArea under the curve: 0.5508\n\n$MQ\nArea under the curve: 0.572\n\n$UA\nArea under the curve: 0.6046\n\n$US\nArea under the curve: 0.5811\n\n$VX\nArea under the curve: 0.67\n\n$WN\nArea under the curve: 0.5607\n\n$YV\nArea under the curve: 0.6041\n\n\nSo these models (again) are a little better than random chance. The point was that we utilized the chunk and pull strategy to pull the data separately by logical units and building a model on each chunk."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#advantages-2",
    "href": "readings/07-strategies-big-data/index.html#advantages-2",
    "title": "Strategies for dealing with large data",
    "section": "Advantages",
    "text": "Advantages\n\nUse the Database. Takes advantage of what databases are often best at: quickly summarizing and filtering data based on a query.\nMore Info, Less Transfer. By compressing before pulling data back to R, the entire data set gets used, but transfer times are far less than moving the entire data set."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#disadvantages-2",
    "href": "readings/07-strategies-big-data/index.html#disadvantages-2",
    "title": "Strategies for dealing with large data",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nDatabase Operations. Depending on what database you are using, some operations might not be supported.\nDatabase Speed. In some contexts, the limiting factor for data analysis is the speed of the database itself, and so pushing more work onto the database is the last thing analysts want to do."
  },
  {
    "objectID": "readings/07-strategies-big-data/index.html#example-2",
    "href": "readings/07-strategies-big-data/index.html#example-2",
    "title": "Strategies for dealing with large data",
    "section": "Example",
    "text": "Example\nIn this case, I am doing a pretty simple BI task - plotting the proportion of flights that are late by the hour of departure and the airline.\nJust by way of comparison, let’s run this first the naive way -– pulling all the data to my system and then doing my data manipulation to plot.\n\nsystem.time(\n  df_plot &lt;- flights_df |&gt;\n    collect() |&gt;\n    group_by(carrier, sched_dep_time) |&gt;\n    # Get proportion per carrier-time\n    summarize(delay_pct = mean(is_delayed, na.rm = TRUE)) |&gt;\n    ungroup() |&gt;\n    # Change string times into actual times\n    dplyr::mutate(sched_dep_time = \n                    stringr::str_pad(sched_dep_time, 4, \"left\", \"0\") |&gt; \n             strptime(\"%H%M\") |&gt;  # converts character class into POSIXlt class\n             as.POSIXct()) # converts POSIXlt class to POSIXct class\n  ) -&gt; timing1\n\ntiming1\n\n   user  system elapsed \n  0.818   0.020   0.838 \n\n\nNow that wasn’t too bad, just 0.838 seconds on my laptop.\nBut let’s see how much of a speedup we can get from chunk and pull. The conceptual change here is significant - I’m doing as much work as possible in the SQLite server now instead of locally.\nBut using dplyr means that the code change is minimal. The only difference in the code is that the collect() call got moved down by a few lines (to below ungroup()).\n\nsystem.time(\n  df_plot &lt;- flights_df |&gt;\n    dplyr::group_by(carrier, sched_dep_time) |&gt;\n    # Get proportion per carrier-time\n    dplyr::summarize(delay_pct = mean(is_delayed, na.rm = TRUE)) |&gt;\n    dplyr::ungroup() |&gt;\n    dplyr::collect() |&gt;\n    # Change string times into actual times\n    dplyr::mutate(sched_dep_time = \n                    stringr::str_pad(sched_dep_time, 4, \"left\", \"0\") |&gt; \n             strptime(\"%H%M\") |&gt; \n             as.POSIXct())) -&gt; timing2\n\n`summarise()` has grouped output by \"carrier\". You can override using the\n`.groups` argument.\n\ntiming2\n\n   user  system elapsed \n  0.280   0.038   0.318 \n\n\nIt might have taken you the same time to read this code as the last chunk, but this took only 0.318 seconds to run, almost an order of magnitude faster! That’s pretty good for just moving one line of code.\nNow that we have done a speed comparison, we can create the nice plot we all came for.\n\ndf_plot |&gt;\n  dplyr::mutate(carrier = paste0(\"Carrier: \", carrier)) |&gt;\n  ggplot(aes(x = sched_dep_time, y = delay_pct)) +\n    geom_line() +\n    facet_wrap(\"carrier\") +\n    ylab(\"Proportion of Flights Delayed\") +\n    xlab(\"Time of Day\") +\n    scale_y_continuous(labels = scales::percent) +\n    scale_x_datetime(date_breaks = \"4 hours\", \n                    date_labels = \"%H\")\n\n\n\n\n\n\n\n\nIt looks to me like flights later in the day might be a little more likely to experience delays."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html",
    "href": "readings/04-data-collection-html/index.html",
    "title": "Scraping data from the web with rvest",
    "section": "",
    "text": "rvest is an R package that helps you scrape (or harvest) data from web pages.\nIt is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nWe will begin with a quick overview of web scraping basics followed by demonstrating the rvest package."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#html-basics",
    "href": "readings/04-data-collection-html/index.html#html-basics",
    "title": "Scraping data from the web with rvest",
    "section": "HTML basics",
    "text": "HTML basics\nHTML stands for “HyperText Markup Language” and looks like this:\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Page title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='first'&gt;A heading&lt;/h1&gt;\n  &lt;p&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\nHTML has a hierarchical structure formed by elements which consist of a start tag (e.g. &lt;tag&gt;), optional attributes (id='first'), an end tag (like &lt;/tag&gt;), and contents (everything in between the start and end tag).\n\n\n\n\n\n\nNote\n\n\n\nA number of tags (including &lt;p&gt; and &lt;li&gt;) don’t require end tags, but I think it’s best to include them because it makes seeing the structure of the HTML a little easier.\n\n\n\nElements\nAll up, there are over 100 HTML elements. Some of the most important are:\n\nEvery HTML page must be must be in an &lt;html&gt; element, and it must have two children:\n\n&lt;head&gt;, which contains document metadata like the page title\n&lt;body&gt;, which contains the content you see in the browser\n\nBlock tags like &lt;h1&gt; (heading 1), &lt;p&gt; (paragraph), and &lt;ol&gt; (ordered list) form the overall structure of the page.\nInline tags like &lt;b&gt; (bold), &lt;i&gt; (italics), and &lt;a&gt; (links) formats text inside block tags.\n\nIf you encounter a tag that you have never seen before, you can find out what it does with a little googling.\nI recommend the MDN Web Docs which are produced by Mozilla, the company that makes the Firefox web browser.\n\n\nContents\nMost elements can have content in between their start and end tags. This content can either be text or more elements. For example, the following HTML contains paragraph of text, with one word in bold.\n&lt;p&gt;\n  Hi! My &lt;b&gt;name&lt;/b&gt; is Stephanie.\n&lt;/p&gt;\nThe children of a node refers only to elements, so the &lt;p&gt; element above has one child, the &lt;b&gt; element. The &lt;b&gt; element has no children, but it does have contents (the text “name”).\nSome elements, like &lt;img&gt; can’t have children. These elements depend solely on attributes for their behavior.\n\n\nAttributes\nTags can have named attributes which look like name1='value1' name2='value2'.\nTwo of the most important attributes are id and class, which are used in conjunction with CSS (Cascading Style Sheets) to control the visual appearance of the page.\nThese are often useful when scraping data off a page."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#reading-html-with-rvest",
    "href": "readings/04-data-collection-html/index.html#reading-html-with-rvest",
    "title": "Scraping data from the web with rvest",
    "section": "Reading HTML with rvest",
    "text": "Reading HTML with rvest\nYou will usually start the scraping process with read_html(). This returns a xml_document object which you will then manipulate using rvest functions:\n\n\n\n\n\n\nNote\n\n\n\nThis xml_document class comes from the xml2 package, which is a low-level package that rvest builds on top of.\n\n\n\nlibrary(tidyverse)\nlibrary(rvest)\n\n\nhtml &lt;- read_html(\"http://rvest.tidyverse.org/\")\nclass(html)\n\n[1] \"xml_document\" \"xml_node\"    \n\n\nFor examples and experimentation, rvest also includes a function (minimal_html()) that lets you create an xml_document from literal HTML:\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;This is a paragraph&lt;p&gt;\n  &lt;ul&gt;\n    &lt;li&gt;This is a bulleted list&lt;/li&gt;\n  &lt;/ul&gt;\n\")\nclass(html)\n\n[1] \"xml_document\" \"xml_node\"    \n\nhtml\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n&lt;p&gt;This is a paragraph&lt;/p&gt;\\n&lt;p&gt;\\n  &lt;/p&gt;\\n&lt;ul&gt;\\n&lt;li&gt;This is a bull ...\n\n\nRegardless of how you get the HTML, you will need some way to identify the elements that contain the data you care about.\nrvest provides two options:\n\nCSS selectors\nXPath expressions\n\nHere I will focus on CSS selectors because they are simpler, but still sufficiently powerful for most scraping tasks."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#css-selectors",
    "href": "readings/04-data-collection-html/index.html#css-selectors",
    "title": "Scraping data from the web with rvest",
    "section": "CSS selectors",
    "text": "CSS selectors\nCSS is short for cascading style sheets, and is a tool for defining the visual styling of HTML documents.\nCSS includes a miniature language for selecting elements on a page called CSS selectors.\nCSS selectors define patterns for locating HTML elements, and are useful for scraping because they provide a concise way of describing which elements you want to extract.\nCSS selectors can be quite complex, but fortunately you only need the simplest for rvest, because you can also write R code for more complicated situations.\nThe four most important selectors are:\n\np: selects all &lt;p&gt; elements.\n.title: selects all elements with class “title”.\np.special: selects all &lt;p&gt; elements with class “special”.\n#title: selects the element with the id attribute that equals “title”. Id attributes must be unique within a document, so this will only ever select a single element.\n\nIf you want to learn more CSS selectors, I recommend starting with the fun CSS dinner tutorial and then referring to the MDN web docs.\nLets try out the most important selectors with a simple example:\n\nhtml &lt;- minimal_html(\"\n  &lt;h1&gt;This is a heading&lt;/h1&gt;\n  &lt;p id='first'&gt;This is a paragraph&lt;/p&gt;\n  &lt;p class='important'&gt;This is an important paragraph&lt;/p&gt;\n\")\n\nIn rvest you can extract\n\na single element with html_element() or\nall matching elements with html_elements()\n\nBoth functions take a document (or another element) and a css selector:\n\nhtml %&gt;% html_elements(\"h1\")\n\n{xml_nodeset (1)}\n[1] &lt;h1&gt;This is a heading&lt;/h1&gt;\n\nhtml %&gt;% html_elements(\"p\")\n\n{xml_nodeset (2)}\n[1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n[2] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\n\nhtml %&gt;% html_elements(\".important\")\n\n{xml_nodeset (1)}\n[1] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\n\nhtml %&gt;% html_elements(\"#first\")\n\n{xml_nodeset (1)}\n[1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nIf you don’t know exactly what selector you need, I highly recommend using SelectorGadget, which lets you automatically generate the selector you need by supplying positive and negative examples in the browser"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#extracting-data",
    "href": "readings/04-data-collection-html/index.html#extracting-data",
    "title": "Scraping data from the web with rvest",
    "section": "Extracting data",
    "text": "Extracting data\nNow that you have got the elements you care about, you will need to get data out of them.\nYou will usually get the data from either the text contents or an attribute. But, sometimes (if you’re lucky!), the data you need will be in an HTML table.\n\nText\nUse html_text2() to extract the plain text contents of an HTML element:\n\nhtml &lt;- minimal_html(\"\n  &lt;ol&gt;\n    &lt;li&gt;apple &amp; pear&lt;/li&gt;\n    &lt;li&gt;banana&lt;/li&gt;\n    &lt;li&gt;pineapple&lt;/li&gt;\n  &lt;/ol&gt;\n\")\nhtml %&gt;% \n  html_elements(\"li\") %&gt;% \n  html_text2()\n\n[1] \"apple & pear\" \"banana\"       \"pineapple\"   \n\n\nNote that the escaped ampersand is automatically converted to &; you will only ever see HTML escapes in the source HTML, not in the data returned by rvest.\nYou might wonder why I used html_text2(), since it seems to give the same result as html_text():\n\nhtml %&gt;% \n  html_elements(\"li\") %&gt;% \n  html_text()\n\n[1] \"apple & pear\" \"banana\"       \"pineapple\"   \n\n\nThe main difference is how the two functions handle white space.\nIn HTML, white space is largely ignored, and it is the structure of the elements that defines how text is laid out.\nhtml_text2() does its best to follow the same rules, giving you something similar to what you’d see in the browser. Take this example which contains a bunch of white space that HTML ignores.\n\nhtml &lt;- minimal_html(\"&lt;body&gt;\n  &lt;p&gt;\n  This is\n  a\n  paragraph.&lt;/p&gt;&lt;p&gt;This is another paragraph.\n  \n  It has two sentences.&lt;/p&gt;\n\")\n\nhtml_text2() gives you what you expect: two paragraphs of text separated by a blank line.\n\nhtml %&gt;% \n  html_element(\"body\") %&gt;% \n  html_text2() %&gt;% \n  cat()\n\nThis is a paragraph.\n\nThis is another paragraph. It has two sentences.\n\n\nWhereas html_text() returns the garbled raw underlying text:\n\nhtml %&gt;% \n  html_element(\"body\") %&gt;% \n  html_text() %&gt;% \n  cat()\n\n\n  \n  This is\n  a\n  paragraph.This is another paragraph.\n  \n  It has two sentences.\n\n\n\n\nAttributes\nAttributes are used to record the destination of links (the href attribute of &lt;a&gt; elements) and the source of images (the src attribute of the &lt;img&gt; element):\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Cat'&gt;cats&lt;/a&gt;&lt;/p&gt;\n  &lt;img src='https://cataas.com/cat' width='100' height='200'&gt;\n\")\n\nThe value of an attribute can be retrieved with html_attr():\n\nhtml %&gt;% \n  html_elements(\"a\") %&gt;% \n  html_attr(\"href\")\n\n[1] \"https://en.wikipedia.org/wiki/Cat\"\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"src\")\n\n[1] \"https://cataas.com/cat\"\n\n\nNote that html_attr() always returns a string, so you may need to post-process with as.integer()/readr::parse_integer() or similar.\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"width\")\n\n[1] \"100\"\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"width\") %&gt;% \n  as.integer()\n\n[1] 100\n\n\n\n\nTables\nHTML tables are composed four main elements:\n\n&lt;table&gt;\n&lt;tr&gt; (table row)\n&lt;th&gt; (table heading)\nand &lt;td&gt; (table data)\n\nHere’s a simple HTML table with two columns and three rows:\n\nhtml &lt;- minimal_html(\"\n  &lt;table&gt;\n    &lt;tr&gt;\n      &lt;th&gt;x&lt;/th&gt;\n      &lt;th&gt;y&lt;/th&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;1.5&lt;/td&gt;\n      &lt;td&gt;2.7&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;4.9&lt;/td&gt;\n      &lt;td&gt;1.3&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;7.2&lt;/td&gt;\n      &lt;td&gt;8.1&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/table&gt;\n  \")\n\nBecause tables are a common way to store data, rvest includes the handy html_table() which converts a table into a data frame:\n\nhtml %&gt;% \n  html_table()\n\n[[1]]\n# A tibble: 3 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1   1.5   2.7\n2   4.9   1.3\n3   7.2   8.1"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#element-vs-elements",
    "href": "readings/04-data-collection-html/index.html#element-vs-elements",
    "title": "Scraping data from the web with rvest",
    "section": "Element vs elements",
    "text": "Element vs elements\nWhen using rvest, your eventual goal is usually to build up a data frame, and you want each row to correspond some repeated unit on the HTML page.\nIn this case, you should generally\n\nstart by using html_elements() to select the elements that contain each observation\nthen, use html_element() to extract the variables from each observation\n\nThis guarantees that you will get the same number of values for each variable because html_element() always returns the same number of outputs as inputs.\nTo illustrate this problem take a look at this simple example I constructed using a few entries from dplyr::starwars:\n\nhtml &lt;- minimal_html(\"\n  &lt;ul&gt;\n    &lt;li&gt;&lt;b&gt;C-3PO&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;167 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R2-D2&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;96 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;Yoda&lt;/b&gt; weighs &lt;span class='weight'&gt;66 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R4-P17&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n  \")\n\nIf you try to extract name, species, and weight directly, you end up with one vector of length four and two vectors of length three, and no way to align them:\n\nhtml %&gt;% html_elements(\"b\") %&gt;% html_text2()\n\n[1] \"C-3PO\"  \"R2-D2\"  \"Yoda\"   \"R4-P17\"\n\nhtml %&gt;% html_elements(\"i\") %&gt;% html_text2()\n\n[1] \"droid\" \"droid\" \"droid\"\n\nhtml %&gt;% html_elements(\".weight\") %&gt;% html_text2()\n\n[1] \"167 kg\" \"96 kg\"  \"66 kg\" \n\n\nInstead, use html_elements() to find a element that corresponds to each character, then use html_element() to extract each variable for all observations:\n\ncharacters &lt;- html %&gt;% html_elements(\"li\")\n\ncharacters %&gt;% html_element(\"b\") %&gt;% html_text2()\n\n[1] \"C-3PO\"  \"R2-D2\"  \"Yoda\"   \"R4-P17\"\n\ncharacters %&gt;% html_element(\"i\") %&gt;% html_text2()\n\n[1] \"droid\" \"droid\" NA      \"droid\"\n\ncharacters %&gt;% html_element(\".weight\") %&gt;% html_text2()\n\n[1] \"167 kg\" \"96 kg\"  \"66 kg\"  NA      \n\n\nhtml_element() automatically fills in NA when no elements match, keeping all of the variables aligned and making it easy to create a data frame:\n\ndata.frame(\n  name = characters %&gt;% html_element(\"b\") %&gt;% html_text2(),\n  species = characters %&gt;% html_element(\"i\") %&gt;% html_text2(),\n  weight = characters %&gt;% html_element(\".weight\") %&gt;% html_text2()\n)\n\n    name species weight\n1  C-3PO   droid 167 kg\n2  R2-D2   droid  96 kg\n3   Yoda    &lt;NA&gt;  66 kg\n4 R4-P17   droid   &lt;NA&gt;"
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#installation",
    "href": "readings/04-data-collection-html/index.html#installation",
    "title": "Scraping data from the web with rvest",
    "section": "Installation",
    "text": "Installation\nTo install it, open this page in your browser, and then drag the following link to your bookmark bar: SelectorGadget."
  },
  {
    "objectID": "readings/04-data-collection-html/index.html#use",
    "href": "readings/04-data-collection-html/index.html#use",
    "title": "Scraping data from the web with rvest",
    "section": "Use",
    "text": "Use\nTo use it, open the page you want to scrape, then:\n\nClick the SelectorGadget entry in your bookmark bar.\nClick on the element you want to select. SelectorGadget will make a first guess at what css selector you want. It’s likely to be bad since it only has one example to learn from, but it’s a start. Elements that match the selector will be highlighted in yellow.\nClick on elements that should not be selected. They will turn red. Click on elements that should be selected. They will turn green.\nIterate until only the elements you want are selected. SelectorGadget is not perfect and sometimes will not be able to find a useful css selector. Sometimes starting from a different element helps."
  },
  {
    "objectID": "readings/03-functional-programming/index.html",
    "href": "readings/03-functional-programming/index.html",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "If you have ever heard the phrase\n\n“R is a functional language.”\n\nyou might have asked yourself what does this means exactly? Generally, this means that R lends itself nice to a particular style of programming, namely a functional style of programming (will explain more below), which is often very helpful to the types of problems you encounter when doing a data analysis.\n\n\nA functional style of programming is contrast to a the formal definition of a functional language (or functional programming, which can be complementary to object-oriented programming), which are languages that use functions to create conditional expressions to perform specific computations.\n\n\n\n\n\n\nDifferences between functional and object-oriented programming\n\n\n\nFrom this resource some differences are:\n\nBasic elements: The fundamental elements of object-oriented languages are objects and methods, while the elements of functional programming are functions and variables.\nStates: Object-oriented languages can change objects within the program, which means it has states or current modifications that affect the result of inputs. Functional languages do not use imperative programming, so they do not keep track of current states.\nParallel programming: This type of programming involves multiple computational processes occurring at the same time. Object-oriented languages have little support for parallel programming, but functional languages have extensive support for it.\nOrder: In object-oriented programming, computations occur in a specific order. In functional programming, computations can occur in any order.\nIterative data: Object-oriented programming uses loops, meaning repeated execution, for iterative data. Functional programming uses recursion for iterative data, meaning it attempts to solve problems using simpler versions of the same problem.\n\n\n\nA traditional weakness of functional languages are poorer performance and sometimes unpredictable memory usage, but these have been much reduced in recent years.\n\n\n\nThere are many definitions for precisely what makes a language functional, but there are two common threads and/or characteristics.\n\n\nAt it is core, functional programming treats functions equally as other data structures, called first class functions.\n\nIn R, this means that you can do many of the things with a function that you can do with a vector: you can assign them to variables, store them in lists, pass them as arguments to other functions, create them inside functions, and even return them as the result of a function.\n\n\n\n\n\n\n\nExamples of cool things you can do with functions in R\n\n\n\n\nAssign a function to a variable (foo):\n\n\nfoo &lt;- function(){\n  return(\"This is foo.\")\n}\nclass(foo)\n\n[1] \"function\"\n\nfoo\n\nfunction () \n{\n    return(\"This is foo.\")\n}\n\nfoo()\n\n[1] \"This is foo.\"\n\n\n\nYou can store functions in a list:\n\n\nfoo_list &lt;- list( \n  fun_1 = function() return(\"foo_1\"),\n  fun_2 = function() return(\"foo_2\")\n)\n\nstr(foo_list)\n\nList of 2\n $ fun_1:function ()  \n $ fun_2:function ()  \n\nfoo_list$fun_1()\n\n[1] \"foo_1\"\n\nfoo_list$fun_2()\n\n[1] \"foo_2\"\n\n\n\nYou can pass functions as arguments to other functions:\n\n\nshell_fn &lt;- function(f) f()\nshell_fn(foo_list$fun_1)\n\n[1] \"foo_1\"\n\nshell_fn(foo_list$fun_2)\n\n[1] \"foo_2\"\n\n\n\nYou can create functions inside of functions and return them as the result of a function\n\n\nfoo_wrap &lt;- function(){\n  foo_2 &lt;- function(){\n    return(\"This is foo_2.\")\n  }\n  return(foo_2)\n}\n\nfoo_wrap()\n\nfunction () \n{\n    return(\"This is foo_2.\")\n}\n&lt;environment: 0x12824dbf8&gt;\n\n(foo_wrap())()\n\n[1] \"This is foo_2.\"\n\n\nThe bottom line, you can manipulate functions as the same way as you can to a vector or a matrix.\n\n\n\n\n\nA function is pure, if it satisfies two properties:\n\nThe output only depends on the inputs, i.e. if you call it again with the same inputs, you get the same outputs. This excludes functions like runif(), read.csv(), or Sys.time() that can return different values.\nThe function has no side-effects, like changing the value of a global variable, writing to disk, or displaying to the screen. This excludes functions like print(), write.csv() and &lt;-.\n\nPure functions are much easier to reason about, but obviously have significant downsides: imagine doing a data analysis where you could not generate random numbers or read files from disk.\n\n\n\n\n\n\nImportant\n\n\n\nTo be clear, R is not formally a functional programming language as it does not require pure functions to be used when writing code.\n\n\nSo you might be asking yourself, why are we talking about this then?\nThe formal definition of a functional programming language introduces a new style of programming, namely a functional style of programming.\n\n\n\n\n\n\nNote\n\n\n\nThe key idea of a functional style is this programming style encourages programmers to write a big function as many smaller isolated functions, where each function addresses one specific task.\n\n\nYou can always adopt a functional style for certain parts of your code! For example, this style of writing code motivates more humanly readable code, and recyclable code.\n\n\"data_set.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()\n\n\"data_set2.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_different_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()\n\n\n\n\n\nAt a high-level, a functional style is the concept of decomposing a big problem into smaller components, then solving each piece with a function or combination of functions.\n\nWhen using a functional style, you strive to decompose components of the problem into isolated functions that operate independently.\nEach function taken by itself is simple and straightforward to understand; complexity is handled by composing functions in various ways.\n\n\n\nIn this lecture, we will focus on one type of functional technique, namely functionals, which are functions that take another function as an argument and returns a vector as output.\nFunctionals allow you to take a function that solves the problem for a single input and generalize it to handle any number of inputs. Once you learn about them, you will find yourself using them all the time in data analysis.\n\n\n\n\n\n\nExample of a functional\n\n\n\nHere’s a simple functional: it calls the function provided as input with 1000 random uniform numbers.\n\nrandomise &lt;- function(f) f(runif(1e3))\nrandomise(mean)\n\n[1] 0.5021298\n\nrandomise(mean)\n\n[1] 0.5110258\n\nrandomise(sum)\n\n[1] 518.8307\n\n\n\n\nThe chances are that you have already used a functional. You might have used for-loop replacements like base R’s lapply(), apply(), and tapply() or maybe you have used a mathematical functional like integrate() or optim().\nOne of the most common use of functionals is an alternative to for loops.\nFor loops have a bad rap in R because many people believe they are slow, but the real downside of for loops is that they’re very flexible: a loop conveys that you’re iterating, but not what should be done with the results.\n\n\nTypically it is not the for loop itself that is slow, but what you are doing inside of it. A common culprit of slow loops is modifying a data structure, where each modification generates a copy.\nIf you’re an experienced for loop user, switching to functionals is typically a pattern matching exercise. You look at the for loop and find a functional that matches the basic form. If one does not exist, do not try and torture an existing functional to fit the form you need. Instead, just leave it as a for loop! (Or once you have repeated the same loop two or more times, maybe think about writing your own functional).\nJust as it is better to use while than repeat, and it’s better to use for than while, it is better to use a functional than for.\nEach functional is tailored for a specific task, so when you recognize the functional you immediately know why it’s being used."
  },
  {
    "objectID": "readings/03-functional-programming/index.html#functional-programming-language",
    "href": "readings/03-functional-programming/index.html#functional-programming-language",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "A functional style of programming is contrast to a the formal definition of a functional language (or functional programming, which can be complementary to object-oriented programming), which are languages that use functions to create conditional expressions to perform specific computations.\n\n\n\n\n\n\nDifferences between functional and object-oriented programming\n\n\n\nFrom this resource some differences are:\n\nBasic elements: The fundamental elements of object-oriented languages are objects and methods, while the elements of functional programming are functions and variables.\nStates: Object-oriented languages can change objects within the program, which means it has states or current modifications that affect the result of inputs. Functional languages do not use imperative programming, so they do not keep track of current states.\nParallel programming: This type of programming involves multiple computational processes occurring at the same time. Object-oriented languages have little support for parallel programming, but functional languages have extensive support for it.\nOrder: In object-oriented programming, computations occur in a specific order. In functional programming, computations can occur in any order.\nIterative data: Object-oriented programming uses loops, meaning repeated execution, for iterative data. Functional programming uses recursion for iterative data, meaning it attempts to solve problems using simpler versions of the same problem.\n\n\n\nA traditional weakness of functional languages are poorer performance and sometimes unpredictable memory usage, but these have been much reduced in recent years."
  },
  {
    "objectID": "readings/03-functional-programming/index.html#characteristics-of-a-functional-language",
    "href": "readings/03-functional-programming/index.html#characteristics-of-a-functional-language",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "There are many definitions for precisely what makes a language functional, but there are two common threads and/or characteristics.\n\n\nAt it is core, functional programming treats functions equally as other data structures, called first class functions.\n\nIn R, this means that you can do many of the things with a function that you can do with a vector: you can assign them to variables, store them in lists, pass them as arguments to other functions, create them inside functions, and even return them as the result of a function.\n\n\n\n\n\n\n\nExamples of cool things you can do with functions in R\n\n\n\n\nAssign a function to a variable (foo):\n\n\nfoo &lt;- function(){\n  return(\"This is foo.\")\n}\nclass(foo)\n\n[1] \"function\"\n\nfoo\n\nfunction () \n{\n    return(\"This is foo.\")\n}\n\nfoo()\n\n[1] \"This is foo.\"\n\n\n\nYou can store functions in a list:\n\n\nfoo_list &lt;- list( \n  fun_1 = function() return(\"foo_1\"),\n  fun_2 = function() return(\"foo_2\")\n)\n\nstr(foo_list)\n\nList of 2\n $ fun_1:function ()  \n $ fun_2:function ()  \n\nfoo_list$fun_1()\n\n[1] \"foo_1\"\n\nfoo_list$fun_2()\n\n[1] \"foo_2\"\n\n\n\nYou can pass functions as arguments to other functions:\n\n\nshell_fn &lt;- function(f) f()\nshell_fn(foo_list$fun_1)\n\n[1] \"foo_1\"\n\nshell_fn(foo_list$fun_2)\n\n[1] \"foo_2\"\n\n\n\nYou can create functions inside of functions and return them as the result of a function\n\n\nfoo_wrap &lt;- function(){\n  foo_2 &lt;- function(){\n    return(\"This is foo_2.\")\n  }\n  return(foo_2)\n}\n\nfoo_wrap()\n\nfunction () \n{\n    return(\"This is foo_2.\")\n}\n&lt;environment: 0x12824dbf8&gt;\n\n(foo_wrap())()\n\n[1] \"This is foo_2.\"\n\n\nThe bottom line, you can manipulate functions as the same way as you can to a vector or a matrix.\n\n\n\n\n\nA function is pure, if it satisfies two properties:\n\nThe output only depends on the inputs, i.e. if you call it again with the same inputs, you get the same outputs. This excludes functions like runif(), read.csv(), or Sys.time() that can return different values.\nThe function has no side-effects, like changing the value of a global variable, writing to disk, or displaying to the screen. This excludes functions like print(), write.csv() and &lt;-.\n\nPure functions are much easier to reason about, but obviously have significant downsides: imagine doing a data analysis where you could not generate random numbers or read files from disk.\n\n\n\n\n\n\nImportant\n\n\n\nTo be clear, R is not formally a functional programming language as it does not require pure functions to be used when writing code.\n\n\nSo you might be asking yourself, why are we talking about this then?\nThe formal definition of a functional programming language introduces a new style of programming, namely a functional style of programming.\n\n\n\n\n\n\nNote\n\n\n\nThe key idea of a functional style is this programming style encourages programmers to write a big function as many smaller isolated functions, where each function addresses one specific task.\n\n\nYou can always adopt a functional style for certain parts of your code! For example, this style of writing code motivates more humanly readable code, and recyclable code.\n\n\"data_set.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()\n\n\"data_set2.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_different_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()"
  },
  {
    "objectID": "readings/03-functional-programming/index.html#functional-style",
    "href": "readings/03-functional-programming/index.html#functional-style",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "At a high-level, a functional style is the concept of decomposing a big problem into smaller components, then solving each piece with a function or combination of functions.\n\nWhen using a functional style, you strive to decompose components of the problem into isolated functions that operate independently.\nEach function taken by itself is simple and straightforward to understand; complexity is handled by composing functions in various ways.\n\n\n\nIn this lecture, we will focus on one type of functional technique, namely functionals, which are functions that take another function as an argument and returns a vector as output.\nFunctionals allow you to take a function that solves the problem for a single input and generalize it to handle any number of inputs. Once you learn about them, you will find yourself using them all the time in data analysis.\n\n\n\n\n\n\nExample of a functional\n\n\n\nHere’s a simple functional: it calls the function provided as input with 1000 random uniform numbers.\n\nrandomise &lt;- function(f) f(runif(1e3))\nrandomise(mean)\n\n[1] 0.5021298\n\nrandomise(mean)\n\n[1] 0.5110258\n\nrandomise(sum)\n\n[1] 518.8307\n\n\n\n\nThe chances are that you have already used a functional. You might have used for-loop replacements like base R’s lapply(), apply(), and tapply() or maybe you have used a mathematical functional like integrate() or optim().\nOne of the most common use of functionals is an alternative to for loops.\nFor loops have a bad rap in R because many people believe they are slow, but the real downside of for loops is that they’re very flexible: a loop conveys that you’re iterating, but not what should be done with the results.\n\n\nTypically it is not the for loop itself that is slow, but what you are doing inside of it. A common culprit of slow loops is modifying a data structure, where each modification generates a copy.\nIf you’re an experienced for loop user, switching to functionals is typically a pattern matching exercise. You look at the for loop and find a functional that matches the basic form. If one does not exist, do not try and torture an existing functional to fit the form you need. Instead, just leave it as a for loop! (Or once you have repeated the same loop two or more times, maybe think about writing your own functional).\nJust as it is better to use while than repeat, and it’s better to use for than while, it is better to use a functional than for.\nEach functional is tailored for a specific task, so when you recognize the functional you immediately know why it’s being used."
  },
  {
    "objectID": "readings/03-functional-programming/index.html#the-map-family",
    "href": "readings/03-functional-programming/index.html#the-map-family",
    "title": "Functional Programming with purrr",
    "section": "The map family",
    "text": "The map family\nThe most fundamental functional in the purrr package is the map(.x, .f) function. It takes a vector (.x) and a function (.f), calls the function once for each element of the vector, and returns the results in a list. In other words, map(1:3, f) is equivalent to list(f(1), f(2), f(3)).\n\nlibrary(purrr)\n\n# we create a function called \"triple\"\ntriple &lt;- function(x) x * 3\n\n# using for loop to iterate over a vector\nloop_ret &lt;- list()\nfor(i in 1:3){\n  loop_ret[i] &lt;- triple(i)\n}\nloop_ret\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 6\n\n[[3]]\n[1] 9\n\n\n\n# map implementation to iterate over a vector\nmap_eg1 &lt;- map(.x = 1:3, .f = triple)\nmap_eg2 &lt;- map(.x = 1:3, .f = function(x) triple(x)) # create an inline anonymous function\nmap_eg3 &lt;- map(.x = 1:3, .f = ~triple(.x)) # same as above, but special purrr syntax with a \"twiddle\"\n\n\nidentical(loop_ret,map_eg1)\n\n[1] TRUE\n\nidentical(loop_ret,map_eg2)\n\n[1] TRUE\n\nidentical(loop_ret,map_eg3)\n\n[1] TRUE\n\n\nOr, graphically this is what map() is doing:\n\n\n\nmap\n\n\n\n\n\n\n\n\nHow does map relate to functional programming in base R?\n\n\n\nmap() returns a list, which makes it the most general of the map family because you can put anything in a list.\nThe base equivalent to map(.x, .f) is lapply(X, FUN).\nBecause the arguments include functions (.f) besides data (.x), map() functions are considered as a convenient interface to implement functional programming.\n\n\n\nmap variants\nSometimes it is inconvenient to return a list when a simpler data structure would do, so there are four more specific variants of map that make it really a family of functions (of syntax map_*()).\n\nmap_lgl()\nmap_int()\nmap_dbl()\nmap_chr()\n\nFor example, purrr uses the convention that suffixes, like _dbl(), refer to the output. Each returns an atomic vector of the specified type:\n\n# map_chr() always returns a character vector\nmap_chr(.x = mtcars, .f = typeof)\n\n     mpg      cyl     disp       hp     drat       wt     qsec       vs \n\"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \n      am     gear     carb \n\"double\" \"double\" \"double\" \n\n# map_lgl() always returns a logical vector\nmap_lgl(.x = mtcars, .f = is.double)\n\n mpg  cyl disp   hp drat   wt qsec   vs   am gear carb \nTRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE \n\n# map_int() always returns a integer vector\nn_unique &lt;- function(x) length(unique(x))\nmap_int(.x = mtcars, .f = n_unique)\n\n mpg  cyl disp   hp drat   wt qsec   vs   am gear carb \n  25    3   27   22   22   29   30    2    2    3    6 \n\n# map_dbl() always returns a double vector\nmap_dbl(.x = mtcars, .f = mean)\n\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nAll map_*() functions can take any type of vector as input. The examples above rely on two facts:\n\nmtcars is a data.frame. In R, data.frame is a special case of list, where each column as one item of the list. Don’t confuse with each row as an item.\n\n\nclass(mtcars)\n\n[1] \"data.frame\"\n\ntypeof(mtcars)\n\n[1] \"list\"\n\n\n\nAll map functions always return an output vector the same length as the input, which implies that each call to .f must return a single value. If it does not, you will get an error:\n\n\npair &lt;- function(x) c(x, x)\nmap_dbl(.x = 1:2, .f = pair)\n\nError in `map_dbl()`:\nℹ In index: 1.\nCaused by error:\n! Result must be length 1, not 2.\n\n\nThis is similar to the error you will get if .f returns the wrong type of result:\n\nmap_dbl(1:2, as.character)\n\nError in `map_dbl()`:\nℹ In index: 1.\nCaused by error:\n! Can't coerce from a string to a double.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s assume I have a dataframe called tmp_dat. How would I use map() to calculate the mean for the columns?\n\ntmp_dat &lt;- data.frame(\n  x = 1:5,\n  y = 6:10\n)\n\n\n## try it out \n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nCan we re-write the map() function above to use tmp_data as input with the |&gt; operator?\n\n## try it out \n\n\n\n\n\nPassing arguments with ...\nIt is often convenient to pass along additional arguments to the function that you are calling.\nFor example, you might want to pass na.rm = TRUE along to mean(). One way to do that is with an anonymous function:\n\nx &lt;- list(1:5, c(1:10, NA))\nmap_dbl(x, ~ mean(.x, na.rm = TRUE))\n\n[1] 3.0 5.5\n\n\nBut because the map functions pass ... along, there is a simpler form available:\n\nmap_dbl(x, mean, na.rm = TRUE)\n\n[1] 3.0 5.5\n\n\nThis is easiest to understand with a picture: any arguments that come after f in the call to map() are inserted after the data in individual calls to f():\n\n\n\nmap\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s important to note that these arguments are not decomposed; or said another way, map() is only vectorised over its first argument.\nIf an argument after f is a vector, it will be passed along as is:\n\n\n\nmap\n\n\n\n\n\n\nStratified analysis with map\nBefore we go on to explore more map variants, let’s take a quick look at how you tend to use multiple purrr functions to solve a moderately realistic problem: fitting a model to each subgroup and extracting a coefficient of the model.\nFor this toy example, I will break the mtcars data set down into groups defined by the number of cylinders, using the base split function:\n\n# different numbers of cylinders\nunique(mtcars$cyl) \n\n[1] 6 4 8\n\n\n\nby_cyl &lt;- split(mtcars, mtcars$cyl)\nlength(by_cyl)\n\n[1] 3\n\nstr(by_cyl)\n\nList of 3\n $ 4:'data.frame':  11 obs. of  11 variables:\n  ..$ mpg : num [1:11] 22.8 24.4 22.8 32.4 30.4 33.9 21.5 27.3 26 30.4 ...\n  ..$ cyl : num [1:11] 4 4 4 4 4 4 4 4 4 4 ...\n  ..$ disp: num [1:11] 108 146.7 140.8 78.7 75.7 ...\n  ..$ hp  : num [1:11] 93 62 95 66 52 65 97 66 91 113 ...\n  ..$ drat: num [1:11] 3.85 3.69 3.92 4.08 4.93 4.22 3.7 4.08 4.43 3.77 ...\n  ..$ wt  : num [1:11] 2.32 3.19 3.15 2.2 1.61 ...\n  ..$ qsec: num [1:11] 18.6 20 22.9 19.5 18.5 ...\n  ..$ vs  : num [1:11] 1 1 1 1 1 1 1 1 0 1 ...\n  ..$ am  : num [1:11] 1 0 0 1 1 1 0 1 1 1 ...\n  ..$ gear: num [1:11] 4 4 4 4 4 4 3 4 5 5 ...\n  ..$ carb: num [1:11] 1 2 2 1 2 1 1 1 2 2 ...\n $ 6:'data.frame':  7 obs. of  11 variables:\n  ..$ mpg : num [1:7] 21 21 21.4 18.1 19.2 17.8 19.7\n  ..$ cyl : num [1:7] 6 6 6 6 6 6 6\n  ..$ disp: num [1:7] 160 160 258 225 168 ...\n  ..$ hp  : num [1:7] 110 110 110 105 123 123 175\n  ..$ drat: num [1:7] 3.9 3.9 3.08 2.76 3.92 3.92 3.62\n  ..$ wt  : num [1:7] 2.62 2.88 3.21 3.46 3.44 ...\n  ..$ qsec: num [1:7] 16.5 17 19.4 20.2 18.3 ...\n  ..$ vs  : num [1:7] 0 0 1 1 1 1 0\n  ..$ am  : num [1:7] 1 1 0 0 0 0 1\n  ..$ gear: num [1:7] 4 4 3 3 4 4 5\n  ..$ carb: num [1:7] 4 4 1 1 4 4 6\n $ 8:'data.frame':  14 obs. of  11 variables:\n  ..$ mpg : num [1:14] 18.7 14.3 16.4 17.3 15.2 10.4 10.4 14.7 15.5 15.2 ...\n  ..$ cyl : num [1:14] 8 8 8 8 8 8 8 8 8 8 ...\n  ..$ disp: num [1:14] 360 360 276 276 276 ...\n  ..$ hp  : num [1:14] 175 245 180 180 180 205 215 230 150 150 ...\n  ..$ drat: num [1:14] 3.15 3.21 3.07 3.07 3.07 2.93 3 3.23 2.76 3.15 ...\n  ..$ wt  : num [1:14] 3.44 3.57 4.07 3.73 3.78 ...\n  ..$ qsec: num [1:14] 17 15.8 17.4 17.6 18 ...\n  ..$ vs  : num [1:14] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ am  : num [1:14] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ gear: num [1:14] 3 3 3 3 3 3 3 3 3 3 ...\n  ..$ carb: num [1:14] 2 4 3 3 3 4 4 4 2 2 ...\n\n\nThis creates a list of three data frames: the cars with 4, 6, and 8 cylinders respectively.\nFirst, imagine we want to fit a linear model to understand how the miles per gallon (mpg) associated with the weight (wt). We can do this for all observations in mtcars using:\n\nlm(mpg ~ wt, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\n\nThe following code shows how you might do that with purrr, which returns a list with output from each lm fit for each cylinder:\n\nby_cyl |&gt;\n  map(.f = ~ lm(mpg ~ wt, data = .x))\n\n$`4`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n     39.571       -5.647  \n\n\n$`6`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n      28.41        -2.78  \n\n\n$`8`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n     23.868       -2.192  \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s say we wanted to extract the second coefficient (i.e. the slope). Using all the observations in mtcars (i.e. ignoring cyl), it would be something like this:\n\nlm.fit &lt;- lm(mpg ~ wt, data = mtcars)\ncoef(lm.fit)\n\n(Intercept)          wt \n  37.285126   -5.344472 \n\ncoef(lm.fit)[2]\n\n       wt \n-5.344472 \n\n\nHow would we do this with the map() family functions if we wanted to stratify the analysis for each cyl?\nHint: you can use two map functions (e.g. map() and map_dbl(2) where you can extract a specific element by a specific name or position).\n\n## try it out \n\n\n\nOr, of course, you could use a for loop:\n\nslopes &lt;- double(length(by_cyl))\nfor (i in seq_along(by_cyl)) {\n  model &lt;- lm(mpg ~ wt, data = by_cyl[[i]])\n  slopes[[i]] &lt;- coef(model)[[2]]\n}\nslopes\n\n[1] -5.647025 -2.780106 -2.192438\n\n\nIt’s interesting to note that as you move from purrr to base apply functions to for loops you tend to do more and more in each iteration.\nIn purrr we iterate 3 times (map(), map(), map_dbl()), and with a for loop we iterate once. I prefer more, but simpler, steps because I think it makes the code easier to understand and later modify.\n\n\n\n\n\n\nQuestion\n\n\n\nNow we are interested in calculating the average mpg for vehicles with different numbers of cylinders. How can we use map functions to do this? You can return a list.\nHint: You can use the syntax x$mpg where x is a dataframe within a map function.\n\n## try it out \n\n\n\n\n\nMatrix as the output\nThe map family include functions that organize the output in different data structures, whose names follow the pattern map_*. As we’ve seen, the map function return a list. The following functions will return a vector of a specific kind, e.g. map_lgl returns a vector of logical variables, map_chr returns a vector of strings.\nIt is also possible to return the the results as data frames by\n\nrow binding (map_dfr) or\ncolumn binding (map_dfc)\n\n\nby_cyl |&gt; \n  map_dbl(.f = ~mean(.x$mpg)) # returns a vector of doubles\n\n       4        6        8 \n26.66364 19.74286 15.10000 \n\nby_cyl |&gt; \n  map_dfr(.f = ~colMeans(.x)) # return a data frame by row binding\n\n# A tibble: 3 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  26.7     4  105.  82.6  4.07  2.29  19.1 0.909 0.727  4.09  1.55\n2  19.7     6  183. 122.   3.59  3.12  18.0 0.571 0.429  3.86  3.43\n3  15.1     8  353. 209.   3.23  4.00  16.8 0     0.143  3.29  3.5 \n\nby_cyl |&gt; \n  map_dfc(.f = ~colMeans(.x)) # return a data frame by col binding\n\n# A tibble: 11 × 3\n       `4`     `6`     `8`\n     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1  26.7    19.7    15.1  \n 2   4       6       8    \n 3 105.    183.    353.   \n 4  82.6   122.    209.   \n 5   4.07    3.59    3.23 \n 6   2.29    3.12    4.00 \n 7  19.1    18.0    16.8  \n 8   0.909   0.571   0    \n 9   0.727   0.429   0.143\n10   4.09    3.86    3.29 \n11   1.55    3.43    3.5"
  },
  {
    "objectID": "readings/03-functional-programming/index.html#more-map-variants",
    "href": "readings/03-functional-programming/index.html#more-map-variants",
    "title": "Functional Programming with purrr",
    "section": "More map variants",
    "text": "More map variants\nThere are 23 primary variants of map(). So far, we have learned about five (map(), map_lgl(), map_int(), map_dbl() and map_chr()). That means that you have got 18 (!!) more to learn. That sounds like a lot, but fortunately the design of purrr means that you only need to learn five new ideas:\n\nOutput same type as input with modify()\nIterate over two inputs with map2().\nIterate with an index using imap()\nReturn nothing with walk().\nIterate over any number of inputs with pmap().\n\nThe map family of functions has orthogonal input and outputs, meaning that we can organise all the family into a matrix, with inputs in the rows and outputs in the columns. Once you have mastered the idea in a row, you can combine it with any column; once you have mastered the idea in a column, you can combine it with any row. That relationship is summarised in the following table:\n\n\n\n\n\n\n\n\n\n\n\nList\nAtomic\nSame type\nNothing\n\n\n\n\nOne argument\nmap()\nmap_lgl(), …\nmodify()\nwalk()\n\n\nTwo arguments\nmap2()\nmap2_lgl(), …\nmodify2()\nwalk2()\n\n\nOne argument + index\nimap()\nimap_lgl(), …\nimodify()\niwalk()\n\n\nN arguments\npmap()\npmap_lgl(), …\n—\npwalk()\n\n\n\n\nmodify()\nImagine you wanted to double every column in a data frame. You might first try using map(), but map() always returns a list:\n\ndf &lt;- data.frame(\n  x = 1:3,\n  y = 6:4\n)\n\nmap(df, ~ .x * 2)\n\n$x\n[1] 2 4 6\n\n$y\n[1] 12 10  8\n\n\nIf you want to keep the output as a data frame, you can use modify(), which always returns the same type of output as the input:\n\nmodify(df, ~ .x * 2)\n\n  x  y\n1 2 12\n2 4 10\n3 6  8\n\n\n\n\n\n\n\n\nNote\n\n\n\nDespite the name, modify() doesn’t modify in place, it returns a modified copy, so if you wanted to permanently modify df, you’d need to assign it:\n\ndf &lt;- modify(df, ~ .x * 2)\n\n\n\n\n\nmap2() and friends\nmap() is vectorised over a single argument, .x.\nThis means it only varies .x when calling .f, and all other arguments are passed along unchanged, thus making it poorly suited for some problems.\nFor example, how would you find a weighted mean when you have a list of observations and a list of weights? Imagine we have the following data:\n\nxs &lt;- map(1:8, ~ runif(10))\nxs[[1]][[1]] &lt;- NA\nws &lt;- map(1:8, ~ rpois(10, 5) + 1)\n\nYou can use map_dbl() to compute the unweighted means:\n\nmap_dbl(.x = xs, .f = mean)\n\n[1]        NA 0.4464825 0.4806867 0.5177861 0.4752695 0.6147369 0.4525804\n[8] 0.5614233\n\n\nBut passing ws as an additional argument does not work because arguments after .f are not transformed:\n\nmap_dbl(x. = xs, .f = weighted.mean, w = ws)\n\nError in map_dbl(x. = xs, .f = weighted.mean, w = ws): argument \".x\" is missing, with no default\n\n\nWe need a new tool: a map2(), which is vectorised over two arguments. This means both .x and .y are varied in each call to .f:\n\nmap2_dbl(.x = xs, .y = ws, .f = weighted.mean)\n\n[1]        NA 0.4548610 0.4449436 0.5327727 0.4077519 0.5728543 0.3940515\n[8] 0.5399974\n\n\nThe arguments to map2() are slightly different to the arguments to map() as two vectors come before the function, rather than one. Additional arguments still go afterwards:\n\nmap2_dbl(.x = xs, .y = ws, .f = weighted.mean, na.rm = TRUE)\n\n[1] 0.5354556 0.4548610 0.4449436 0.5327727 0.4077519 0.5728543 0.3940515\n[8] 0.5399974\n\n\n\n\nwalk() and friends\nMost functions are called for the value that they return, so it makes sense to capture and store the value with a map() function.\nBut some functions are called primarily for their side-effects (e.g. cat(), write.csv(), or ggsave()) and it does not make sense to capture their results.\nLet’s consider the example of saving a dataset. In this case, map will force an output, e.g. NULL. One can consider using walk instead. The function walk (and walk2 for more than two inputs) behaves exactly the same as map but does not output anything.\n\ntmp_fldr &lt;- tempdir()\n\nmap2(.x = by_cyl,\n     .y = 1:length(by_cyl),\n     .f = ~saveRDS(.x, \n                   file = paste0(tmp_fldr, \"/\",.y, \".rds\"))\n)\n\n$`4`\nNULL\n\n$`6`\nNULL\n\n$`8`\nNULL\n\n# No output\nwalk2(.x = by_cyl,\n      .y = (1:length(by_cyl)),\n      .f = ~saveRDS(.x, \n                    file = paste0(tmp_fldr, \"/\",.y, \".rds\"))\n)"
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "Important reading materials",
    "section": "",
    "text": "The following contains relevant reading materials you should read prior to each class:\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2024-10-24\n\n\nAuthoring projects and websites with Quarto\n\n\nStephanie Hicks\n\n\n\n\n2024-11-05\n\n\nFunctional Programming with purrr\n\n\nStephanie Hicks\n\n\n\n\n2024-11-07\n\n\nRetrieving data from APIs with httr2\n\n\nStephanie Hicks\n\n\n\n\n2024-11-07\n\n\nScraping data from the web with rvest\n\n\nStephanie Hicks\n\n\n\n\n2024-11-12\n\n\nRelational databases and SQL basics\n\n\nStephanie Hicks\n\n\n\n\n2024-11-19\n\n\nStrategies for dealing with large data\n\n\nStephanie Hicks\n\n\n\n\n2024-11-21\n\n\nObject Oriented Programming\n\n\nStephanie Hicks\n\n\n\n\n2024-12-03\n\n\nBuilding dashboards with flexdashboard\n\n\nStephanie Hicks\n\n\n\n\n2024-12-10\n\n\nProgramming in Python with reticulate\n\n\nStephanie Hicks\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/03-project/index.html",
    "href": "projects/03-project/index.html",
    "title": "Project 3",
    "section": "",
    "text": "Background\nDue date: November 22 at 11:59pm\nThe goal of this assignment is to practice some of the skills we have been learning about in class around working with relational databases and machine learning paradigms. Specifically, you will create a new SQL database, write SQL queries to the database, explore and summarize the data, train a prediction model, and summarize your findings.\n\nTo submit your project\nYou need to create a private GitHub Classroom repository (only one per group) for you and your partner, which will be posted in CoursePlus. This creates an empty GitHub repository. You need to show all your code and submit both the .qmd file and the rendered HTML file. Please include section headers for each of the components below. All plots should have titles, subtitles, captions, and human-understandable axis labels. The TAs will grade the contents in the GitHub Classroom repo by cloning the repo and checking for all the things described below.\n\n\n\n\n\n\nImportant\n\n\n\nBecause you will work with a partner, please be sure to include the names, emails, and JHED IDs for both individuals in your submitted work.\nBoth of you should commit to the repository!\n\n\n\n\n\nData\nYou are welcome to pick your own datasets, but here are some ideas (which you are not limited to):\n\nnycflights13 dataset – contains data on flights that departed NYC in 2013, including tables for weather, planes, airports, and airlines. This dataset is useful for exploring what causes delays. To practice SQL queries, you could consider aggregations and group by queries across airlines or days of the week. To practice machine learning, you could predict flight delays. Also, here are two related datasets you might interesting too:\n\nnycflights for flights departing from NYC in the last year.\nanyflights for flights departing from any airport in any year.\n\nIMDB dataset – Contains data on movies, including tables for titles, ratings, cast, and crew. This dataset is useful for exploring movie information, reviews, and ratings. To practice SQL queries, you could consider nested queries, joins, filtering, and text-based queries on genres or keywords. To practice machine learning, you could predict ratings.\nLahman Baseball dataset – contains historical baseball data, with tables for teams, players, games, and statistics. To practice SQL queries, you could consider aggregation, and time-based queries to calculate baseball statistics. To practice machine learning, you could predict the number of runs a team will score.\nWorld Bank Open datasets – contains extensive economic and social data on countries worldwide, such as population, GDP, education, life expectancy, and health indicators. To practice SQL queries, you could perform time-based queries such as filtering by regions or income levels, and aggregating metrics by country or year. To practice machine learning, you could predict life expectancy.\n\n\n\n\n\n\n\nImportant things to consider when thinking about which dataset to pick\n\n\n\n\nYou will either use an SQL database with at least three tables in it or you will make a SQL database with at least 3 tables in it. So you need to pick a dataset with at least 3 tables available.\nYou will use this data to practice SQL queries (Part 1) and to practice building a machine learning model (Part 2). So you want to make sure you consider both parts while pondering which dataset to use (e.g. What kind of SQL queries might we use with this database? What kind of data visualization do we want to make? What would our prediction task be?).\n\n\n\n\n\nPart 1\nIn this part, you and your partner will use the DBI and RSQLite packages to write SQL queries, explore and summarize the data, visualize the data, and summarize your findings.\nUsing the data you picked, choose a question to investigate. For example, if you are using the nycflights13 dataset, maybe you want to understand if there are certain days of the week that flights are more delayed than other days of the week. Describe what is the question you aim to answer with the data and what you want to visualize.\n\nIf it’s already a SQL database, read into R using the DBI and RSQLite packages. If it’s not already a SQL database, create a new SQL database and use the dbWriteTable() function to add at minimum three tables to the SQL database.\nWrite three SQL queries using dbGetQuery() to explore and summarize the data. You must use at least five different SQL functions (e.g. SELECT, GROUP BY, DISTINCT, SUM, etc).\nWrite two SQL queries to create new features from existing data. For example, if using nycflights13, you could think about how to\n\nBin departure times into time-of-day categories (e.g., morning, afternoon, evening).\nLag features like the previous day’s average delay by carrier, which can be helpful for predictions.\nMerge additional weather data (such as hourly temperature, precipitation, etc., if available). e.g. this could be done using SQL joins.\n\nVisualize your data by creating a plot with ggplot2. For example, if using nycflights13, you could think about how to visualize delays by month, carrier, or weather conditions.\nReport your findings. Provide a paragraph summarizing your methods and key findings. Include any limitations or potential biases in your analysis. Be sure to comment and organize your code so is easy to understand what you are doing.\n\n\n\n\n\n\n\nImportant\n\n\n\nAt the end of the data analysis, list out each of the SQL functions you used to help the TA with respect to making sure you met all the requirements described above.\n\n\n\n\nPart 2\nIn this part, you and your partner will use use caret or tidymodels to train a predictive model for a task or outcome, perform model evaluation, and summarize your findings. For this part, you can use the data directly in R as standard dataframes or tibbles. You do not need to build the models In this section, you must do the following when building your prediction model:\n\nSplit the data into training and test sets.\nChoose a machine learning model appropriate for the task (e.g. consider if it’s a binary or continuous outcome and choose an appropriate model). For example, if you are using the nycflights13 dataset, you could could pick\n\nLogistic Regression (if predicting delay as a binary outcome, e.g., delay/no delay).\nLinear Regression (if predicting the length of delay in minutes).\nDecision Trees or Random Forests (for both binary classification or regression).\n\nTrain the model using caret or tidymodels in R using the training data.\nAssess the model performance both the training and test datasets using metrics like Accuracy or area under the curve (AUC) (if classification) or root mean squared error (RMSE) (if regression).\n\nFinally, report your findings. For example, if you are predicting flight delays, provide 1-2 practical recommendations for reducing delays. Broadly, provide a paragraph summarizing your methods and key findings. Include limitations or potential biases in training and evaluation your machine learning model. Be sure to comment and organize your code so is easy to understand what you are doing."
  },
  {
    "objectID": "projects/01-project/index.html",
    "href": "projects/01-project/index.html",
    "title": "Project 1",
    "section": "",
    "text": "Due date: November 8 at 11:59pm\nThe goal of this assignment is to practice some of the skills we have been learning about in class around quarto, command-line, and version control by building and deploying a website. You also are asked to practice with some command-line skills more formally.\n\n\nPlease use this Quarto file (.qmd) and fill in the requested components by adding the URLs pointing to the GitHub repositories and deployed websites. Render this file to a HTML file.\nYou will push the .qmd file and rendered HTML file to a private GitHub repostory on GitHub classroom. The link to create a private GitHub repository for yourself to complete Project 1 will be posted in CoursePlus (Note: this creates an empty repository. You will need to clone the reopository locally, add your code, and push your code from your local repo to the remote repository on GitHub Classroom when ready). Please show all your code, if relevant to a section.\nThe TAs will grade the contents in the GitHub repo by cloning the repo and checking for all the things described below."
  },
  {
    "objectID": "projects/01-project/index.html#create-a-github-repo-for-your-website",
    "href": "projects/01-project/index.html#create-a-github-repo-for-your-website",
    "title": "Project 1",
    "section": "1. Create a GitHub repo for your website",
    "text": "1. Create a GitHub repo for your website\nCreate a new public GitHub repository titled biostat777-intro-&lt;firstname&gt;-&lt;lastname&gt; (where you replace &lt;firstname&gt; with your first name and &lt;lastname&gt; with your last name) in your own personal GitHub account (e.g. https://github.com/&lt;yourgithubusername&gt;/biostat777-intro-&lt;firstname&gt;-&lt;lastname&gt;)."
  },
  {
    "objectID": "projects/01-project/index.html#build-a-website-using-quarto",
    "href": "projects/01-project/index.html#build-a-website-using-quarto",
    "title": "Project 1",
    "section": "2. Build a website using Quarto",
    "text": "2. Build a website using Quarto\nCreate a new project locally within RStudio or VSCode and build a website for yourself. Your website should include the following:\n\nA home/landing page. This is home page that someone will land on your website. At minimum it should include your name, a short summary about yourself (max 2-3 sentences), and a picture of something you enjoy to do for fun (or a picture of yourself if you are comfortable sharing one).\nA page titled ‘About’. This page should describe who you are in greater detail. It could include your professional interests and your educational and/or professional background and/or experience. It could also include any personal information you feel conformable sharing on the website.\nA data analysis page called ‘Example analysis’. You can pick any dataset you wish you analyze. In this webpage, you will analyze a dataset and summarize the results. The requirements for this webpage are the following:\n\nYou must describe what is the question you aim to answer with the data and data analysis.\nYou must describe who is the intended audience for the data analysis.\nYou must describe and link to where the original data come from that you chose.\nYou must include a link to a data dictionary for the data or create one inside the webpage.\nYour analysis must include some minimal form of data wrangling with you using at least five different functions from dplyr or tidyr.\nYour analysis should include at least three plots with you using at least three different geom_*() functions from ggplot2 (or another package with geom_*() functions).\nPlots should have titles, subtitles, captions, and human-understandable axis labels.\nAt least one plot should using a type of faceting (facet_grid() or facet_wrap()).\nYour analysis must include one image or table (not one you created yourself, but one you have saved locally or one from the web).\nYour analysis must include at least two different callout blocks.\nYour analysis must include a .bib file, which you use to reference at least three unique citations. For example, it could be to a website or paper from where the original data came from or it could be to a paper describing a method you are using to analyze the data.\nYour analysis must include the use of at least 1 margin content.\nYou must summarize your analysis and/or results with a paragraph (4-6 sentences).\nAt the end of the data analysis, list out each of the functions you used from each of the packages (dplyr, tidyr, and ggplot2) to help the TA with respect to making sure you met all the requirements described above."
  },
  {
    "objectID": "projects/01-project/index.html#include-a-readme.md-file",
    "href": "projects/01-project/index.html#include-a-readme.md-file",
    "title": "Project 1",
    "section": "3. Include a README.md file",
    "text": "3. Include a README.md file\nYour local repository should include a README.md file describing who is the author of the website and a link to the website after it has been deployed. Other things you might include are the technical details for how the website was created and/or deployed."
  },
  {
    "objectID": "projects/01-project/index.html#deploy-your-website",
    "href": "projects/01-project/index.html#deploy-your-website",
    "title": "Project 1",
    "section": "4. Deploy your website",
    "text": "4. Deploy your website\nDeploy your website e.g. using Quarto Pub, GitHub pages, or Netlify, etc. (Note: Deploying your website to RPubs will not be accepted)."
  },
  {
    "objectID": "projects/01-project/index.html#share-your-website",
    "href": "projects/01-project/index.html#share-your-website",
    "title": "Project 1",
    "section": "5. Share your website",
    "text": "5. Share your website\nGo to the Discussion Board in CoursePlus and write a short post with a link (URL) to your website (and URL to the corresponding GitHub repository) that you created. Also, list the URLs below for the purposes of grading.\nAs you read the introductions from other folks in the class, feel free to comment/reply using Discussion board.\n\nLink to your GitHub repository: [Delete this text and replace the text with the link to the public GitHub repo you created above for your website]\nLink to your deployed website: [Delete this and replace the text with the link to the public deployed website you created above]"
  },
  {
    "objectID": "lectures/12-programming-in-python/index.html",
    "href": "lectures/12-programming-in-python/index.html",
    "title": "Programming with Python with reticulate",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please install:\n\nreticulate - this provides an interface between R and python\n\nYou can do this by calling\n\ninstall.packages(c(\"reticulate\"))\n\n\n\nIn addition, please read through the pre-reading:\n\nLecture 12: Programming in Python with reticulate\n\nAnd if there is time, these are useful too:\n\nhttps://rstudio.github.io/reticulate\nhttps://py-pkgs.org/02-setup\nThe Python Tutorial"
  },
  {
    "objectID": "lectures/12-programming-in-python/index.html#acknowledgements",
    "href": "lectures/12-programming-in-python/index.html#acknowledgements",
    "title": "Programming with Python with reticulate",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://rstudio.github.io/reticulate"
  },
  {
    "objectID": "lectures/12-programming-in-python/index.html#learning-objectives",
    "href": "lectures/12-programming-in-python/index.html#learning-objectives",
    "title": "Programming with Python with reticulate",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nInstall the reticulate R package on your machine (I’m assuming you have python installed already)\nLearn about reticulate to work interoperability between Python and R\nBe able to translate between R and Python objects"
  },
  {
    "objectID": "lectures/12-programming-in-python/index.html#slides",
    "href": "lectures/12-programming-in-python/index.html#slides",
    "title": "Programming with Python with reticulate",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "lectures/12-programming-in-python/index.html#additional-practice",
    "href": "lectures/12-programming-in-python/index.html#additional-practice",
    "title": "Programming with Python with reticulate",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nTry to use tab completion for a function.\nTry to install and load a different python module in R using import()."
  },
  {
    "objectID": "lectures/10-flexdashboard/index.html",
    "href": "lectures/10-flexdashboard/index.html",
    "title": "Building dashboards with flexdashboard",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please install three additional packages:\n\nflexdashboard - this provides tools for easily building dashboards\nDT - this provides built-in data display functionality\nshiny - this provides functionality to create interactive dashboard elements\n\nYou can do this by calling\n\ninstall.packages(c(\"flexdashboard\", \"DT\", \"shiny\"))\n\n\n\nIn addition, please read through\n\nInformation about creating dashboards: https://pkgs.rstudio.com/flexdashboard\nExamples of flexdashboard dashboards: https://pkgs.rstudio.com/flexdashboard/articles/examples"
  },
  {
    "objectID": "lectures/10-flexdashboard/index.html#acknowledgements",
    "href": "lectures/10-flexdashboard/index.html#acknowledgements",
    "title": "Building dashboards with flexdashboard",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\n“R for Data Science” by Grolemund and Wickham, sections 29.6 and 29.7.2. It is based on lecture notes initially developed by Margaret Taub and Leah Jager."
  },
  {
    "objectID": "lectures/10-flexdashboard/index.html#learning-objectives",
    "href": "lectures/10-flexdashboard/index.html#learning-objectives",
    "title": "Building dashboards with flexdashboard",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nKnow how to create a basic dashboard to display data analysis elements using flexdashboard\nAdd interactive elements to your dashboard using tools from the shiny package\nHave resources to assist you in developing your own more complex dashboard to clearly present data and interactive elements"
  },
  {
    "objectID": "lectures/10-flexdashboard/index.html#slides",
    "href": "lectures/10-flexdashboard/index.html#slides",
    "title": "Building dashboards with flexdashboard",
    "section": "Slides",
    "text": "Slides\n\nLecture 10: Building dashboards with flexdashboard"
  },
  {
    "objectID": "lectures/10-flexdashboard/index.html#deploying-a-dashboard",
    "href": "lectures/10-flexdashboard/index.html#deploying-a-dashboard",
    "title": "Building dashboards with flexdashboard",
    "section": "Deploying a dashboard",
    "text": "Deploying a dashboard\nHere are some helpful pointers for getting a free Shinyapps.io account and then publishing your dashboard to the web:\n\n\n\n\n\n\nDeploying a Shiny app in RStudio\n\n\n\n\nSign up for a free account on http://www.shinyapps.io/\nWithin RStudio, install the rsconnect package: install.packages(\"rsconnect\")\nWithin RStudio Cloud, select “Tools” then “Global Options…” and then select “Publishing” from the left-hard menu. (Within the non-cloud RStudio, under the “Preferences” menu, click on “Publishing”.) Click the “Connect” button next to the publishing accounts box and then “Shinypps.io” to link your shinyapps.io account to your RStudio. Click on “Shinyapps.io” from the pop-up menu, and then follow the instructions to link your account. This involves copying and pasting a token from your account into the box in R Studio.\nNow you are ready to publish! Click the “Run Document” button to create your app; then click “Publish” in the upper right hand corner of your app (the publish icon is a blue circle with blue curves around it). Choose “Publish just this document” from the pop-up menu. Make sure the selected destination account is your shinyapps.io account. You can change the name of the app if you want. Then click publish!\nIf you want to delete the app (unpublish it), you need to do this from within your shinyapps.io account. Go to http://www.shinyapps.io/ and log in to your account. Click on applications to manage your applications. You must first archive your app before you can delete it."
  },
  {
    "objectID": "lectures/10-flexdashboard/index.html#stephanies-dashboard",
    "href": "lectures/10-flexdashboard/index.html#stephanies-dashboard",
    "title": "Building dashboards with flexdashboard",
    "section": "Stephanie’s dashboard",
    "text": "Stephanie’s dashboard\nI have deployed the Old Faithful dashboard to my own Shiny account and linked the public github repo (on GitHub Classroom) to give as an example:\n\nDeployed dashboard: https://stephaniehicks.shinyapps.io/OldFaithfulGeyser\nGitHub repository: https://github.com/jhu-statprogramming-fall-2024/project4-stephanieteam"
  },
  {
    "objectID": "lectures/10-flexdashboard/index.html#additional-practice",
    "href": "lectures/10-flexdashboard/index.html#additional-practice",
    "title": "Building dashboards with flexdashboard",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nStarting with the GeyserFlexDashboard.Rmd file, modify the file to also create a data display related to the waiting variable. This display could be on another tab, or you could create an entire new page. You could allow the user to specify if they want a histogram or a boxplot with a dropdown selector.\nAlternatively, keep the layout simple with a single pane for the plot, but allow the user to select whether they want to display a histogram of the waiting variable or the eruptions variable. Make sure to update the main plot label to indicate the selected variable.\nSimilar modifications can be made to the MPGFlexDashboard.Rmd example. Create an interface that allows the user to select two different variables from the mpg data set and then create an appropriate data display to illustrate the relationship between these two variables, updating any plot labels to reflect the selected variables."
  },
  {
    "objectID": "lectures/08-oop-paradigm/index.html",
    "href": "lectures/08-oop-paradigm/index.html",
    "title": "Object-oriented programming",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please read through:\n\nLecture 08: Object-Oriented Programming\n\n\n\nIn addition, please have a brief look through these four sections of the book:\n\nhttps://adv-r.hadley.nz/oo (Chapters 12-16)"
  },
  {
    "objectID": "lectures/08-oop-paradigm/index.html#acknowledgements",
    "href": "lectures/08-oop-paradigm/index.html#acknowledgements",
    "title": "Object-oriented programming",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://adv-r.hadley.nz/oo (Chapters 12-16)"
  },
  {
    "objectID": "lectures/08-oop-paradigm/index.html#learning-objectives",
    "href": "lectures/08-oop-paradigm/index.html#learning-objectives",
    "title": "Object-oriented programming",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nRecognize the primary object-oriented systems in R: S3, S4, R6, and Reference Classes (RC).\nUnderstand the terminology of a class, object, method, constructor and generic.\nBe able to create a new S3 or S4 with generics and methods"
  },
  {
    "objectID": "lectures/08-oop-paradigm/index.html#slides",
    "href": "lectures/08-oop-paradigm/index.html#slides",
    "title": "Object-oriented programming",
    "section": "Slides",
    "text": "Slides\n\nLecture 08: Object-oriented programming"
  },
  {
    "objectID": "lectures/08-oop-paradigm/index.html#summary",
    "href": "lectures/08-oop-paradigm/index.html#summary",
    "title": "Object-oriented programming",
    "section": "Summary",
    "text": "Summary\n\nR has three object oriented systems: S3, S4, and Reference Classes.\nReference Classes are the most similar to classes and objects in other programming languages.\nClasses are blueprints for an object.\nObjects are individual instances of a class.\nMethods are functions that are associated with a particular class.\nConstructors are methods that create objects.\nEverything in R is an object.\nS3 is a liberal object oriented system that allows you to assign a class to any object.\nS4 is a more strict object oriented system that build upon ideas in S3."
  },
  {
    "objectID": "lectures/08-oop-paradigm/index.html#additional-practice",
    "href": "lectures/08-oop-paradigm/index.html#additional-practice",
    "title": "Object-oriented programming",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\nhttps://adv-r.hadley.nz/s3.html#exercises-38\nhttps://adv-r.hadley.nz/s3.html#exercises-39\nhttps://adv-r.hadley.nz/s3.html#exercises-40\nhttps://adv-r.hadley.nz/s3.html#exercises-42"
  },
  {
    "objectID": "lectures/06-ml-paradigms-workflows/index.html",
    "href": "lectures/06-ml-paradigms-workflows/index.html",
    "title": "Machine learning paradigms and workflows",
    "section": "",
    "text": "No Pre-lecture readings today! Just focus on Project 2 and Project 4 (Part 2) – both due tomorrow (Friday November 15th at 11:59pm)."
  },
  {
    "objectID": "lectures/06-ml-paradigms-workflows/index.html#acknowledgements",
    "href": "lectures/06-ml-paradigms-workflows/index.html#acknowledgements",
    "title": "Machine learning paradigms and workflows",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nAn Introduction to Statistical Learning"
  },
  {
    "objectID": "lectures/06-ml-paradigms-workflows/index.html#learning-objectives",
    "href": "lectures/06-ml-paradigms-workflows/index.html#learning-objectives",
    "title": "Machine learning paradigms and workflows",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nState the differences between machine learning paradigms including supervised, unsupervised, semi-supervised, and reinforcement Learning\nDescribe some common methods for each of the ML paradigms\nDescribe some evaluation techniques"
  },
  {
    "objectID": "lectures/06-ml-paradigms-workflows/index.html#slides",
    "href": "lectures/06-ml-paradigms-workflows/index.html#slides",
    "title": "Machine learning paradigms and workflows",
    "section": "Slides",
    "text": "Slides\n\nLecture 06: Machine learning paradgims"
  },
  {
    "objectID": "lectures/04-data-collection/index.html",
    "href": "lectures/04-data-collection/index.html",
    "title": "Data Collection",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please install the following R packages\n\njsonlite (https://jeroen.cran.dev/jsonlite)\nhttr2 (https://httr2.r-lib.org)\nrvest (https://rvest.tidyverse.org) (should be installed already with the tidyverse)\n\n\ninstall.packages(\"jsonlite\")\ninstall.packages(\"httr2\")\n\n\n\nIn addition, please read through\n\nData collection with APIs\nData collection from HTMLs"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#acknowledgements",
    "href": "lectures/04-data-collection/index.html#acknowledgements",
    "title": "Data Collection",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://jeroen.cran.dev/jsonlite\nhttps://httr2.r-lib.org\nhttps://rvest.tidyverse.org"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#learning-objectives",
    "href": "lectures/04-data-collection/index.html#learning-objectives",
    "title": "Data Collection",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nIntroduce the JSON file format\nDemonstrate how to convert JSON file format into data frames in R\nKnow what does API mean and state four types of API architectures\nPractice with the GitHub API and make authenticated requests\nPractice a range of rvest functions to scrape data from HTML pages\nRecognize various HTML elements on the page (text, links, images, lists, etc.)"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#slides",
    "href": "lectures/04-data-collection/index.html#slides",
    "title": "Data Collection",
    "section": "Slides",
    "text": "Slides\n\nLecture 04: Data collection paradigms"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#part-1-extracting-tables",
    "href": "lectures/04-data-collection/index.html#part-1-extracting-tables",
    "title": "Data Collection",
    "section": "Part 1: Extracting tables",
    "text": "Part 1: Extracting tables\n\nUse html_table to extract a table containing the FIFA Women’s World Cup and the corresponding runner-up for each World Cup year. This is the first table under “Results”.\nShow the first few rows with head().\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# This is the URL we want to scrape data from\nurl &lt;- \"https://en.wikipedia.org/wiki/FIFA_Women%27s_World_Cup\"\n\n# This is a local HTML file to avoid scraping data from it each time I compile this quarto file. \nhtml_worldcup &lt;- here::here(\"lectures\",\"04-data-collection\", \"world-cup.html\")\n\nif(!file.exists(html_worldcup)){\n  page &lt;- read_html(url)\n  write_html(page, html_worldcup)\n} else {\n  page &lt;- read_html(html_worldcup)\n}\n\n\n# Extract the table and show the first few rows\npage %&gt;%\n  html_table() %&gt;%\n  .[[5]] %&gt;% \n  head()\n\n# A tibble: 6 × 13\n  X1    X2     X3    X4    X5    X6    X7    X8    X9    X10   X11   X12   X13  \n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt;\n1 Ed.   Year   Hosts NA    Final Final Final NA    Thir… Thir… Thir… NA    No. …\n2 Ed.   Year   Hosts NA    Cham… Score Runn… NA    Thir… Score Four… NA    No. …\n3 1     1991   China NA    Unit… 2–1   Norw… NA    Swed… 4–0   Germ… NA    12   \n4 2     1995   Swed… NA    Norw… 2–0   Germ… NA    Unit… 2–0   China NA    12   \n5 3     1999   Unit… NA    Unit… 0–0 … China NA    Braz… 0–0[… Norw… NA    16   \n6 4     2003[… Unit… NA    Germ… 2–1 … Swed… NA    Unit… 3–1   Cana… NA    16   \n\n\n\n\n\n\nUse html_table() to extract a table containing the number of goal scored by country. This is the second table under “Top goalscores”.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Extract the table and show the first few rows\npage %&gt;%\n  html_table() %&gt;%\n  .[[9]] %&gt;% \n  head()\n\n# A tibble: 6 × 3\n   Rank Country       `Goals scored`\n  &lt;int&gt; &lt;chr&gt;                  &lt;int&gt;\n1     1 United States            142\n2     2 Germany                  129\n3     3 Norway                   100\n4     4 Sweden                    83\n5     5 Brazil                    71\n6     6 England                   56"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#part-2-extract-text",
    "href": "lectures/04-data-collection/index.html#part-2-extract-text",
    "title": "Data Collection",
    "section": "Part 2: Extract text",
    "text": "Part 2: Extract text\n\nUse html_elements() to select the introductory paragraph(s) of text (e.g., the first three &lt;p&gt; tags under the main content) from the introductory section of the Wikipedia page, where key information about the World Cup is provided.\nUse html_text2() to retrieve the text.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npage %&gt;%\n  html_elements(\"p\") %&gt;%   # Selecting the first few paragraphs\n  .[1:3] %&gt;%            # Adjust based on the number of paragraphs you want\n  html_text2() \n\n[1] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n[2] \"The FIFA Women's World Cup is an international association football competition contested by the senior women's national teams of the members of Fédération Internationale de Football Association (FIFA), the sport's international governing body. The competition has been held every four years and one year after the men's FIFA World Cup since 1991, when the inaugural tournament, then called the FIFA Women's World Championship, was held in China. Under the tournament's current format, national teams vie for the remaining 31 slots in a three-year qualification phase. The host nation's team is automatically entered as the first slot. The tournament, called the World Cup Finals, is contested at venues within the host nation(s) over about one month.\"\n[3] \"The nine FIFA Women's World Cup tournaments have been won by five national teams. The United States have won four times. The other winners are Germany, with two titles, and Japan, Norway, and Spain with one title each.\""
  },
  {
    "objectID": "lectures/04-data-collection/index.html#part-3-extract-external-links",
    "href": "lectures/04-data-collection/index.html#part-3-extract-external-links",
    "title": "Data Collection",
    "section": "Part 3: Extract external links",
    "text": "Part 3: Extract external links\nHere, we will extract a list of external links related to the FIFA Women’s World Cup from the “References” section at the bottom.\n\nUse html_elements() to select all the references.\nUse html_elements() to select all links (&lt;a&gt; tags) in the references section.\nUse html_attr() to extract the URLs (href) for these links.\nDisplay a list of all unique URLs (hint: use unique() function)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npage %&gt;%\n  html_elements(\".mw-references-columns\") %&gt;% \n  html_elements(\"li\") %&gt;% \n  html_elements(\"a\") %&gt;%\n  html_attr(\"href\") %&gt;%\n  unique()\n\n  [1] \"#cite_ref-1\"                                                                                                                                                                           \n  [2] \"https://web.archive.org/web/20150706151332/http://www.ussoccer.com/stories/2015/07/05/21/19/150705-wnt-v-jpn-game-story\"                                                               \n  [3] \"http://www.ussoccer.com/stories/2015/07/05/21/19/150705-wnt-v-jpn-game-story\"                                                                                                          \n  [4] \"#cite_ref-FIFAformat_2-0\"                                                                                                                                                              \n  [5] \"#cite_ref-FIFAformat_2-1\"                                                                                                                                                              \n  [6] \"#cite_ref-FIFAformat_2-2\"                                                                                                                                                              \n  [7] \"https://web.archive.org/web/20141209162112/http://resources.fifa.com/mm/document/tournament/competition/02/07/47/91/regulationsfwwccanada2015e_neutral.pdf\"                            \n  [8] \"http://resources.fifa.com/mm/document/tournament/competition/02/07/47/91/regulationsfwwccanada2015e_neutral.pdf\"                                                                       \n  [9] \"#cite_ref-3\"                                                                                                                                                                           \n [10] \"https://www.rsssf.org/tablesm/mondo-women70.html\"                                                                                                                                      \n [11] \"/wiki/RSSSF\"                                                                                                                                                                           \n [12] \"https://web.archive.org/web/20220728155233/https://www.rsssf.org/tablesm/mondo-women70.html\"                                                                                           \n [13] \"#cite_ref-4\"                                                                                                                                                                           \n [14] \"https://www.bbc.co.uk/news/business-46149887\"                                                                                                                                          \n [15] \"/wiki/British_Broadcasting_Cooperation\"                                                                                                                                                \n [16] \"https://web.archive.org/web/20181207214128/https://www.bbc.com/news/business-46149887\"                                                                                                 \n [17] \"#cite_ref-5\"                                                                                                                                                                           \n [18] \"https://www.rsssf.org/tablesm/mundo-women71.html\"                                                                                                                                      \n [19] \"https://web.archive.org/web/20220728155235/https://www.rsssf.org/tablesm/mundo-women71.html\"                                                                                           \n [20] \"#cite_ref-6\"                                                                                                                                                                           \n [21] \"https://www.theguardian.com/football/blog/2015/jun/04/womens-world-cup-unofficial-record-breaking\"                                                                                     \n [22] \"/wiki/The_Guardian\"                                                                                                                                                                    \n [23] \"https://web.archive.org/web/20150605044132/https://www.theguardian.com/football/blog/2015/jun/04/womens-world-cup-unofficial-record-breaking\"                                          \n [24] \"#cite_ref-7\"                                                                                                                                                                           \n [25] \"https://www.rsssf.org/tablesm/mundialito-women.html\"                                                                                                                                   \n [26] \"https://web.archive.org/web/20220803221248/https://www.rsssf.org/tablesm/mundialito-women.html\"                                                                                        \n [27] \"#cite_ref-8\"                                                                                                                                                                           \n [28] \"http://www.the-afc.com/competitions/afc-womens-asian-cup/latest/news/foundation-of-asian-brilliance\"                                                                                   \n [29] \"https://web.archive.org/web/20190703193448/http://www.the-afc.com/competitions/afc-womens-asian-cup/latest/news/foundation-of-asian-brilliance\"                                        \n [30] \"#cite_ref-9\"                                                                                                                                                                           \n [31] \"https://web.archive.org/web/20190608195632/https://www.fifa.com/womensworldcup/news/ellen-wille-mother-norwegian-women-football-1462830\"                                               \n [32] \"https://www.fifa.com/womensworldcup/news/ellen-wille-mother-norwegian-women-football-1462830\"                                                                                          \n [33] \"#cite_ref-10\"                                                                                                                                                                          \n [34] \"http://www.fifamuseum.com/stories/blog/a-green-and-gold-shirt-steeped-in-history-500107/\"                                                                                              \n [35] \"https://web.archive.org/web/20190629110059/http://www.fifamuseum.com/stories/blog/a-green-and-gold-shirt-steeped-in-history-500107/\"                                                   \n [36] \"#cite_ref-11\"                                                                                                                                                                          \n [37] \"https://web.archive.org/web/20181213173348/https://www.fifa.com/womensworldcup/news/when-akers-and-usa-got-the-party-started\"                                                          \n [38] \"https://www.fifa.com/womensworldcup/news/when-akers-and-usa-got-the-party-started\"                                                                                                     \n [39] \"#cite_ref-12\"                                                                                                                                                                          \n [40] \"https://web.archive.org/web/20190524061602/https://www.fifa.com/womensworldcup/news/fifa-women-world-cup-sweden-1995-501999\"                                                           \n [41] \"https://www.fifa.com/womensworldcup/news/fifa-women-world-cup-sweden-1995-501999\"                                                                                                      \n [42] \"#cite_ref-13\"                                                                                                                                                                          \n [43] \"http://www.sportsnetwork.com/default.asp?c=sportsnetwork&page=SOC-WWC/STAT/WWC-HISTORY.htm\"                                                                                            \n [44] \"/wiki/Wikipedia:Link_rot\"                                                                                                                                                              \n [45] \"#cite_ref-14\"                                                                                                                                                                          \n [46] \"https://www.usatoday.com/sports/soccer/world/2003-05-03-womens-cup-sars_x.htm\"                                                                                                         \n [47] \"https://web.archive.org/web/20090212124055/https://www.usatoday.com/sports/soccer/world/2003-05-03-womens-cup-sars_x.htm\"                                                              \n [48] \"#cite_ref-15\"                                                                                                                                                                          \n [49] \"https://www.cbc.ca/sports/soccer/canada-gets-2015-women-s-world-cup-of-soccer-1.988843\"                                                                                                \n [50] \"/wiki/Canadian_Broadcasting_Company\"                                                                                                                                                   \n [51] \"https://web.archive.org/web/20110304143611/http://www.cbc.ca/sports/soccer/story/2011/03/03/sp-womens-world-cup.html\"                                                                  \n [52] \"#cite_ref-16\"                                                                                                                                                                          \n [53] \"https://web.archive.org/web/20160821094856/http://uk.reuters.com/article/uk-soccer-women-japan-idUKKBN0NM3D120150501\"                                                                  \n [54] \"http://uk.reuters.com/article/uk-soccer-women-japan-idUKKBN0NM3D120150501\"                                                                                                             \n [55] \"#cite_ref-17\"                                                                                                                                                                          \n [56] \"http://www.huffingtonpost.com/2015/06/17/christie-rampone-oldest-player_n_7599882.html\"                                                                                                \n [57] \"https://web.archive.org/web/20150617061147/http://www.huffingtonpost.com/2015/06/17/christie-rampone-oldest-player_n_7599882.html\"                                                     \n [58] \"#cite_ref-18\"                                                                                                                                                                          \n [59] \"https://web.archive.org/web/20150320194817/http://www.fifa.com/womensworldcup/news/y=2015/m=3/news=france-to-host-the-fifa-women-s-world-cup-in-2019-2567761.html\"                     \n [60] \"https://www.fifa.com/womensworldcup/news/y=2015/m=3/news=france-to-host-the-fifa-women-s-world-cup-in-2019-2567761.html\"                                                               \n [61] \"#cite_ref-19\"                                                                                                                                                                          \n [62] \"https://www.fifamuseum.com/en/blog-stories/blog/the-fifa-women-s-world-cuptm-original-trophy-is-back-at-the-fifa-museu-2620371/\"                                                       \n [63] \"#cite_ref-20\"                                                                                                                                                                          \n [64] \"https://web.archive.org/web/20170319113103/http://www.fifa.com/marketinghighlights/canada2015/marketing-higlights/the-brand/the-official-womens-world-cup-trophy.html\"                 \n [65] \"https://www.fifa.com/marketinghighlights/canada2015/marketing-higlights/the-brand/the-official-womens-world-cup-trophy.html\"                                                           \n [66] \"#cite_ref-21\"                                                                                                                                                                          \n [67] \"https://thejewelerblog.wordpress.com/2015/07/06/womens-world-cup-trophy-is-made-of-gold-glad-sterling-silver-mens-version-is-18-karat-gold/\"                                           \n [68] \"https://web.archive.org/web/20181013211741/https://thejewelerblog.wordpress.com/2015/07/06/womens-world-cup-trophy-is-made-of-gold-glad-sterling-silver-mens-version-is-18-karat-gold/\"\n [69] \"#cite_ref-22\"                                                                                                                                                                          \n [70] \"https://web.archive.org/web/20191222125210/https://www.fifa.com/clubworldcup/news/fifa-world-champions-badge-honours-real-madrid-s-impeccable-year-2494968\"                            \n [71] \"/wiki/FIFA\"                                                                                                                                                                            \n [72] \"https://www.fifa.com/clubworldcup/news/fifa-world-champions-badge-honours-real-madrid-s-impeccable-year-2494968\"                                                                       \n [73] \"#cite_ref-23\"                                                                                                                                                                          \n [74] \"https://digitalhub.fifa.com/m/1816849eda4db6/original/jaeq2lvmczqjofxccj3u-pdf.pdf\"                                                                                                    \n [75] \"https://web.archive.org/web/20210831030705/https://digitalhub.fifa.com/m/1816849eda4db6/original/jaeq2lvmczqjofxccj3u-pdf.pdf\"                                                         \n [76] \"#cite_ref-2015_keyfacts_24-0\"                                                                                                                                                          \n [77] \"#cite_ref-2015_keyfacts_24-1\"                                                                                                                                                          \n [78] \"https://web.archive.org/web/20150711210112/http://www.fifa.com/womensworldcup/news/y=2015/m=7/news=key-figures-from-the-fifa-women-s-world-cup-canada-2015tm-2661648.html\"             \n [79] \"https://www.fifa.com/womensworldcup/news/y=2015/m=7/news=key-figures-from-the-fifa-women-s-world-cup-canada-2015tm-2661648.html\"                                                       \n [80] \"#cite_ref-25\"                                                                                                                                                                          \n [81] \"https://www.nytimes.com/2003/05/27/sports/soccer-us-replaces-china-as-host-of-soccer-s-women-s-world-cup.html\"                                                                         \n [82] \"/wiki/The_New_York_Times\"                                                                                                                                                              \n [83] \"https://web.archive.org/web/20180908054348/https://www.nytimes.com/2003/05/27/sports/soccer-us-replaces-china-as-host-of-soccer-s-women-s-world-cup.html\"                              \n [84] \"#cite_ref-26\"                                                                                                                                                                          \n [85] \"https://web.archive.org/web/20020228035519/http://sportsillustrated.cnn.com/soccer/world/1999/womens_worldcup/news/1999/07/10/brazil_norway/\"                                          \n [86] \"http://sportsillustrated.cnn.com/soccer/world/1999/womens_worldcup/news/1999/07/10/brazil_norway/\"                                                                                     \n [87] \"#cite_ref-ussf_070815_29-0\"                                                                                                                                                            \n [88] \"#cite_ref-ussf_070815_29-1\"                                                                                                                                                            \n [89] \"https://web.archive.org/web/20150709161003/http://www.ussoccer.com/stories/2015/07/08/16/59/150708-wnt-victory-breaks-tv-records\"                                                      \n [90] \"http://www.ussoccer.com/stories/2015/07/08/16/59/150708-wnt-victory-breaks-tv-records\"                                                                                                 \n [91] \"#cite_ref-30\"                                                                                                                                                                          \n [92] \"https://www.sbnation.com/2015/7/6/8900299/more-americans-watched-the-womens-world-cup-final-than-the-nba-finals\"                                                                       \n [93] \"https://web.archive.org/web/20150707222336/https://www.sbnation.com/2015/7/6/8900299/more-americans-watched-the-womens-world-cup-final-than-the-nba-finals\"                            \n [94] \"#cite_ref-31\"                                                                                                                                                                          \n [95] \"https://web.archive.org/web/20151218034246/http://www.fifa.com/womensworldcup/news/y=2015/m=12/news=record-breaking-fifa-women-s-world-cup-tops-750-million-tv-viewers-2745963.html\"   \n [96] \"https://www.fifa.com/womensworldcup/news/y=2015/m=12/news=record-breaking-fifa-women-s-world-cup-tops-750-million-tv-viewers-2745963.html\"                                             \n [97] \"#cite_ref-32\"                                                                                                                                                                          \n [98] \"https://www.nbcsports.com/northwest/world-cup/equal-pay-womens-world-cup-players-seriously\"                                                                                            \n [99] \"https://web.archive.org/web/20230124175112/https://www.nbcsports.com/northwest/world-cup/equal-pay-womens-world-cup-players-seriously\"                                                 \n[100] \"#cite_ref-33\"                                                                                                                                                                          \n[101] \"https://pluralist.com/uswnt-equal-pay-controversy/\"                                                                                                                                    \n[102] \"https://web.archive.org/web/20190703120647/https://pluralist.com/uswnt-equal-pay-controversy/\"                                                                                         \n[103] \"#cite_ref-34\"                                                                                                                                                                          \n[104] \"https://www.nytimes.com/2018/06/12/sports/fifa-revenue.html\"                                                                                                                           \n[105] \"https://ghostarchive.org/archive/20220102/https://www.nytimes.com/2018/06/12/sports/fifa-revenue.html\"                                                                                 \n[106] \"#cite_ref-35\"                                                                                                                                                                          \n[107] \"https://boxscorenews.com/fifa-calls-womens-world-cup-broadcast-offers-disappointing-p168538-199.htm\"                                                                                   \n[108] \"https://web.archive.org/web/20230518034444/https://boxscorenews.com/fifa-calls-womens-world-cup-broadcast-offers-disappointing-p168538-199.htm\"                                        \n[109] \"#cite_ref-ath-2023-broadcast_36-0\"                                                                                                                                                     \n[110] \"#cite_ref-ath-2023-broadcast_36-1\"                                                                                                                                                     \n[111] \"https://theathletic.com/4575427/2023/06/04/womens-world-cup-commercial-tv-rights/?source=twitterhq\"                                                                                    \n[112] \"/wiki/The_Athletic\"                                                                                                                                                                    \n[113] \"#cite_ref-37\"                                                                                                                                                                          \n[114] \"https://digitalhub.fifa.com/m/6bd2fa3c769ee09c/original/lnpeuvaoc1v5tih9rf7p-pdf.pdf\"                                                                                                  \n[115] \"https://web.archive.org/web/20210727190318/https://digitalhub.fifa.com/m/6bd2fa3c769ee09c/original/lnpeuvaoc1v5tih9rf7p-pdf.pdf\""
  },
  {
    "objectID": "lectures/04-data-collection/index.html#part-4-extract-links-from-images",
    "href": "lectures/04-data-collection/index.html#part-4-extract-links-from-images",
    "title": "Data Collection",
    "section": "Part 4: Extract links from images",
    "text": "Part 4: Extract links from images\nHere we will extract the URLs for images on the page, particularly images related to tournament trophies or logos.\n\nUse html_elements() to select  tags.\nUse html_attr() to get the image source (src) URLs.\nFilter for images that contain keywords like “FIFA”, “World Cup”, or “Logo” in their src using the grepl function.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npage %&gt;%\n  html_elements(\"img\") %&gt;%\n  html_attr(\"src\") %&gt;%\n  tibble(url = .) %&gt;% \n  filter(grepl(\"FIFA|World_Cup|Logo\", url))\n\n# A tibble: 5 × 1\n  url                                                                           \n  &lt;chr&gt;                                                                         \n1 //upload.wikimedia.org/wikipedia/commons/thumb/a/aa/FIFA_logo_without_slogan.…\n2 //upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Womens_World_Cup_countrie…\n3 //upload.wikimedia.org/wikipedia/commons/thumb/a/aa/FIFA_logo_without_slogan.…\n4 //upload.wikimedia.org/wikipedia/commons/thumb/2/26/World_Map_FIFA.svg/100px-…\n5 //upload.wikimedia.org/wikipedia/commons/thumb/2/26/World_Map_FIFA.svg/200px-…"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#other-good-r-packages-to-know-about",
    "href": "lectures/04-data-collection/index.html#other-good-r-packages-to-know-about",
    "title": "Data Collection",
    "section": "Other good R packages to know about",
    "text": "Other good R packages to know about\n\ngooglesheets4 to interact with Google Sheets in R\ngoogledrive to interact with files on your Google Drive"
  },
  {
    "objectID": "lectures/04-data-collection/index.html#additional-practice",
    "href": "lectures/04-data-collection/index.html#additional-practice",
    "title": "Data Collection",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nUsing the GitHub API, access the repository information and ask how many open github issues you have?\nPick another API that we have not discussed here and use httr to retreive data from it.\nLook how many open issues there are in the dplyr package in the tidyverse.\nPractice requesting data from the openFDA API, which returns JSON files. This API provides create easy access to public data, to create a new level of openness and accountability, to ensure the privacy and security of public FDA data, and ultimately to educate the public and save lives. See data definitions for all included data."
  },
  {
    "objectID": "lectures/02-version-control/index.html",
    "href": "lectures/02-version-control/index.html",
    "title": "Introduction to version control",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please follow the instructions on Software Carpentry: Version Control with Git to\n\nInstalling Git\nCreating a GitHub Account\nPreparing Your Working Directory\n\nIn addition, please read through Chapters 1-9.\n\n\n\n\n\n\n\n\nHow much should I prepare for before class?\n\n\n\nYou should be comfortable with the meaning of version control, have git installed, create a GitHub account (if you have not before), prepare your working directory, understand the meaning of most the git commands, and also executing commands on your computer before class starts.\nDuring class, I will give an overview of these topics and then we will practice using version control in groups of two with an in-class activity. I will walk around the class answering questions and helping to address questions as they arise in practice. If you have not installed git, created a GitHub account, and prepared your working directory, it will be challenging to participate in the activity."
  },
  {
    "objectID": "lectures/02-version-control/index.html#acknowledgements",
    "href": "lectures/02-version-control/index.html#acknowledgements",
    "title": "Introduction to version control",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nSoftware Carpentry: Version Control with Git"
  },
  {
    "objectID": "lectures/02-version-control/index.html#learning-objectives",
    "href": "lectures/02-version-control/index.html#learning-objectives",
    "title": "Introduction to version control",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nUnderstand the benefits of an automated version control system.\nUnderstand how to set up git.\nUnderstand how to set up a git repository.\nUnderstand how to track changes, explore history, and ignore files in a git\nUnderstand git remotes.\nUnderstand how to use GitHub.\nUnderstand collaborating."
  },
  {
    "objectID": "lectures/02-version-control/index.html#slides",
    "href": "lectures/02-version-control/index.html#slides",
    "title": "Introduction to version control",
    "section": "Slides",
    "text": "Slides\n\nLecture 02: Introduction to version control"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-1-repository-setup",
    "href": "lectures/02-version-control/index.html#part-1-repository-setup",
    "title": "Introduction to version control",
    "section": "Part 1: Repository Setup",
    "text": "Part 1: Repository Setup\n\nCreate a new repository. One partner (the “Owner” of the GitHub repo) should create a GitHub repository titled bikelanes in their own personal GitHub repository.\nInvite a collaborator. The repository owner needs to invite their partner as a collaborator by going to Settings &gt; Collaborators &gt; Manage Access. Specifically, on GitHub, click the “Settings” button on the right, select “Collaborators”, click “Add people”, and then enter your partner’s GitHub username.\n\nTo accept access to the Owner’s repo, the Collaborator needs to go to https://github.com/notifications or check for email notification. Once there you can accept access to the Owner’s repo.\n\nClone the repository. Both the Owner and Collaborator should clone the repository locally to their respective computers.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf using SSH:\ngit clone git@github.com:&lt;change-to-owners-github-username&gt;/bikelanes.git\nIf using HTTPS:\ngit clone https://github.com/&lt;change-to-owners-github-username&gt;/bikelanes.git"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-2-adding-content-to-the-repository",
    "href": "lectures/02-version-control/index.html#part-2-adding-content-to-the-repository",
    "title": "Introduction to version control",
    "section": "Part 2: Adding content to the repository",
    "text": "Part 2: Adding content to the repository\n\nAdd a CSV file to the local repository. Consider the dataset called bike_lanes_data.csv with the following contents:\n\nLane_ID,Street_Name,Length_km,Type,Year_Installed,City\n1,Main St,1.2,Protected,2018,Springfield\n2,Elm St,0.8,Shared,2016,Springfield\n3,Maple Ave,2.3,Buffered,2020,Springfield\n4,Oak St,1.5,Protected,2019,Springfield\n5,Pine St,0.5,Shared,2015,Springfield\n6,River Rd,3.1,Buffered,2021,Springfield\nThe Owner should create a new CSV locally titled bike_lanes_data.csv and paste the data into the new CSV file. Save the file and commit the file to the local repository using git commands.\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncd bikelanes\ntouch bike_lanes_data.csv # (and paste in the content above)\ngit status\ngit add bike_lanes_data.csv\ngit commit -m \"adding bike lanes data\"\ngit push origin main\n\n\n\n\nCollaborator needs to pull the new changes locally to their computer. Next, the collaborator should pull the changes from the remote bikelanes GitHub repository to their local computer. This should make the new bike_lanes_data.csv appear locally on their computer.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncd bikelanes\ngit pull origin main\n\n\n\n\nAdd a README.md file. The collaborator should create a new file called README.md in the bikelanes repository. Please add the following information to it:\n\n\nThe names of the owner and collaborator of the project\nThe emails of the owner and collaborator of the project\nAnswers to the following questions:\n\nDo you enjoy biking?\nWhat type of biking (e.g. road biking, mountain biking, no biking, etc ) do you enjoy?\nIf not biking, what hobbies do you enjoy doing?\n\n\nAfter the README.md file is complete, add and commit the file to the local repository using git commands. Push the changes to the remote bikelanes repository on GitHub.\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntouch README.md # (add the content)\ngit status\ngit add README.md\ngit commit -m \"adding readme file\"\ngit push\n\n\n\n\nOwner needs to pull the new changes locally to their computer. Next, the owner of the repository should pull the changes from the remote bikelanes GitHub repository to their local computer. This should make the new REAMDE.md appear locally on their computer.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncd bikelanes\ngit pull"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-3-create-github-issues-to-assign-tasks",
    "href": "lectures/02-version-control/index.html#part-3-create-github-issues-to-assign-tasks",
    "title": "Introduction to version control",
    "section": "Part 3: Create GitHub issues to assign tasks",
    "text": "Part 3: Create GitHub issues to assign tasks\nThe partners should create at least one Github Issue for a set of future tasks for the project (e.g., “Add bike lane data from our local area” or “Write code to analyze bike lane usage trends”).\nAssign these issues to each other and set a due date, if desired."
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-4-review-the-git-history",
    "href": "lectures/02-version-control/index.html#part-4-review-the-git-history",
    "title": "Introduction to version control",
    "section": "Part 4: Review the git history",
    "text": "Part 4: Review the git history\nBoth partners should review the commit history using git commands\n\n\n\n\n\n\nSolution\n\n\n\n\n\nExpected commands: git log"
  },
  {
    "objectID": "lectures/02-version-control/index.html#part-5-switch-roles-and-repeat-process",
    "href": "lectures/02-version-control/index.html#part-5-switch-roles-and-repeat-process",
    "title": "Introduction to version control",
    "section": "Part 5: Switch roles and repeat process",
    "text": "Part 5: Switch roles and repeat process\nSwitch roles and repeat the whole process."
  },
  {
    "objectID": "lectures/02-version-control/index.html#reflection-questions",
    "href": "lectures/02-version-control/index.html#reflection-questions",
    "title": "Introduction to version control",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nWhat challenges did you encounter when collaborating on GitHub?\nHow did using Issues help you coordinate work?\nIn what ways could GitHub features be useful for larger projects, such as full bike lane data studies?"
  },
  {
    "objectID": "lectures/02-version-control/index.html#additional-practice",
    "href": "lectures/02-version-control/index.html#additional-practice",
    "title": "Introduction to version control",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nInitialize a new Git repository.\n\nCreate a new folder on your computer.\nUse the git init command to turn it into a Git repository.\nConfigure your name and email using git config –global user.name “Your Name”andgit config –global user.email “you@example.com”`.\n\n\nGoal: Learn to set up Git for the first time and understand how Git tracks your identity.\n\nCreate a new file and commit it.\n\nCreate a simple text file in your repository (e.g., README.md).\nUse git add &lt;filename&gt; to stage the file.\nUse git commit -m \"Initial commit\" to commit it to the repository.\n\n\nGoal: Understand how to add and commit files in Git.\n\nModify a file and create a new commit.\n\nMake changes to the file (e.g., add some text to the README.md).\nStage the changes and commit them using git add and git commit.\nUse git log to see the history of your commits.\n\n\nGoal: Learn how to track changes over time and inspect the commit history.\n\nWork with branches.\n\nCreate a new branch using git checkout -b feature-branch.\nMake changes to a file, stage, and commit them.\nSwitch back to the main branch (git checkout main).\nMerge your changes from feature-branch into main using git merge feature-branch.\n\n\nGoal: Understand how branching works and how to merge changes from different branches.\n\nSimulate and resolve a merge conflict.\n\nOn the main branch, edit a line in a file and commit the change.\nSwitch to a new branch (git checkout -b conflicting-branch), edit the same line differently, and commit it.\nMerge the conflicting-branch back into main and resolve the merge conflict manually.\nUse git status to see the files with conflicts and edit them to resolve.\nCommit the resolved changes.\n\n\nGoal: Learn how to handle merge conflicts and understand conflict markers."
  },
  {
    "objectID": "lectures/00-course-intro/index.html",
    "href": "lectures/00-course-intro/index.html",
    "title": "Welcome to the course",
    "section": "",
    "text": "Before each class, there will be a set of pre-lecture activities and/or readings for you to complete. It is important these activities be done before class so that you can benefit the most from the in-class activities.\nToday we will cover the Pre-reading material about quarto as a way to demonstrate where to find the pre-reading materials going forward. Sometimes, there will not be pre-reading materials here, but rather direct links to external resources that you need to read in advance."
  },
  {
    "objectID": "lectures/00-course-intro/index.html#acknowledgements",
    "href": "lectures/00-course-intro/index.html#acknowledgements",
    "title": "Welcome to the course",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nr4ds book: https://r4ds.hadley.nz/quarto\nQuarto Publishing System: https://quarto.org"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#learning-objectives",
    "href": "lectures/00-course-intro/index.html#learning-objectives",
    "title": "Welcome to the course",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nGet an overview of the course (including staff, format, grading, etc)\nBe able to recognize and operate an Integrated Developer Evironment (IDE) to perform statistial programming and data analysis.\nBe able to describe reasons why having a personal website can be useful.\nRecognize what is Quarto and how it’s different from RMarkdown.\nBe able to create a Quarto project and Quarto website."
  },
  {
    "objectID": "lectures/00-course-intro/index.html#slides",
    "href": "lectures/00-course-intro/index.html#slides",
    "title": "Welcome to the course",
    "section": "Slides",
    "text": "Slides\n\nLecture 00: Welcome and Introductions"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#summary",
    "href": "lectures/00-course-intro/index.html#summary",
    "title": "Welcome to the course",
    "section": "Summary",
    "text": "Summary\n\nAccess all course material on CoursePlus and course website (https://www.stephaniehicks.com/jhustatprogramming2024)\nLectures will be recorded followed by an in-class activity. Later in the course, the in-class activity will be to work on the final project\nAt the end of each class, fill out the reflection card (not graded, but helpful to both the student and instructor)\nIntegrated developer environment (IDEs) can make you more efficient as a programmer!\nQuarto is an open-source scientific and technical publishing system to create reproducible, production quality articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, and more\nYou can think of Quarto as a natural successor to RMarkdown"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#additional-practice",
    "href": "lectures/00-course-intro/index.html#additional-practice",
    "title": "Welcome to the course",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nIn either RStudio or VSCode, create a new Quarto document. Read the instructions. Practice running the chunks individually. Then render the document and practice the appropriate keyboard short cut. Verify that you can modify the code, re-run it, and see modified output.\nCreate one new Quarto document for each of the three built-in formats: HTML, PDF and Word. Render each of the three documents. How do the outputs differ? How do the inputs differ? (You may need to install LaTeX in order to build the PDF output — RStudio will prompt you if this is necessary.)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to the Course Website for PH.140.777 Statistical Programming Paradigms and Workflows!"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Welcome",
    "section": "Overview",
    "text": "Overview\nComputing and programming are fundamental skills for applied statisticians to efficiently demonstrate the performance of their models with data, to develop reproducible data analyses or robust software, and to effectively communicate their own research interests. However, these skills are often not taught in the classroom, often making it challenging to learn these skills “on the job”.\nThis hands-on course will cover advanced statistical computing programming paradigms and workflows required for the research and application of statistical methods. Students will be expected to complete readings prior to class, attend lectures to dive deeper into those topics in class, participate in classroom activities, complete projects (both solo and group) practicing and reinforcing the computing and programming skills. There will be a final group project, which will include a major class presentation."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "Welcome",
    "section": "Course Information",
    "text": "Course Information\n\nCourse Staff: Prof. Stephanie Hicks, Joe Sartini, and Wenxuan Lu\nLectures: 1:30-2:50pm Tuesday and Thursday. See CoursePlus for location details.\nOffice Hours: See CoursePlus for location details."
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Welcome",
    "section": "Course Details",
    "text": "Course Details\nAll course details are available on the Course page. The syllabus is available on CoursePlus."
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Course content",
    "section": "",
    "text": "Course content for each lecture is below:\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2024-10-24\n\n\nWelcome to the course\n\n\nStephanie Hicks\n\n\n\n\n2024-10-29\n\n\nIntroduction to the command-line\n\n\nStephanie Hicks\n\n\n\n\n2024-10-31\n\n\nIntroduction to version control\n\n\nStephanie Hicks\n\n\n\n\n2024-11-05\n\n\nFunctional programming\n\n\nStephanie Hicks\n\n\n\n\n2024-11-07\n\n\nData Collection\n\n\nStephanie Hicks\n\n\n\n\n2024-11-12\n\n\nDatabase programming paradigms\n\n\nStephanie Hicks\n\n\n\n\n2024-11-14\n\n\nMachine learning paradigms and workflows\n\n\nStephanie Hicks\n\n\n\n\n2024-11-19\n\n\nParallel programming\n\n\nStephanie Hicks\n\n\n\n\n2024-11-21\n\n\nObject-oriented programming\n\n\nStephanie Hicks\n\n\n\n\n2024-11-26\n\n\nR package development and pkgdown\n\n\nStephanie Hicks\n\n\n\n\n2024-12-03\n\n\nBuilding dashboards with flexdashboard\n\n\nStephanie Hicks\n\n\n\n\n2024-12-05\n\n\nProgramming with GitHub Copilot\n\n\nStephanie Hicks & Kinnary Shah\n\n\n\n\n2024-12-10\n\n\nProgramming with Python with reticulate\n\n\nStephanie Hicks\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lectures/01-command-line/index.html",
    "href": "lectures/01-command-line/index.html",
    "title": "Introduction to the command-line",
    "section": "",
    "text": "The next lecture falls on 👻 Halloween ! I plan to give the lecture dressed up in a costume. This is entirely optional, but I encourage students to come in costume if you wish! Candy 🍬 will be offered to anyone in costume!"
  },
  {
    "objectID": "lectures/01-command-line/index.html#acknowledgements",
    "href": "lectures/01-command-line/index.html#acknowledgements",
    "title": "Introduction to the command-line",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nSoftware Carpentry: The Unix Shell\nData Science at the Command line\nApplied Computational Genomics"
  },
  {
    "objectID": "lectures/01-command-line/index.html#learning-objectives",
    "href": "lectures/01-command-line/index.html#learning-objectives",
    "title": "Introduction to the command-line",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nUnderstand what is a command shell and why would use one.\nCreate, copy, move, rename, and delete files and folders.\nSearch for regular expressions in files.\nExecute R commands and scripts in the command line.\nRedirect a command’s output to a file with redirect operators (&gt;, &gt;&gt;).\nConstruct command pipelines with two or more stages with the pipe operator (|).\nWrite a loop that applies one or more commands separately to each file in a set of files.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can practice your command-line skills with the Command Challenge"
  },
  {
    "objectID": "lectures/01-command-line/index.html#slides",
    "href": "lectures/01-command-line/index.html#slides",
    "title": "Introduction to the command-line",
    "section": "Slides",
    "text": "Slides\n\nLecture 01: Introduction to the command-line"
  },
  {
    "objectID": "lectures/01-command-line/index.html#summary",
    "href": "lectures/01-command-line/index.html#summary",
    "title": "Introduction to the command-line",
    "section": "Summary",
    "text": "Summary\n\nShell is a text based application for viewing, handling and manipulating files\nIt is also known by the following names\n\nCLI (Command Line Interface)\nTerminal\nBash (Bourne Again Shell)\n\nUse Rscript -e or R -e to execute R scripts from the command line\nRStudio includes a Terminal (from version 1.1.383)\nExecute commands from shell script in RStudio using Ctrl + Enter\nRMarkdown and Quarto supports bash, sh and awk"
  },
  {
    "objectID": "lectures/01-command-line/index.html#additional-practice",
    "href": "lectures/01-command-line/index.html#additional-practice",
    "title": "Introduction to the command-line",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nMove around the computer, get used to moving in and out of directories, see how different file types appear in the Unix shell. Be sure to use the pwd and cd commands, and the different flags for the ls commands.\nPractice using “Tab for Auto-complete” in the shell to autocomplete commands or file names.\nExplore the manual pages of date in the command line to show you what that looks like. Try to figure out what is the argument to print the date since the Unix epoch or 00:00:00 UTC on 1 January 1970 as a function of the number of seconds. Then try to identify what is the argument to display the date in UTC.\nPractice your command line knowledge with Command Challenge."
  },
  {
    "objectID": "lectures/03-functional-programming/index.html",
    "href": "lectures/03-functional-programming/index.html",
    "title": "Functional programming",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please install\n\npurrr - this provides a consistent functional programming interface to work with functions and vectors\n\nYou can do this by calling\n\ninstall.packages(\"purrr\")\n\nAnd load the package using:\n\nlibrary(purrr)\n\n\n\nIn addition, please read through\n\nFunctional programming\nhttps://adv-r.hadley.nz/functionals.html\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/purrr.pdf\n\n\n\n\n\n\n\nHow much should I prepare for before class?\n\n\n\nYou should have purrr installed and be familiar with the map() function along with map variants in purrr.\nWe will learn more about these functions in class, but we will also practice them at the end of class."
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#acknowledgements",
    "href": "lectures/03-functional-programming/index.html#acknowledgements",
    "title": "Functional programming",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://adv-r.hadley.nz/fp.html\nhttps://adv-r.hadley.nz/functionals.html\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/purrr.pdf"
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#learning-objectives",
    "href": "lectures/03-functional-programming/index.html#learning-objectives",
    "title": "Functional programming",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nBe familiar with the concept of functional languages and functional styles of programming\nGet comfortable with the major functions in purrr (e.g. the map family of functions) provides a nice interface to functional programming and list manipulation\nPractice the function map and its alternative map_* provide a neat way to iterate over a list or vector with the output in different data structures (instead of a for loop)\nRecongize the function map2 and pmap allow having more than one list as input.\nRecongize the function walk and its alternatives walk2, walk_*, which do not provide any output."
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#slides",
    "href": "lectures/03-functional-programming/index.html#slides",
    "title": "Functional programming",
    "section": "Slides",
    "text": "Slides\n\nLecture 03: Functional programming"
  },
  {
    "objectID": "lectures/03-functional-programming/index.html#additional-practice",
    "href": "lectures/03-functional-programming/index.html#additional-practice",
    "title": "Functional programming",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nUse as_mapper() to explore how purrr generates anonymous functions for the integer, character, and list helpers. What helper allows you to extract attributes? Read the documentation to find out.\nmap(1:3, ~ runif(2)) is a useful pattern for generating random numbers, but map(1:3, runif(2)) is not. Why not? Can you explain why it returns the result that it does?\nCan you write a section of code to demonstrate the central limit theorem primarily using the purrr package and/or using the R base package?\nUse the appropriate map() function to:\n\nCompute the standard deviation of every column in a numeric data frame.\nCompute the standard deviation of every numeric column in a mixed data frame. (Hint: you will need to do it in two steps.)\nCompute the number of levels for every factor in a data frame.\n\nThe following code simulates the performance of a t-test for non-normal data. Extract the p-value from each test, then visualise.\n\ntrials &lt;- map(1:100, ~ t.test(rpois(10, 10), rpois(7, 10)))\n\nUse map() to fit linear models to the mtcars dataset using the formulas stored in this list:\n\ndata(mtcars)\nformulas &lt;- list(\n  mpg ~ disp,\n  mpg ~ I(1 / disp),\n  mpg ~ disp + wt,\n  mpg ~ I(1 / disp) + wt\n)\n\nFit the model mpg ~ disp to each of the bootstrap replicates of mtcars in the list below, then extract the \\(R^2\\) of the model fit (Hint: you can compute the \\(R^2\\) with summary().)\n\nbootstrap &lt;- function(df) {\n  df[sample(nrow(df), replace = TRUE), , drop = FALSE]\n}\n\nbootstraps &lt;- map(1:10, ~ bootstrap(mtcars))\n\nHow does purrr make it easier to perform repeated transformations compared to base R? What are some use cases where conditional transformations like map_if() could be helpful in real-world data?"
  },
  {
    "objectID": "lectures/05-database-programming/index.html",
    "href": "lectures/05-database-programming/index.html",
    "title": "Database programming paradigms",
    "section": "",
    "text": "Important\n\n\n\nFor this lecture, we will use Unix shell, plus SQLite3 or DB Browser for SQLite.\nYou can see if the command-line tool sqlite3 (also known as “SQLite”) is already installed with\n\nsqlite3 --version\n\n3.43.2 2023-10-10 13:08:14 1b37c146ee9ebb7acd0160c0ab1fd11017a419fa8a3187386ed8cb32b709aapl (64-bit)\n\n\nIf not, you can follow the instructions here:\n\nhttps://swcarpentry.github.io/sql-novice-survey\n\nAlso, you will need to install these R packages:\n\ninstall.packages(\"DBI\")\ninstall.packages(\"RSQLite\")\ninstall.packages(\"dbplyr\")\n\n\n\nIn addition, please read through\n\nRelational databases and SQL basics\nhttps://swcarpentry.github.io/sql-novice-survey (Chapters 1-4)\n\n\n\n\n\n\n\nHow much should I prepare for before class?\n\n\n\nPlease install the packages above and be comfortable with running the functions in the example code here:\n\nhttps://dbi.r-dbi.org\nhttps://solutions.posit.co/connections/db/databases/sqlite/\nhttps://dbplyr.tidyverse.org"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#acknowledgements",
    "href": "lectures/05-database-programming/index.html#acknowledgements",
    "title": "Database programming paradigms",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://swcarpentry.github.io/sql-novice-survey"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#learning-objectives",
    "href": "lectures/05-database-programming/index.html#learning-objectives",
    "title": "Database programming paradigms",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nExplain the difference between a table, a record, and a field in relational databases\nExplain the difference between a database and a database manager\nWrite a query to select all values for specific fields from a single table\nWrite queries that display results in a particular order\nWrite queries that eliminate duplicate values from data\nWrite queries that select records that satisfy user-specified conditions\nLearn about the DBI, RSQLite, dbplyr packages for making SQL queries in R"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#slides",
    "href": "lectures/05-database-programming/index.html#slides",
    "title": "Database programming paradigms",
    "section": "Slides",
    "text": "Slides\n\nLecture 05: Database programming paradigms"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#part-1-create-a-sql-database",
    "href": "lectures/05-database-programming/index.html#part-1-create-a-sql-database",
    "title": "Database programming paradigms",
    "section": "Part 1: Create a SQL database",
    "text": "Part 1: Create a SQL database\n\nCreate a new SQL database titled beyonce.sqlite using the DBI and RSQLite packages using the dbConnect() function.\nUsing the dbWriteTable() function, add the songs and albums datasets to the SQL database.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# This code to ensure that the lecture builds and there no SQL database at the start of the exercise\nsql_beyonce &lt;- here::here(\"lectures\",\"05-database-programming\", \"data\", \"beyonce.sqlite\")\nif(file.exists(sql_beyonce)){\n  file.remove(sql_beyonce)\n}\n\n[1] TRUE\n\nlibrary(DBI)\nmydb &lt;- dbConnect(drv = RSQLite::SQLite(), \n                  dbname = sql_beyonce)\n\ndbWriteTable(conn = mydb, name = \"songs\", value = songs)\ndbWriteTable(conn = mydb, name = \"albums\", value = albums)\ndbListTables(conn = mydb)\n\n[1] \"albums\" \"songs\""
  },
  {
    "objectID": "lectures/05-database-programming/index.html#part-2-practice-sql-queries",
    "href": "lectures/05-database-programming/index.html#part-2-practice-sql-queries",
    "title": "Database programming paradigms",
    "section": "Part 2: Practice SQL queries",
    "text": "Part 2: Practice SQL queries\n\nWrite a SQL query that selects all columns from the songs table where the number of streams is greater than 600 million.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nresults &lt;- dbGetQuery(mydb, \"SELECT * \n                             FROM songs\n                             WHERE streams_millions &gt; 600;\")\nprint(results)\n\n  song_id         title album_id release_year streams_millions\n1       3 Single Ladies        1         2008              700\n2       4     Formation        3         2016              800\n3       5 Irreplaceable        2         2006              900\n4       6 Drunk in Love        3         2013             1000\n5       9   Love on Top        2         2011              750\n6      10         Sorry        3         2016              900\n\n\n\n\n\n\nUse SQL to select the titles of Beyoncé’s songs released after 2010, along with the year they were released.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nresults &lt;- dbGetQuery(mydb, \"SELECT title, release_year \n                             FROM songs \n                             WHERE release_year &gt; 2010;\")\nprint(results)\n\n          title release_year\n1     Formation         2016\n2 Drunk in Love         2013\n3 Run the World         2011\n4     Partition         2013\n5   Love on Top         2011\n6         Sorry         2016\n\n\n\n\n\n\nWrite a SQL query that counts the number of songs for each album.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nresults &lt;- dbGetQuery(mydb, \"SELECT album_id, COUNT(song_id) AS song_count\n                             FROM songs\n                             GROUP BY album_id;\")\nprint(results)\n\n  album_id song_count\n1        1          3\n2        2          3\n3        3          4\n\n\n\n\n\n\nWrite a SQL query that calculates the total streams for each album. Select the album ID, album title, and total streams.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nresults &lt;- dbGetQuery(mydb, \"SELECT album_id, title, SUM(streams_millions) AS total_streams \n                             FROM songs \n                             GROUP BY album_id;\")\nprint(results)\n\n  album_id         title total_streams\n1        1 Crazy in Love          1650\n2        2          Halo          2250\n3        3     Formation          3050\n\n\n\n\n\n\nIdentify the least streamed song for each release year.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nresults &lt;- dbGetQuery(mydb, \"SELECT release_year, title, MIN(streams_millions) AS min_streams\n                             FROM songs\n                             GROUP BY release_year;\")\nprint(results)\n\n  release_year         title min_streams\n1         2003 Crazy in Love         500\n2         2006 Irreplaceable         900\n3         2008          Halo         600\n4         2011 Run the World         450\n5         2013     Partition         350\n6         2016     Formation         800\n\n\nClose connection when done\n\ndbDisconnect(conn = mydb)"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#part-3-discussion",
    "href": "lectures/05-database-programming/index.html#part-3-discussion",
    "title": "Database programming paradigms",
    "section": "Part 3: Discussion",
    "text": "Part 3: Discussion\nDiscuss with your partner:\n\nHow does SQL make it easier to analyze and summarize data?\nWhich SQL query might you use to quickly identify Beyoncé’s most popular song based on streams?\nHow could these SQL skills be applied to other areas of data analysis?"
  },
  {
    "objectID": "lectures/05-database-programming/index.html#additional-practice",
    "href": "lectures/05-database-programming/index.html#additional-practice",
    "title": "Database programming paradigms",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\nUsing the survey.db database discussed in the relational databases and SQL basics pre-reading material:\n\nUse .schema to identify column that contains integers\nWrite a query that selects only the name column from the Site table.\nMany people format queries in the following two ways. What style do you find easiest to read, and why?\n\nSELECT personal, family FROM person;\nor\nselect Personal, Family from PERSON;\n\nWrite a query that selects distinct dates from the Visited table.\nWrite a query that displays the full names of the scientists in the Person table, ordered by family name."
  },
  {
    "objectID": "lectures/07-parallel-programming/index.html",
    "href": "lectures/07-parallel-programming/index.html",
    "title": "Parallel programming",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please\n\nfuture - this provides a unified parallel framework in R consistent\n\nYou can do this by calling\n\ninstall.packages(\"future\")\n\nAnd load the package using:\n\nlibrary(future)\n\n\n\nIn addition, please read through\n\nStrategies for dealing with large data\nhttps://www.futureverse.org/packages-overview.html (just the future R package)\n\n\n\n\n\n\n\nHow much should I prepare for before class?\n\n\n\nYou should have future installed and be familiar with the three basic functions - plan(), future(), and value().\nWe will learn more about these functions in class."
  },
  {
    "objectID": "lectures/07-parallel-programming/index.html#acknowledgements",
    "href": "lectures/07-parallel-programming/index.html#acknowledgements",
    "title": "Parallel programming",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://www.futureverse.org/packages-overview"
  },
  {
    "objectID": "lectures/07-parallel-programming/index.html#learning-objectives",
    "href": "lectures/07-parallel-programming/index.html#learning-objectives",
    "title": "Parallel programming",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nUnderstand the basics of parallel computing\nBecome familiar with basic functions in the future package\nRecognize different file formats to work with large data not locally\nImplement three ways to work with large data:\n\n“sample and model”\n“chunk and pull”\n“push compute to data”"
  },
  {
    "objectID": "lectures/07-parallel-programming/index.html#slides",
    "href": "lectures/07-parallel-programming/index.html#slides",
    "title": "Parallel programming",
    "section": "Slides",
    "text": "Slides\n\nLecture 07: Parallel computing (and dealing with large data)"
  },
  {
    "objectID": "lectures/09-r-pkg-dev/index.html",
    "href": "lectures/09-r-pkg-dev/index.html",
    "title": "R package development and pkgdown",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please install two additional packages:\n\ndevtools - this provides many additional tools for building packages\nroxygen2 - this provides tools for writing documentation\npkgdown - this helps you to build a package website with little effort\nusethis - an automation package that simplifies project creation and setup\n\nYou can do this by calling\n\ninstall.packages(c(\"devtools\", \"roxygen2\",\n                   \"usethis\", \"pkgdown\"))\n\nIn addition, please read through:\n\nhttps://r-pkgs.org\nhttps://stat545.com/package-overview\nhttps://usethis.r-lib.org\nhttps://pkgdown.r-lib.org/articles/pkgdown"
  },
  {
    "objectID": "lectures/09-r-pkg-dev/index.html#acknowledgements",
    "href": "lectures/09-r-pkg-dev/index.html#acknowledgements",
    "title": "R package development and pkgdown",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://pkgdown.r-lib.org/index.html\nhttps://bookdown.org/yihui/rmarkdown/pkgdown-components.html"
  },
  {
    "objectID": "lectures/09-r-pkg-dev/index.html#learning-objectives",
    "href": "lectures/09-r-pkg-dev/index.html#learning-objectives",
    "title": "R package development and pkgdown",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nCreate an empty R package\nDesign a R function and write documentation\nDescribe what a DESCRIPTION file is and what goes in it\nBe able to build and install a R package\nBuild a website for your package"
  },
  {
    "objectID": "lectures/09-r-pkg-dev/index.html#slides",
    "href": "lectures/09-r-pkg-dev/index.html#slides",
    "title": "R package development and pkgdown",
    "section": "Slides",
    "text": "Slides\n\nLecture 09: R package development"
  },
  {
    "objectID": "lectures/11-programming-with-copilot/index.html",
    "href": "lectures/11-programming-with-copilot/index.html",
    "title": "Programming with GitHub Copilot",
    "section": "",
    "text": "Important\n\n\n\nIn advance of class, please set up your GitHub student account on this website: https://education.github.com/discount_requests/application. This process may take up to 72 hours.\nOnce you’ve been granted access, you can follow these instructions to install Copilot in RStudio: https://drive.google.com/file/d/1Y_BLnYYWxujbJuxlWXjCtU93mghKG-2s/view?usp=sharing."
  },
  {
    "objectID": "lectures/11-programming-with-copilot/index.html#learning-objectives",
    "href": "lectures/11-programming-with-copilot/index.html#learning-objectives",
    "title": "Programming with GitHub Copilot",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nKnow the basic terminology and logic of GitHub Copilot\nHave helpful tips to optimize your use of GitHub Copilot\nHave resources to create a free student account to GitHub Copilot and install it in RStudio"
  },
  {
    "objectID": "lectures/11-programming-with-copilot/index.html#slides",
    "href": "lectures/11-programming-with-copilot/index.html#slides",
    "title": "Programming with GitHub Copilot",
    "section": "Slides",
    "text": "Slides\n\nLecture 11: Programming with Copilot"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2024-11-12\n\n\nProject 3\n\n\nStephanie Hicks\n\n\n\n\n2024-11-05\n\n\nProject 2\n\n\nStephanie Hicks\n\n\n\n\n2024-10-31\n\n\nProject 4\n\n\nStephanie Hicks\n\n\n\n\n2024-10-24\n\n\nProject 1\n\n\nStephanie Hicks\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/02-project/index.html",
    "href": "projects/02-project/index.html",
    "title": "Project 2",
    "section": "",
    "text": "Background\nDue date: November 15 at 11:59pm\nThe goal of this assignment is to practice some of the skills we have been learning about in class around data collection paradigms and functional programming.\n\nTo submit your project\nYou need to create a private GitHub Classroom repository (only one per group) for you and your partner, which will be posted in CoursePlus. This creates an empty GitHub repository. You need to show all your code and submit both the .qmd file and the rendered HTML file. Please include section headers for each of the components below. All plots should have titles, subtitles, captions, and human-understandable axis labels. The TAs will grade the contents in the GitHub Classroom repo by cloning the repo and checking for all the things described below.\nBecause you will work with a partner, please be sure to include the names, emails, and JHED IDs for both individuals in your submitted work.\n\n\n\nPart 1\nHere, you and your partner will practice using a API and making data visualizations.\nThe API we will use is tidycensus (https://walker-data.com/tidycensus), which is an R package that allows users to interface with a select number of the US Census Bureau’s data APIs and return tidyverse-ready data frames, optionally with simple feature geometry included.\nThe goal of this part is to create a set of data visualizations using the US Census Bureau’s data.\n\n\n\n\n\n\nImportant\n\n\n\nTo use this API, you must obtain and API key, which can be found at the top of this page:\n\nhttps://walker-data.com/tidycensus/articles/basic-usage\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you use an API, you want to figure out the data you want to extract and then save it locally so that you are not using the API each time you knit or render your data analysis.\nMost APIs have limits on the number of times you can ping it in a given hour and your IP address can be blocked if you try to ping it too many times within a short time.\nTherefore, it is strongly suggested that you create a new folder called data locally and save the output from extracting data from the tidycensus API. In this way, you can read the data in locally each time you knit/render the document, rather than continue to pull data from the API each time you knit/render the document.\n\n\n\nChoose a question to investigate. Describe what is the question you aim to answer with the data and what you want to visualize.\nExtract data from the tidycensus API. Use at least three different calls to the tidycensus API to extract out different datasets. For example, these could be across years, locations, or variables.\nClean the data. Include some form of data wrangling and data visualization using packages such as dplyr or tidyr. Other packages that might be helpful to you include lubridate, stringr, and forcats. You must use at least two functions from purrr.\nVisualize the data. Create data visualizations of your choice. However, your analysis should include at least three plots with you using at least two different geom_*() functions from ggplot2 (or another package with geom_*() functions).\nReport your findings. Provide a paragraph summarizing your methods and key findings. Include any limitations or potential biases in pulling data from the API or the analysis. Be sure to comment and organize your code so is easy to understand what you are doing.\n\n\n\nPart 2\nIn this part, you and your partner will use the rvest package to scrape data from a website, wrangle and analyze the data, and summarize your findings.\n\nChoose a website to scrape. Select a website with structured data in HTML tables or well-defined sections. Some examples could include:\n\nA movie database like IMDb or Rotten Tomatoes (scraping movie titles, ratings, release years, etc.)\nA job listing site like Indeed or LinkedIn (scraping job titles, companies, and locations)\nA sports statistics site like ESPN or Baseball Reference (scraping team statistics, player info, etc.)\n\nExtract data with rvest. Here, you will want to identify the specific HTML elements or CSS selectors containing the data. Then, use rvest functions like read_html(), html_elements(), and html_text() or html_table() to retrieve the data.\nClean the data. Next, perform some basic wrangling, such as remove extra whitespace, handle missing values, and convert data types as needed. You might find the functions from dplyr or tidyr useful for any additional transformations, such as renaming columns, filtering rows, or creating new variables.\nAnalyze the data. Perform a simple analysis of your choice. For example, you could\n\nCount how many times specific words or themes appear.\nCreate a summary statistic (e.g., average rating, job salary, team win percentage).\nCreate a data visualization (e.g., bar chart, histogram) of an interesting metric.\n\nReport your findings. Provide a paragraph summarizing your methods and key findings. Include any limitations or potential biases in your scraping or analysis. Be sure to comment and organize your code so is easy to understand what you are doing.\n\n\n\n\n\n\n\nEnsure ethical use of web scraping\n\n\n\nBefore scraping a site, it’s a good practice to check if the site allows scraping in its terms of service or look at the robots.txt file. While robots.txt does not legally prevent access, it reflects the site’s preferred limits on automated access.\nSome web scraping tools and libraries allow you to specify a “polite” setting that follows the robots.txt rules by default, which is often a good practice to follow.\nIt’s typically located at the root of the domain (e.g., https://example.com/robots.txt) and follows a simple format to specify rules.\nFor more information, check out https://en.wikipedia.org/wiki/Robots.txt."
  },
  {
    "objectID": "projects/04-project/index.html",
    "href": "projects/04-project/index.html",
    "title": "Project 4",
    "section": "",
    "text": "The purpose of Project 4 is to work together as a team to design and implement a data analytic product (e.g. a data analysis, a software package, a dashboard, simulation tool, etc) that integrates multiple programming paradigms. The project is intentionally open-ended with the goal it will give you and your team the chance to follow your own curiosity.\n\n\nUnder the Schedule on Course Plus, there will be Google Forms posted to submit the various components of the Final Project.\n\nForm a team (Due Friday November 8th at 11:59pm) and submit the names of your team members using a Google Form on CoursePlus. You should aim to have minimum 3, but ideally 4 (max) people on your team. Please identify a team leader who will fill out this form only on behalf of all team members. This data is very important because we will start scheduling meetings with teams for the week of Nov 18-22 based on the information provided by Nov 8th.\nSubmit a final project proposal (Due Friday November 15th at 11:59pm) using a Google Form on CoursePlus. The team leader who was identified in Part 1 of the Final project should fill out this form only on behalf of all team members. You will need to upload a PDF of your project proposal answering the questions below describing what should be in the project proposal.\nMeet with the instructor or TAs the week of November 18-22, 2024. The instructor or TAs will contact teams individuall to schedule a time to meet. The purpose of this meeting is to make sure the project is feasible, not too big or small in scope, data is accessible, etc.\nPrepare a final project presentation (Due Wednesday December 11th at 11:59pm) and upload a PDF of the presentation using a Google Form on CoursePlus. Your team also will need to sign up for a date to present as a team on either December 12th or December 17th in class. You are expected to present as a team on that date. The sign up for the schedule will be posted soon. The content of what should be in the presentation is described below.\nSubmit a final project write up (Due Thursday December 19th at 11:59pm) to GitHub Classroom. You will also submit a link to the GitHub Classroom repository using a Google Form on CoursePlus. Please prepare a write up of your final project and upload the write up. The content of what should be in the write up is described below.\nSubmit group participation evaluation (Due Thursday December 19th at 11:59pm) using a Google Form on CoursePlus. This will include both a self-evaluation and a peer-evaluation on your team member.\n\n\n\n\nThe breakdown for how the components in the final project will be weighted towards the final project (or Project 4) grade:\n\nSubmit names of team members (5%)\nSubmit project proposal (20%)\nMeet with the instructor or TAs to discuss project proposal as a team (15%)\nProject presentation as a team (25%)\nFinal project write up via GitHub Classroom (25%)\nGroup participation (self- and peer-evaluation) (10%)\n\n\n\n\n\n\n\nImportant\n\n\n\nTeam members will recieve the same grade for everything except the group participation. This will be evaluated separately for each individual depending on their level of participation and contribution to the team. We will ask each of you to self-evaluation your participation and we will ask your team members to evaluate your particiption.\nIf you all contribute to the project, this should be an easy 10%. If you let your team members do all the work and you don’t contribute, this will reflect in your final project grade.\n\n\n\n\n\nUsing quarto, write up a project proposal and submit the PDF. The final project proposal should include the following information:\n\nThe title of your project and the team members names\nYou should describe a research or data analysis question and explain its importance\nYou should summarize work that already exists (if it does)\nYou should outline the work you plan to do\nYou should demonstrate you have access to the data, describe the data, and propose how you will collect the data\nYou should describe the programming paradigms you plan to use and why it makes sense to combine them for your project\nYou should describe any packages and/or software you plan to use\nYou should briefly describe the data analytic product you plan to build\nYou should describe a tentative timeline for the proposal\nYou should describe how the tasks will be split amongst the team members\n\n\n\nYour final project must demonstrate collecting data from a source in a non-trival way. An example of something trival might be to simply read in a CSV file. In class, we talked about extracting data from APIs, HTML, or SQL databases. These are not the only ways to collect data, but the final project should include either one of the following paradigms around data / database collection or the team could propose another (non-trivial) data collection paradigm they would like to propose for the project.\n\nData collection paradigms\nDatabase programming paradigms\n\n\n\n\nYour final project must use at least two (or more is OK too, but at minimum two) of the following programming paradigms we discussed in class:\n\nProgramming in the command line (e.g. shell scripting)\nFunctional programming paradigms\nObject oriented programming paradigms\nParallel computing paradigms\nMachine learning paradigms\n\n\n\n\nYour final project must include building a data analytic products, such as:\n\nA data analysis summarized in a deployed quarto website\nAn R package with a deployed pkgdown website\nA deployed dashboard (e.g. using flexdashboard or shiny)\n\n\n\n\nHere are some example ideas for potential projects:\n\nBuild a custom SQL database to track outcomes for a particular disease and then build machine learning models to predict disease spread allowing for functional modules for data cleaning.\nBuild an R package (i.e. object oriented programming) around pulling data from the Open Baltimore API, which includes writing functions leveraging functional programming paradigms.\nBuild machine learning models leveraging parallel computing for distributed data (e.g. data not all in one place or data that can’t be read into memory at once).\nExtract data from an API and build a dashboard to tackle a statistical problem that might leverage functional programming and parallel computing paradigms.\nBuild an R package to help customer retention for a business using shell scripts to run simulations.\n\nAgain, the goal is for your team to investigate a question of interest with data of your choice that integrates multiple programming paradigms and finally builds some type of data analytic product. It is intentionally open and broad, but hopefully more fun for your team!\n\n\n\n\nDepending on how many teams are formed, this will determine how long teams have to present, but given the size of the class, it will likely be around 10-15 mins in length. You will be asked to turn in slides for your presentation before you present.\nGive a presentation explaining the importance of the project, an overview of the technical challenges, and what you learned. Plan for a few minutes of questions at the end. Also consider the following:\n\nPresentation quality: Is the presentation clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Are the slides readable? Do the figures have large enough legends and figure titles? Did you describe the data?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?\n\n\n\n\nWrite up a summary of your final project and submit it to GitHub classroom.\nPlease explain the importance of the project, give an overview of the technical challenges, and what you learned. Also consider the following:\n\nWrite up quality: Is the write up clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Do the figures have large enough legends and figure titles? Did you describe the data?\nIs there a README.md in the repo you push to GitHub classroom summarizing key details about the project, including team members and an overview of the final project?\nHave you linked to all code and data needed to reproduce your work?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?"
  },
  {
    "objectID": "projects/04-project/index.html#deliverables",
    "href": "projects/04-project/index.html#deliverables",
    "title": "Project 4",
    "section": "",
    "text": "Under the Schedule on Course Plus, there will be Google Forms posted to submit the various components of the Final Project.\n\nForm a team (Due Friday November 8th at 11:59pm) and submit the names of your team members using a Google Form on CoursePlus. You should aim to have minimum 3, but ideally 4 (max) people on your team. Please identify a team leader who will fill out this form only on behalf of all team members. This data is very important because we will start scheduling meetings with teams for the week of Nov 18-22 based on the information provided by Nov 8th.\nSubmit a final project proposal (Due Friday November 15th at 11:59pm) using a Google Form on CoursePlus. The team leader who was identified in Part 1 of the Final project should fill out this form only on behalf of all team members. You will need to upload a PDF of your project proposal answering the questions below describing what should be in the project proposal.\nMeet with the instructor or TAs the week of November 18-22, 2024. The instructor or TAs will contact teams individuall to schedule a time to meet. The purpose of this meeting is to make sure the project is feasible, not too big or small in scope, data is accessible, etc.\nPrepare a final project presentation (Due Wednesday December 11th at 11:59pm) and upload a PDF of the presentation using a Google Form on CoursePlus. Your team also will need to sign up for a date to present as a team on either December 12th or December 17th in class. You are expected to present as a team on that date. The sign up for the schedule will be posted soon. The content of what should be in the presentation is described below.\nSubmit a final project write up (Due Thursday December 19th at 11:59pm) to GitHub Classroom. You will also submit a link to the GitHub Classroom repository using a Google Form on CoursePlus. Please prepare a write up of your final project and upload the write up. The content of what should be in the write up is described below.\nSubmit group participation evaluation (Due Thursday December 19th at 11:59pm) using a Google Form on CoursePlus. This will include both a self-evaluation and a peer-evaluation on your team member."
  },
  {
    "objectID": "projects/04-project/index.html#grading",
    "href": "projects/04-project/index.html#grading",
    "title": "Project 4",
    "section": "",
    "text": "The breakdown for how the components in the final project will be weighted towards the final project (or Project 4) grade:\n\nSubmit names of team members (5%)\nSubmit project proposal (20%)\nMeet with the instructor or TAs to discuss project proposal as a team (15%)\nProject presentation as a team (25%)\nFinal project write up via GitHub Classroom (25%)\nGroup participation (self- and peer-evaluation) (10%)\n\n\n\n\n\n\n\nImportant\n\n\n\nTeam members will recieve the same grade for everything except the group participation. This will be evaluated separately for each individual depending on their level of participation and contribution to the team. We will ask each of you to self-evaluation your participation and we will ask your team members to evaluate your particiption.\nIf you all contribute to the project, this should be an easy 10%. If you let your team members do all the work and you don’t contribute, this will reflect in your final project grade."
  },
  {
    "objectID": "projects/04-project/index.html#final-project-proposal",
    "href": "projects/04-project/index.html#final-project-proposal",
    "title": "Project 4",
    "section": "",
    "text": "Using quarto, write up a project proposal and submit the PDF. The final project proposal should include the following information:\n\nThe title of your project and the team members names\nYou should describe a research or data analysis question and explain its importance\nYou should summarize work that already exists (if it does)\nYou should outline the work you plan to do\nYou should demonstrate you have access to the data, describe the data, and propose how you will collect the data\nYou should describe the programming paradigms you plan to use and why it makes sense to combine them for your project\nYou should describe any packages and/or software you plan to use\nYou should briefly describe the data analytic product you plan to build\nYou should describe a tentative timeline for the proposal\nYou should describe how the tasks will be split amongst the team members\n\n\n\nYour final project must demonstrate collecting data from a source in a non-trival way. An example of something trival might be to simply read in a CSV file. In class, we talked about extracting data from APIs, HTML, or SQL databases. These are not the only ways to collect data, but the final project should include either one of the following paradigms around data / database collection or the team could propose another (non-trivial) data collection paradigm they would like to propose for the project.\n\nData collection paradigms\nDatabase programming paradigms\n\n\n\n\nYour final project must use at least two (or more is OK too, but at minimum two) of the following programming paradigms we discussed in class:\n\nProgramming in the command line (e.g. shell scripting)\nFunctional programming paradigms\nObject oriented programming paradigms\nParallel computing paradigms\nMachine learning paradigms\n\n\n\n\nYour final project must include building a data analytic products, such as:\n\nA data analysis summarized in a deployed quarto website\nAn R package with a deployed pkgdown website\nA deployed dashboard (e.g. using flexdashboard or shiny)\n\n\n\n\nHere are some example ideas for potential projects:\n\nBuild a custom SQL database to track outcomes for a particular disease and then build machine learning models to predict disease spread allowing for functional modules for data cleaning.\nBuild an R package (i.e. object oriented programming) around pulling data from the Open Baltimore API, which includes writing functions leveraging functional programming paradigms.\nBuild machine learning models leveraging parallel computing for distributed data (e.g. data not all in one place or data that can’t be read into memory at once).\nExtract data from an API and build a dashboard to tackle a statistical problem that might leverage functional programming and parallel computing paradigms.\nBuild an R package to help customer retention for a business using shell scripts to run simulations.\n\nAgain, the goal is for your team to investigate a question of interest with data of your choice that integrates multiple programming paradigms and finally builds some type of data analytic product. It is intentionally open and broad, but hopefully more fun for your team!"
  },
  {
    "objectID": "projects/04-project/index.html#final-project-presentation",
    "href": "projects/04-project/index.html#final-project-presentation",
    "title": "Project 4",
    "section": "",
    "text": "Depending on how many teams are formed, this will determine how long teams have to present, but given the size of the class, it will likely be around 10-15 mins in length. You will be asked to turn in slides for your presentation before you present.\nGive a presentation explaining the importance of the project, an overview of the technical challenges, and what you learned. Plan for a few minutes of questions at the end. Also consider the following:\n\nPresentation quality: Is the presentation clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Are the slides readable? Do the figures have large enough legends and figure titles? Did you describe the data?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?"
  },
  {
    "objectID": "projects/04-project/index.html#final-project-write-up",
    "href": "projects/04-project/index.html#final-project-write-up",
    "title": "Project 4",
    "section": "",
    "text": "Write up a summary of your final project and submit it to GitHub classroom.\nPlease explain the importance of the project, give an overview of the technical challenges, and what you learned. Also consider the following:\n\nWrite up quality: Is the write up clear on what was the question being investigated? What were the orginal goals and what was accomplished along the way? Was there previous work in this area? Do the figures have large enough legends and figure titles? Did you describe the data?\nIs there a README.md in the repo you push to GitHub classroom summarizing key details about the project, including team members and an overview of the final project?\nHave you linked to all code and data needed to reproduce your work?\nParadigm integration: How effectively does your project demonstrate multiple paradigms?\nFunctionality: Does the data analytic product work as intended? Are the components well-integrated?\nUsability and documentation: Is the data analytic product easy to use/read and well-documented?\nOriginality and complexity: Does the project address a non-trivial statistical or programming problem with creativity?"
  },
  {
    "objectID": "readings/00-quarto/index.html",
    "href": "readings/00-quarto/index.html",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "Quarto provides a unified authoring framework for data science, combining your code, its results, and your prose.\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.\n\n\n\n\n\n\n\nImportant\n\n\n\nQuarto is a command line interface tool, not an R package.\nThis means that help is, by-and-large, not available through ? in the R console.\nAnd not to add to the confusion, but there is an quarto R package that has helper functions for you to use in R to e.g. check the Quarto version installed, etc.\n\n\nFormally, Quarto is a publishing system built on Pandoc that allows users to create dynamic content using R, Python, Julia, and ObservableJS (with plans to add more languages too!).\n\n\n\nA schematic representing the multi-language input versatility of Quarto\n\n\n\n\nArt by Allison Horst. Be sure to check out the rest of Allison’s seriously cute Quarto penguin art in the #rstudioconf2022 keynote talk, Hello Quarto, by Julie Lowndes & Mine Çetinkaya-Rundel!\n\n\n\nYou need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed.\n\nhttps://quarto.org/docs/get-started\nhttps://formulae.brew.sh/cask/quarto (this is my preferred way using home brew)"
  },
  {
    "objectID": "readings/00-quarto/index.html#introduction",
    "href": "readings/00-quarto/index.html#introduction",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "Quarto provides a unified authoring framework for data science, combining your code, its results, and your prose.\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.\n\n\n\n\n\n\n\nImportant\n\n\n\nQuarto is a command line interface tool, not an R package.\nThis means that help is, by-and-large, not available through ? in the R console.\nAnd not to add to the confusion, but there is an quarto R package that has helper functions for you to use in R to e.g. check the Quarto version installed, etc.\n\n\nFormally, Quarto is a publishing system built on Pandoc that allows users to create dynamic content using R, Python, Julia, and ObservableJS (with plans to add more languages too!).\n\n\n\nA schematic representing the multi-language input versatility of Quarto\n\n\n\n\nArt by Allison Horst. Be sure to check out the rest of Allison’s seriously cute Quarto penguin art in the #rstudioconf2022 keynote talk, Hello Quarto, by Julie Lowndes & Mine Çetinkaya-Rundel!"
  },
  {
    "objectID": "readings/00-quarto/index.html#prerequisites",
    "href": "readings/00-quarto/index.html#prerequisites",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "You need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed.\n\nhttps://quarto.org/docs/get-started\nhttps://formulae.brew.sh/cask/quarto (this is my preferred way using home brew)"
  },
  {
    "objectID": "readings/00-quarto/index.html#qmd-files",
    "href": "readings/00-quarto/index.html#qmd-files",
    "title": "Authoring projects and websites with Quarto",
    "section": ".qmd files",
    "text": ".qmd files\nQuarto files end in a .qmd. This is short for quarto markdown.\n\n\n\n\n\n\nNote\n\n\n\nThese files are decoupled from RStudio IDE and there are plugins to work with .qmd files for\n\nVSCode\nJupyterLab\nRStudio\n\n\n\n\nRendering\nUse the  Render button in the RStudio IDE to render the file and preview the output with a single click or keyboard shortcut (⇧⌘K).\n\n\n\n\n\nIf you prefer to automatically render whenever you save, you can check the Render on Save option on the editor toolbar. The preview will update whenever you re-render the document. Side-by-side preview works for both HTML and PDF outputs.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDocuments can also be rendered from the R console via the quarto package:\n\n\nCode run in the R Console\n\ninstall.packages(\"quarto\")\nquarto::quarto_render(\"hello.qmd\")\n\nAnd documents can also be rendered from the command line:\n\n\nCode run in the command line\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles\n\n\n\n\nHow rendering works\nWhen you render a Quarto document, first knitr executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated is then processed by pandoc, which creates the finished format. The Render button encapsulates these actions and executes them in the right order for you.\n\n\n\n\n\nWhen rendering, Quarto generates a new file that contains selected text, code, and results from the .qmd file. The new file can be an HTML, PDF, MS Word document, presentation, website, book, interactive document, or other format.\n\n\n\nAuthoring\nIn the image below we can see the same document in the two modes of the RStudio editor:\n\nvisual (on the left)\nsource (on the right)\n\nRStudio’s visual editor offers an WYSIWYM authoring experience for markdown. For formatting (e.g. bolding text) you can use the toolbar, a keyboard shortcut (⌘B), or the markdown construct (**bold**).\nYou can toggle back and forth these two modes by clicking on Source and Visual in the editor toolbar (or using the keyboard shortcut ⌘⇧ F4).\n\n\n\n\n\n\n\nHow does multi-language support work?\n\n\n\n\n\n\nQuarto supports multiple languages\n\n\n\nThese languages include\n\nR\nPython\nJulia\nObservable javascript\n\nQuarto can also interchange between languages using Apache Arrow.\n\n\nThe idea behind how quarto supports multi-language code is that the code output is “frozen” after it is rendered.\nIn this way, code output is not recomputed, unless you want it to."
  },
  {
    "objectID": "readings/00-quarto/index.html#r-markdown-vs-quarto",
    "href": "readings/00-quarto/index.html#r-markdown-vs-quarto",
    "title": "Authoring projects and websites with Quarto",
    "section": "R Markdown vs Quarto",
    "text": "R Markdown vs Quarto\nSome high-level differences include\n\nStandardized YAML across formats\nDecoupled from RStudio\nMore consistent presentation across formats\nTab Panels\nCode Highlighting\n\n\nCode block options\nAnother noticeable difference are options for code blocks. Rather than being in the header of the code block, options are moved to within the code block using the #| (hash-pipe) for each line.\nThis is a code block for R Markdown:\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(tidytext)\n```\nThis is a code block for Quarto:\n```{r}\n#| label: \"setup\"\n#| include: false\nlibrary(tidyverse)\nlibrary(tidytext)\n```\n\n\nOutput Options\nThere are a wide variety of output options available for customizing output from executed code.\nAll of these options can be specified either\n\nglobally (in the document front-matter) or\nper code-block\n\nFor example, here’s a modification of the Python example to specify that we don’t want to “echo” the code into the output document:\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\nNote that we can override this option on a per code-block basis. For example:\n```{python}\n#| echo: true\n\nimport matplotlib.pyplot as plt\nplt.plot([1,2,3,4])\nplt.show()\n```\nCode block options available for customizing output include:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output (note that this implies that errors executing code will not halt processing of the document).\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\nHere’s a example with r code blocks and some of these additional options included:\n---\ntitle: \"Knitr Document\"\nexecute:\n  echo: false\n---\n\n```{r}\n#| warning: false\n\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)\n```\n\n```{r}\nsummary(airquality)\n```\n\n\n\n\n\n\nTip\n\n\n\nWhen using the Knitr engine, you can also use any of the available native options (e.g. collapse, tidy, comment, etc.).\nSee the Knitr options documentation for additional details. You can include these native options in option comment blocks as shown above, or on the same line as the {r} as shown in the Knitr documentation.\n\n\n\n\nMargin content\nYou can place content within the right margin of Quarto document. For example, here we use the .column-margin class to place an image in the margin:\n::: {.column-margin}\nWe know from *the first fundamental theorem of calculus* that for $x$ in $[a, b]$:\n\n$$\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).$$\n:::\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]\n\n\nMargin Figures\nFigures that you create using code blocks can be placed in the margin by using the column: margin code block option.\nIf the code produces more than one figure, each of the figures will be placed in the margin.\n\n```{r}\n#| label: fig-mtcars\n#| fig-cap: \"MPG vs horsepower, colored by transmission.\"\n#| column: margin\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\n```\n\n\n\n\n\n\n\n\nFigure 1: MPG vs horsepower, colored by transmission.\n\n\n\n\n\n\nMargin Tables\nYou an also place tables in the margin of your document by specifying column: margin.\n\n```{r}\n#| column: margin\nknitr::kable(\n  mtcars[1:6, 1:3]\n)\n```\n\n\n\n\n\n\nmpg\ncyl\ndisp\n\n\n\n\nMazda RX4\n21.0\n6\n160\n\n\nMazda RX4 Wag\n21.0\n6\n160\n\n\nDatsun 710\n22.8\n4\n108\n\n\nHornet 4 Drive\n21.4\n6\n258\n\n\nHornet Sportabout\n18.7\n8\n360\n\n\nValiant\n18.1\n6\n225\n\n\n\n\n\n\nCode line numbers\nIf you want to display line numbers alongside the code block, add the code-line-numbers option. For example:\nformat:\n  html:\n    code-line-numbers: true\nHere’s how a code block with line numbers would display throughout the document:\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\nYou can also enable line numbers for an individual code block using the code-line-numbers attribute.\n\n\nShould you switch to quarto?\n\nShould you switch to Quarto? Not necessarily. If you find R Markdown meets your need, you can definitely stay there. It is not imperative to switch. - Yihui Xie\n\n\n\nhttps://yihui.org/en/2022/04/quarto-r-markdown/"
  },
  {
    "objectID": "readings/00-quarto/index.html#project",
    "href": "readings/00-quarto/index.html#project",
    "title": "Authoring projects and websites with Quarto",
    "section": "Project",
    "text": "Project\nHere are the general steps for creating a Quarto project in RStudio:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the project"
  },
  {
    "objectID": "readings/00-quarto/index.html#website",
    "href": "readings/00-quarto/index.html#website",
    "title": "Authoring projects and websites with Quarto",
    "section": "Website",
    "text": "Website\nHere are the general steps for creating a Quarto website:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the website\nDeploy the website\n\n\n\n\n\n\n\nDeploying a website\n\n\n\nquarto publish can push and update a number of different kinds of webhosts. You will need credentials to publish to each of these.\nquarto publish gh-pages    # GitHub Pages\nquarto publish quarto-pub  # Quarto.pub \nquarto publish netlify     # Netlify\nquarto publish connect     # RStudio Connect"
  },
  {
    "objectID": "readings/00-quarto/index.html#freeze-results-and-avoid-recomputing",
    "href": "readings/00-quarto/index.html#freeze-results-and-avoid-recomputing",
    "title": "Authoring projects and websites with Quarto",
    "section": "Freeze Results and avoid recomputing",
    "text": "Freeze Results and avoid recomputing\nFreezing code output is generally used when you have either\n\nA large number of collaborators or\nMany computational documents created over a longer period of time\nA project with different types of file formats from different languages (e.g. .qmd, .ipynb, .Rmd)\n\nIn the above cases, it can be challenging to fully re-execute every document when you render the site.\nThis could be because some documents have esoteric or environment-specific requirements (e.g. require access/authentication to a data source) or due to general fragility of dependencies over time.\nUsing freeze ensures that you can always reproducibly render your site.\nThe computational results of documents executed with freeze are stored in the _freeze/ directory, and re-used when needed to fulfill document renders.\nYou should check the contents of _freeze/ into version control so that others rendering the project don’t need to reproduce your computational environment to render it in their environment.\n\n\n\n\n\n\nNote\n\n\n\nYou will still want to take care to fully re-render your project when things outside of source code change (e.g. input data).\nYou can remove previously frozen output by deleting the _freeze folder at the root of your project.\n\n\nFor example, consider the _quarto.yml file.\nOne argument in the file is the freeze option to denote that computational documents should never be re-rendered during a global project render, or alternatively only be re-rendered when their source file changes:\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n  \nexecute:\n  freeze: true  # never re-render during project render\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n\nexecute:\n  freeze: auto  # re-render only when source changes\n\n\n\n\n\n\nNote\n\n\n\nThe freeze option in the _quarto.yml file controls whether execution occurs during global project renders.\nIf you do an incremental render of either a single document or a project sub-directory then code is always executed. For example:\n\n\nTerminal\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html",
    "href": "readings/04-data-collection-apis/index.html",
    "title": "Retrieving data from APIs with httr2",
    "section": "",
    "text": "Before we begin, let’s load a few R packages\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(httr2)"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#raw-vs-clean-data",
    "href": "readings/04-data-collection-apis/index.html#raw-vs-clean-data",
    "title": "Retrieving data from APIs with httr2",
    "section": "“Raw” vs “Clean” data",
    "text": "“Raw” vs “Clean” data\nAs data analysts, this is what we wished data looked like whenever we start a project\n\n\n\n\n\n\n\n\n\nHowever, the reality, is data is rarely in that form in comes in all types of “raw” formats that need to be transformed into a “clean” format.\nFor example, in field of genomics, raw data looks like something like this:\n\n\n\n\n\n\n\n\n\nOr if you are interested in analyzing data from Twitter:\n\n\n\n\n\n\n\n\n\nOr data from Electronic Healthcare Records (EHRs):\n\n\n\n\n\n\n\n\n\nWe all have our scary spreadsheet tales. Here is Jenny Bryan from Posit and UBC actually asking for some of those spreadsheet tales on twitter.\n\n\n\n\n\n\n\n\n\nFor example, this is an actual spreadsheet from Enron in 2001:"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#what-do-we-mean-by-raw-data",
    "href": "readings/04-data-collection-apis/index.html#what-do-we-mean-by-raw-data",
    "title": "Retrieving data from APIs with httr2",
    "section": "What do we mean by “raw” data?",
    "text": "What do we mean by “raw” data?\nFrom https://simplystatistics.org/posts/2016-07-20-relativity-raw-data/ raw data is defined as data…\n\n…if you have done no processing, manipulation, coding, or analysis of the data. In other words, the file you received from the person before you is untouched. But it may not be the rawest version of the data. The person who gave you the raw data may have done some computations. They have a different “raw data set”."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#where-do-data-live",
    "href": "readings/04-data-collection-apis/index.html#where-do-data-live",
    "title": "Retrieving data from APIs with httr2",
    "section": "Where do data live?",
    "text": "Where do data live?\nData lives anywhere and everywhere. Data might be stored simply in a .csv or .txt file. Data might be stored in an Excel or Google Spreadsheet. Data might be stored in large databases that require users to write special functions to interact with to extract the data they are interested in.\nFor example, you may have heard of the terms mySQL or MongoDB.\nFrom Wikipedia, MySQL is defined as an open-source relational database management system (RDBMS). Its name is a combination of “My”, the name of co-founder Michael Widenius’s daughter,[7] and “SQL”, the abbreviation for Structured Query Language.\nFrom Wikipeda, MongoDB is defined as “a free and open-source cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schemata.”\nSo after reading that, we get the sense that there are multiple ways large databases can be structured, data can be formatted and interacted with. In addition, we see that database programs (e.g. MySQL and MongoDB) can also interact with each other.\n\n\n\n\n\n\n\n\n\nWe will learn more about JSON today and learn about SQL in a later lecture more formally."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#json-files",
    "href": "readings/04-data-collection-apis/index.html#json-files",
    "title": "Retrieving data from APIs with httr2",
    "section": "JSON files",
    "text": "JSON files\nJSON (or JavaScript Object Notation) is a file format that stores information in human-readable, organized, logical, easy-to-access manner.\nFor example, here is what a JSON file looks like:\nvar stephanie = {\n    \"job-title\" : \"Associate Professor\",\n    \"hometown\" : \"Baltimore, MD\",\n    \"pronouns\": \"she/her\",\n  \"states-lived\" : {\n    \"state1\" : \"Louisiana\",\n    \"state2\" : \"Texas\",\n    \"state3\" : \"Massachusetts\",\n    \"state4\" : \"Maryland\"\n  }\n}\nSome features about JSON objects:\n\nJSON objects are surrounded by curly braces {}\nJSON objects are written in key/value pairs\nKeys must be strings, and values must be a valid JSON data type (string, number, object, array, boolean)\nKeys and values are separated by a colon\nEach key/value pair is separated by a comma"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#overview-of-apis",
    "href": "readings/04-data-collection-apis/index.html#overview-of-apis",
    "title": "Retrieving data from APIs with httr2",
    "section": "Overview of APIs",
    "text": "Overview of APIs\nFrom AWS, API stands for Application Programming Interface.\n\n“Application” = any software with a distinct function\n“Interface” = a contract of service between two applications. This contract defines how the two communicate with each other using requests and responses.\n\nThe API documentation contains information on how developers are to structure those requests and responses.\n\n\n\n\n\n\nPurpose of APIs\n\n\n\nThe purpose of APIs is enable two software components to communicate with each other using a set of definitions and protocols.\nFor example, the weather bureau’s software system contains daily weather data. The weather app on your phone “talks” to this system via APIs and shows you daily weather updates on your phone.\n\n\n\nHow do APIs work?\nTo understand how APIs work, two terms that are important are\n\nclient. This is the application sending the request.\nserver. This is the application sending the response.\n\nSo in the weather example, the bureau’s weather database is the server, and the mobile app is the client.\n\n\nFour types of API architectures\nThere are four different ways that APIs can work depending on when and why they were created.\n\nSOAP APIs. These APIs use Simple Object Access Protocol. Client and server exchange messages using XML. This is a less flexible API that was more popular in the past.\nRPC APIs. These APIs are called Remote Procedure Calls. The client completes a function (or procedure) on the server, and the server sends the output back to the client.\nWebsocket APIs. Websocket API is another modern web API development that uses JSON objects to pass data. A WebSocket API supports two-way communication between client apps and the server. The server can send callback messages to connected clients, making it more efficient than REST API.\nREST APIs. REST stands for Representational State Transfer (and are the most popular and flexible APIs). The client sends requests to the server as data. The server uses this client input to start internal functions and returns output data back to the client. REST defines a set of functions like GET, PUT, DELETE, etc. that clients can use to access server data. Clients and servers exchange data using HTTP.\n\nThe main feature of REST API is statelessness (i.e. servers do not save client data between requests). Client requests to the server are similar to URLs you type in your browser to visit a website. The response from the server is plain data, without the typical graphical rendering of a web page.\n\n\nHow to use an API?\nThe basic steps to using an API are:\n\nObtaining an API key. This is done by creating a verified account with the API provider.\nSet up an HTTP API client. This tool allows you to structure API requests easily using the API keys received. Here, we will use functions from the httr2 package (which is the next generation of the httr package).\nIf you don’t have an API client, you can try to structure the request yourself in your browser by referring to the API documentation.\nOnce you are comfortable with the new API syntax, you can start using it in your code.\n\n\n\nWhere can I find new APIs?\nNew web APIs can be found on API marketplaces and API directories, such as:\n\nRapid API – One of the largest global API markets (10k+ public APIs). Users to test APIs directly on the platform before committing to purchase.\nPublic REST APIs – Groups REST APIs into categories, making it easier to browse and find the right one to meet your needs.\nAPIForThat and APIList – Both these websites have lists of 500+ web APIs, along with in-depth information on how to use them."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#access-the-api-from-r",
    "href": "readings/04-data-collection-apis/index.html#access-the-api-from-r",
    "title": "Retrieving data from APIs with httr2",
    "section": "Access the API from R",
    "text": "Access the API from R\nThere are packages for many programming languages that provide convenient access for communicating with the GitHub API, but there are no such packages (that I’m aware of) for accessing the API from R.\nThis means we can only access the API directly, e.g. by using the jsonlite package to fetch the data and convert it to an R list or data.frame.\nSpecifically, we will use the jsonlite::read_json() function to read a JSON file into a data frame.\nThe JSON file is located at https://api.github.com/users/stephaniehicks/repos.\n\ngithub_url &lt;- \"https://api.github.com/users/stephaniehicks/repos\"\n\nlibrary(jsonlite)\nlibrary(tidyverse)\njsonData &lt;- read_json(github_url, simplifyVector = TRUE)\nglimpse(jsonData)\n\nRows: 30\nColumns: 79\n$ id                          &lt;int&gt; 160194123, 132884754, 647539937, 225501707…\n$ node_id                     &lt;chr&gt; \"MDEwOlJlcG9zaXRvcnkxNjAxOTQxMjM=\", \"MDEwO…\n$ name                        &lt;chr&gt; \"2018-bioinfosummer-scrnaseq\", \"advdatasci…\n$ full_name                   &lt;chr&gt; \"stephaniehicks/2018-bioinfosummer-scrnase…\n$ private                     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ owner                       &lt;df[,19]&gt; &lt;data.frame[26 x 19]&gt;\n$ html_url                    &lt;chr&gt; \"https://github.com/stephaniehicks/201…\n$ description                 &lt;chr&gt; NA, NA, \"Repo to share code for the atlas-…\n$ fork                        &lt;lgl&gt; FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FAL…\n$ url                         &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ forks_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ keys_url                    &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ collaborators_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ teams_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ hooks_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issue_events_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ events_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ assignees_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ branches_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ tags_url                    &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ blobs_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_tags_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_refs_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ trees_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ statuses_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ languages_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ stargazers_url              &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ contributors_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ subscribers_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ subscription_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ commits_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_commits_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ comments_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issue_comment_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ contents_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ compare_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ merges_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ archive_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ downloads_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issues_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ pulls_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ milestones_url              &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ notifications_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ labels_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ releases_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ deployments_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ created_at                  &lt;chr&gt; \"2018-12-03T13:20:45Z\", \"2018-05-10T10:22:…\n$ updated_at                  &lt;chr&gt; \"2019-08-08T02:18:17Z\", \"2018-05-10T10:22:…\n$ pushed_at                   &lt;chr&gt; \"2018-12-05T17:07:09Z\", \"2017-12-18T17:18:…\n$ git_url                     &lt;chr&gt; \"git://github.com/stephaniehicks/2018-bioi…\n$ ssh_url                     &lt;chr&gt; \"git@github.com:stephaniehicks/2018-bioinf…\n$ clone_url                   &lt;chr&gt; \"https://github.com/stephaniehicks/2018-bi…\n$ svn_url                     &lt;chr&gt; \"https://github.com/stephaniehicks/2018-bi…\n$ homepage                    &lt;chr&gt; NA, NA, NA, NA, NA, \"\", NA, NA, NA, NA, NA…\n$ size                        &lt;int&gt; 60296, 172353, 8866, 121, 675, 26688, 20, …\n$ stargazers_count            &lt;int&gt; 4, 0, 2, 1, 0, 0, 1, 8, 0, 1, 0, 15, 3, 0,…\n$ watchers_count              &lt;int&gt; 4, 0, 2, 1, 0, 0, 1, 8, 0, 1, 0, 15, 3, 0,…\n$ language                    &lt;chr&gt; \"TeX\", \"HTML\", \"R\", NA, NA, \"R\", \"R\", \"Jup…\n$ has_issues                  &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRU…\n$ has_projects                &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_downloads               &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_wiki                    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_pages                   &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ has_discussions             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ forks_count                 &lt;int&gt; 4, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 4, 1, 1, …\n$ mirror_url                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ archived                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ disabled                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ open_issues_count           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ license                     &lt;df[,5]&gt; &lt;data.frame[26 x 5]&gt;\n$ allow_forking               &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ is_template                 &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ web_commit_signoff_required &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ topics                      &lt;list&gt; &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;…\n$ visibility                  &lt;chr&gt; \"public\", \"public\", \"public\", \"public\", \"p…\n$ forks                       &lt;int&gt; 4, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 4, 1, 1,…\n$ open_issues                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ watchers                    &lt;int&gt; 4, 0, 2, 1, 0, 0, 1, 8, 0, 1, 0, 15, 3, 0,…\n$ default_branch              &lt;chr&gt; \"master\", \"master\", \"main\", \"master\", \"mas…\n\n\nWe see this has returned a data frame with the argument simplifyVector which converts the output from a list to a dataframe.\nHowever, from here, we see that there are only 30 rows (or 30 repositories). If you look on my github page, you can see there are more than 30 repositories.\n\nhttps://github.com/stephaniehicks?tab=repositories\n\n\n\n\n\n\n\nAPIs limit info from users\n\n\n\nWhat’s happening is called pagination.\nAt a high-level, the API is limiting the amount of items a user gets and splitting it into pages.\nFormally, pagination is the process of splitting the contents or a section of a website into discrete pages. Users tend to get lost when there’s bunch of data and with pagination splitting they can concentrate on a particular amount of content. Hierarchy and paginated structure improve the readability score of the content.\nIn this use case Github api splits the result into 30 items per resonse, depends on the request\n\n\nSolution: You should explicitly specify in your request how many items you would like to receive from server pagination engine, using formula for Github pagination api:\n?page=1&per_page=&lt;numberOfItemsYouSpecify&gt;\"\nYou can read more about pagination here:\n\nhttps://docs.github.com/en/rest/guides/using-pagination-in-the-rest-api\n\n\n\n\n\n\n\nExample\n\n\n\nHere we can visit this website:\n\nhttps://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000\n\nAnd see there are more than 30 repos. Let’s read it into R.\n\ngithub_url = \"https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000\"\n\njsonDataAll &lt;- read_json(github_url, simplifyVector = TRUE)\ndim(jsonDataAll)\n\n[1] 92 79\n\n\nWe now get all the public repositories! yay!"
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#access-apis-with-httr2",
    "href": "readings/04-data-collection-apis/index.html#access-apis-with-httr2",
    "title": "Retrieving data from APIs with httr2",
    "section": "Access APIs with httr2",
    "text": "Access APIs with httr2\nThere are a set of basic HTTP verbs that allow you access a set of endpoints.\nThe basic request patterns are:\n\nRetrieve a single item (GET)\nRetrieve a list of items (GET)\nCreate an item (POST)\nUpdate an item (PUT)\nDelete an item (DELETE)\n\n\nExample: GitHub commits\nLet’s say you want to retrieve information about the latest commits from a GitHub repository. We will use httr2 to make a request to the GitHub API for a repository of your choice. Later on we will make this an authenticated HTTP response to the GitHub API.\nFirst, we make sure we have the httr2 package installed and loaded. We’ll also need jsonlite package for handling JSON files and dplyr for data wrangling.\n\nlibrary(httr2)\nlibrary(jsonlite)\nlibrary(dplyr)\n\nNow we will set up our request to the GitHub API. The GitHub API endpoint for getting the latest commits in a repository is at https://api.github.com/repos/{owner}/{repo}/commits.\nFor this example, we’ll look at the latest commits for the tidyverse/dplyr repository. We will use httr2::request() function to set up the request, (and later on we will add authentication – optional, but recommended for higher rate limits), and parse the response.\n\nowner &lt;- \"tidyverse\"\nrepo &lt;- \"dplyr\"\nurl &lt;- paste0(\"https://api.github.com/repos/\", owner, \"/\", repo, \"/commits\")\n\n\nresponse &lt;- request(url) %&gt;%\n  req_perform()\nresponse\n\n&lt;httr2_response&gt;\n\n\nGET https://api.github.com/repos/tidyverse/dplyr/commits\n\n\nStatus: 200 OK\n\n\nContent-Type: application/json\n\n\nBody: In memory (146056 bytes)\n\n\nNext, we can see if the response was successful.\n\n# Check if the response was successful\nif (resp_status(response) == 200) {\n  # Parse JSON response into an R list\n  commits &lt;- resp_body_json(response, simplifyVector = TRUE)\n  \n  # View the first few rows of the commits data\n  head(commits)\n} else {\n  message(\"Failed to retrieve data. Status code: \", resp_status(response))\n}\n\n                                       sha\n1 fb25640fa1eb74746a7a74a06090045106e5d20f\n2 e4e9a295a373b85e02ae084a23f12e9212a72b98\n3 1d17672a54305170dc75c251f8ae69a85c0bea37\n4 cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84\n5 85e94fcde02ad49c77510991078899278489fd8f\n6 e0555277878ed174d40bda86690674ecdc27db55\n                                                                node_id\n1 C_kwDOAGIUpdoAKGZiMjU2NDBmYTFlYjc0NzQ2YTdhNzRhMDYwOTAwNDUxMDZlNWQyMGY\n2 C_kwDOAGIUpdoAKGU0ZTlhMjk1YTM3M2I4NWUwMmFlMDg0YTIzZjEyZTkyMTJhNzJiOTg\n3 C_kwDOAGIUpdoAKDFkMTc2NzJhNTQzMDUxNzBkYzc1YzI1MWY4YWU2OWE4NWMwYmVhMzc\n4 C_kwDOAGIUpdoAKGNmYjI1YTAzMGY5ZjdjMzlmNzdmZWQyYzk3ZjNmYTdiMTVhNTVlODQ\n5 C_kwDOAGIUpdoAKDg1ZTk0ZmNkZTAyYWQ0OWM3NzUxMDk5MTA3ODg5OTI3ODQ4OWZkOGY\n6 C_kwDOAGIUpdoAKGUwNTU1Mjc3ODc4ZWQxNzRkNDBiZGE4NjY5MDY3NGVjZGMyN2RiNTU\n    commit.author.name                         commit.author.email\n1        Kirill Müller                           kirill@cynkra.com\n2        Davis Vaughan                           davis@rstudio.com\n3              Mike Du 58779940+ilovemane@users.noreply.github.com\n4                 Adam                       adampeterso@gmail.com\n5 Núria Mercadé-Besora 61558739+nmercadeb@users.noreply.github.com\n6           James Wade                       github@jameshwade.com\n    commit.author.date commit.committer.name commit.committer.email\n1 2024-11-02T17:43:50Z         Kirill Müller      kirill@cynkra.com\n2 2024-10-01T15:53:13Z                GitHub     noreply@github.com\n3 2024-08-27T16:31:39Z                GitHub     noreply@github.com\n4 2024-08-27T16:30:57Z                GitHub     noreply@github.com\n5 2024-08-27T15:51:07Z                GitHub     noreply@github.com\n6 2024-08-27T15:40:46Z                GitHub     noreply@github.com\n  commit.committer.date\n1  2024-11-02T17:44:39Z\n2  2024-10-01T15:53:13Z\n3  2024-08-27T16:31:39Z\n4  2024-08-27T16:30:57Z\n5  2024-08-27T15:51:07Z\n6  2024-08-27T15:40:46Z\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        commit.message\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Move to tidyverse, already applied manually to gh-pages\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Remove not needed `new_expanded_quosures()` (#7090)\n3                                                                                                                                                                                                                                                                                               Add error message when passing an array in `conditions` (#7069)\\n\\n* add error message when passing a matrix\\r\\n\\r\\ntidyverse day\\r\\n\\r\\n* Update test-vec-case-when.R\\r\\n\\r\\n* fixes\\r\\n\\r\\n* Tweaks\\r\\n\\r\\n* NEWS bullet\\r\\n\\r\\n* Update snap\\r\\n\\r\\n---------\\r\\n\\r\\nCo-authored-by: Davis Vaughan &lt;davis@posit.co&gt;\n4                                                                                                                                                                                                                                                                   Add documentation clarifying appropriate use of weights in `slice_sample()` (#7052)\\n\\n* Add documentation clarifying appropriate use of weights in dplyr's `slice_sample()`.\\r\\n\\r\\n* Add documentation to relevant .Rd file.\\r\\n\\r\\n* Tweak documentation placement a bit\\r\\n\\r\\n---------\\r\\n\\r\\nCo-authored-by: Davis Vaughan &lt;davis@posit.co&gt;\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Document that `group_by()` works with data-masking (#7071)\n6 Add a `ptype` argument to `between()` (#7073)\\n\\n* add ptype argument to between Fixes #6906\\r\\n\\r\\n* update NEWS with ptype argument\\r\\n\\r\\n* document() and add tests\\r\\n\\r\\n* add back see also\\r\\n\\r\\n* add back see also\\r\\n\\r\\n* Redocument\\r\\n\\r\\n* Trim trailing whitespace\\r\\n\\r\\n* Remove extra line\\r\\n\\r\\n* Minor docs tweaks\\r\\n\\r\\n* require names ptype, update tests, update function documentation\\r\\n\\r\\n* remove unnecessary if else blocks\\r\\n\\r\\n* Tweak NEWS bullet\\r\\n\\r\\n* A few more tweaks\\r\\n\\r\\n* Few more tweaks\\r\\n\\r\\n---------\\r\\n\\r\\nCo-authored-by: Davis Vaughan &lt;davis@posit.co&gt;\n                           commit.tree.sha\n1 5aaa2c4dcdabd6c8303b660f15c963740193eb17\n2 8299635297b6b5e61c9522b525a5414993405e08\n3 9144e07c3b09886b79b64a76904501f565f1b6c8\n4 3d6a95112c5bc59e6a60d245704984e722aeacad\n5 852e02c951972c5a4e9a831c68e2425085e7fdd5\n6 18d4e6763ceb64f3967f9addb712ad0878798b38\n                                                                                  commit.tree.url\n1 https://api.github.com/repos/tidyverse/dplyr/git/trees/5aaa2c4dcdabd6c8303b660f15c963740193eb17\n2 https://api.github.com/repos/tidyverse/dplyr/git/trees/8299635297b6b5e61c9522b525a5414993405e08\n3 https://api.github.com/repos/tidyverse/dplyr/git/trees/9144e07c3b09886b79b64a76904501f565f1b6c8\n4 https://api.github.com/repos/tidyverse/dplyr/git/trees/3d6a95112c5bc59e6a60d245704984e722aeacad\n5 https://api.github.com/repos/tidyverse/dplyr/git/trees/852e02c951972c5a4e9a831c68e2425085e7fdd5\n6 https://api.github.com/repos/tidyverse/dplyr/git/trees/18d4e6763ceb64f3967f9addb712ad0878798b38\n                                                                                         commit.url\n1 https://api.github.com/repos/tidyverse/dplyr/git/commits/fb25640fa1eb74746a7a74a06090045106e5d20f\n2 https://api.github.com/repos/tidyverse/dplyr/git/commits/e4e9a295a373b85e02ae084a23f12e9212a72b98\n3 https://api.github.com/repos/tidyverse/dplyr/git/commits/1d17672a54305170dc75c251f8ae69a85c0bea37\n4 https://api.github.com/repos/tidyverse/dplyr/git/commits/cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84\n5 https://api.github.com/repos/tidyverse/dplyr/git/commits/85e94fcde02ad49c77510991078899278489fd8f\n6 https://api.github.com/repos/tidyverse/dplyr/git/commits/e0555277878ed174d40bda86690674ecdc27db55\n  commit.comment_count commit.verification.verified commit.verification.reason\n1                    0                        FALSE                   unsigned\n2                    0                         TRUE                      valid\n3                    0                         TRUE                      valid\n4                    0                         TRUE                      valid\n5                    0                         TRUE                      valid\n6                    0                         TRUE                      valid\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      commit.verification.signature\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              &lt;NA&gt;\n2 -----BEGIN PGP SIGNATURE-----\\n\\nwsFcBAABCAAQBQJm/BrpCRC1aQ7uu5UhlAAApk0QABIAjfuu47L1gaXmicgRMYpN\\nTs1JfHO7zGxafb5QYqgk80yH/w+XsqHt+Q2Xd3JLvIYSWBJ4IAuKU+R4vBOF6yhW\\nDprWxU3K0bLeOc9ycmH21WUPSBNjw/dhyFkMULBa6ZbZhsfPddb8OhPSw02ze/Rw\\n9oQSVIWC5ZGIHwBp4/dvrdmQ7ztwmFnTp8uegpIdLdfpqCereJdV74VYx7TrGYB4\\n/+48s84H2X2p/P3h15riv5t+545uhrMZMP9RspV7etRju4mloG5EP2zpLPgxrCIi\\nLhmpZdjKgrOc0AlocOWyjcGzRLSgExYV0bTeJnTpxqZRsZzkM5JMEGEnPCBP5OD3\\nd+PGv+l7WeOioB8+r5Sz+asoWqEfv2rfrjibqZpT4BSwV+R4+4p0NFtzOZpBzrCz\\nd+7mu0PWyLP4H7RQ0vWNZTMP3YYpQoEL5FX+X9qKKuFnob8n6W4Fje/B1ru4cYip\\nvI7sX43WLQ9X32x7FleFHsFAZDKSg8x/QXlJ2T1/VZSv0ge4M/wg5YmzhPi17xSl\\n7JcizRSKzqZDtDiIZQD2FjnVMNdL1LsjbnbWJGf02KejxFkgsYa2oEos2ekouilL\\n+xswdRrF8Fuh8KNCMc3MGO3nQovjMGgMoaFaYetXhYOTUSGAfQJBOOpNrH0vzf6g\\nOSuaLjJrCYFv0IIxdtrA\\n=kx9G\\n-----END PGP SIGNATURE-----\\n\n3 -----BEGIN PGP SIGNATURE-----\\n\\nwsFcBAABCAAQBQJmzf9rCRC1aQ7uu5UhlAAA+k4QADkSbzuLgeAvxtczSazlRvuW\\nAYPlvaK02ndKbIY8Ucwp/wyTGgorMH2kC3g3r0cy1bwVHvsNp0gt1S3tbxdvXXEA\\n8R0+pHSxgDvzCIkZdE5WJpN1VjQVYAmqRzeVt9ieifuBGVWapIn26fDPndXswPWq\\nQWDKh6tZn5wsfWiclR4TSKIcqOrva7AzegB0iyF/8kKer7jOuG/R5OQoTGJoXwlR\\nzGdI+JxKBnY9Q24SBo5xruKq3LKQIWUiICm48aFQ35JbsT83v+RuiAfMkrn1C0RM\\nQdN0820iz5/oShO5iIXvcIBZSZhSjQ/EQkv394YS0N4gElGwEbXQIOon5nZIzK3d\\n7jtXerms96sjUCOXyb0fB6YnbNEA3/Tiq7x61Fy6uUSrblewhd5AXNZu9/aJwvYv\\nOj1BoMdr/HSIUnHl11+90Y0RIA66WsHNCZLKm3L2DAlYczGmL/zcFNivH/3epmlB\\nMirSkqfuK1AYzaH5z8Fpu9UOkEVw18L+gFwn2fTye3rxzoy6Lr8R9eT/VAUtZCQV\\ng3LurvIWjHe1NNVxeQ702E1ACBXcUhD4Bfqij1QZeEFP7bsIo+ggcyyEIn56ayEO\\nSmGMb76kcBciL44oU8fAuzWK8nVVA54iM4ecJltYhp1o3tOFpJ+fQA4n5hxFYgc4\\nU+1DPZvop1yluVlV1vVV\\n=AwJu\\n-----END PGP SIGNATURE-----\\n\n4 -----BEGIN PGP SIGNATURE-----\\n\\nwsFcBAABCAAQBQJmzf9BCRC1aQ7uu5UhlAAA68AQAEtPIx3MrOwvPhjYi4mbBvZJ\\n/EeNZqaiHoanezr8L+AR0Fym/Asnf5h35+t4PDYU/JqGdND/es0LB6GxH3YMNUsK\\n6PrGbv4CMs3Ary5si5c7ynAlASCnbcMrvbIUM0UWzWd5eV+am0irDFmZc20g5Wt/\\ngZPYGNKK0D3RWM2KP5O6a67zm9ipuqNbAkGRat9qehxvTEblnB/v8jHZGy5WpTjw\\nZDxrdgdCHWCHM48viFsJlbEm8V17tFJ/ipy6JthZy7Ei1JyWpmuc28y3VqrofIDF\\n58OdA6RA7JDvfhWPFKq9RKjgfSXp5hgz+5edSwc9fTS77KL9MDq8ZK+Mhm12F3x+\\nzAb8fdajL4YwTjquwUfKJWYEgrc39vmFo/G84+VtYuRRvi2T8BFlXqTsEw3z109Y\\nfFzem/3R0PFn/+M68dzh931G52JEkhlcowR/Dy+cy1bgnWlEDOHZQQUtFGsuRJ/T\\nxOByNQ3GIiqxR+40VREeByXuCdLCOrD0KiggwNBIbUb9AU4fwvS3LNxDZLMB8gzJ\\n+DRTH/uMwwlySvf/gn5NvlasXVnLSTuMCi/DBEUMFpOkfeUG63stOuiiqn0p9ll8\\nHuAsLVT72uZOYOMiW+MsskehXZKKnOUlzv4JfoakFIEFMwBSDAdfsq9hWYtdZ9so\\ndNwPfMuZLou4JZ4kNJoP\\n=2gy1\\n-----END PGP SIGNATURE-----\\n\n5 -----BEGIN PGP SIGNATURE-----\\n\\nwsFcBAABCAAQBQJmzfXrCRC1aQ7uu5UhlAAAGIkQAAWFfWEtO+rNEL4oWHAm0Fdx\\ncKsyfH/j+eIZDIwJ7KF9hcd1VLeVO96lxCtAqW2/x7lYReM/NyfBtz0nQuwaVM01\\nstesFeyJZDclN2LgHWPwuq9QM3Gt2M1hrmguDvb6oM5rvT2W0XXKNS5TlPKx3TeU\\nZT1RIFfndFuvifQlZjmYMaDI9kLQS8kQtQCTjuv3Ei57uWEAbkj5r2w6SA8HA8Ti\\nQxCOWzQ8FTPqyvb3iev3xLmJvXXNr+AJXbJRkIZA3Pwu8CCOmpmf6H6HeBQqMzaG\\nkjqX5uqzmyAyf38z7Y+yALQkPySQbNp/de2jea1hrq7v2W78cR4+gIzti09Y1Q9R\\nhi5PIXwsykb4XKdZXl3kQfEBxBh7iIbBOglLPHMDRVolQMmj6S9ezjnn0FkpXdKE\\nnCPGPI/+6MzTeSPrinfO7wUpXNQocVwBEUV8Qvv8Rc/uHbKw6FLPofZepJ+Z2UmA\\npyEvwcADNGXhJM8Ef9O3tdDFhdV5bSORW9bhQh97l9yPneB5+Rui1ftiqKjqR0pC\\n9uPNrMoexCc1O/uEv5CotGjViOJrdzbqJxBWO9BD8i8LKNI/Fiuu4OHMQsXwxHye\\nqSPrOx4zrAxrg/qn9hEPQFjj+sHwjUV3dHgpSCSqzmLZzPYrAKQS7BMERogzgNke\\nT9u5cp6sbK4eI414nNvP\\n=4+mC\\n-----END PGP SIGNATURE-----\\n\n6 -----BEGIN PGP SIGNATURE-----\\n\\nwsFcBAABCAAQBQJmzfN+CRC1aQ7uu5UhlAAAL3cQABd/cNjfNWYYv/iRI12OoHJF\\n8Sqp/50IfyuyMgEJT4wGstAUi/Z632TGTQEsEBuvVbrsmlRH6myYEXIUWGEv2RM2\\nD4bgykku0rZCeIJFyMjCrnMK1NYOrp3RoqD7HlWFzvpW5ZzNyXZPwafeYvsakh5K\\nPt1V4WjYzEioPWTJIgAKEUr8Pr3zePCO0zY7NXAhsgobaxUK0PcDoTt0WeHkxhBL\\nwt2f+FylBKSbh3Fw6zv2xINGxEQWwSWa3EZTvsu5s3aTl0OOtz/1vLQ+gCYqhU9Z\\n4VHdgj0j2+AbETBPiou8E/szSuuffRTwgSkobbAkgOF6uyFg3gxRM7zjXsDiN4o6\\nwxNx72y1/tDanfUCRX/e3zcUh8gqtB4RggHoKtdun7UnAck+kgCeMH+ru5eNINxH\\n9K/1xL70FoasI0Kd9k4L0Q2YsoXOhgHVoQFBKC0AgiIWaJrjpx/C+MeMeXj/XgNm\\nQfybWEiXHL9S4jq0Wy/3he0BvwwiHcy682/FyeVx0fxUEHw4DzL0LkcBctm+yUKS\\n3MFADYcgTiVlafXFdej9mtiElSGINNh/C83Vj+LQdG6axzHeiWX6mGiRCgfEZhpT\\n+XhMnpI7XyQoeSyREnuVUx+E2PWsqG0gFocq0KV3UDnc5ZGE3JtH2L9w6CKlW7YA\\n8RlhDNCiHgAk2O7S2iE/\\n=Z8qV\\n-----END PGP SIGNATURE-----\\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 commit.verification.payload\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       &lt;NA&gt;\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               tree 8299635297b6b5e61c9522b525a5414993405e08\\nparent 1d17672a54305170dc75c251f8ae69a85c0bea37\\nauthor Davis Vaughan &lt;davis@rstudio.com&gt; 1727797993 -0400\\ncommitter GitHub &lt;noreply@github.com&gt; 1727797993 -0400\\n\\nRemove not needed `new_expanded_quosures()` (#7090)\\n\\n\n3                                                                                                                                                                                                                                                                            tree 9144e07c3b09886b79b64a76904501f565f1b6c8\\nparent cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84\\nauthor Mike Du &lt;58779940+ilovemane@users.noreply.github.com&gt; 1724776299 +0100\\ncommitter GitHub &lt;noreply@github.com&gt; 1724776299 -0400\\n\\nAdd error message when passing an array in `conditions` (#7069)\\n\\n* add error message when passing a matrix\\r\\n\\r\\ntidyverse day\\r\\n\\r\\n* Update test-vec-case-when.R\\r\\n\\r\\n* fixes\\r\\n\\r\\n* Tweaks\\r\\n\\r\\n* NEWS bullet\\r\\n\\r\\n* Update snap\\r\\n\\r\\n---------\\r\\n\\r\\nCo-authored-by: Davis Vaughan &lt;davis@posit.co&gt;\n4                                                                                                                                                                                                                                                                         tree 3d6a95112c5bc59e6a60d245704984e722aeacad\\nparent 85e94fcde02ad49c77510991078899278489fd8f\\nauthor Adam &lt;adampeterso@gmail.com&gt; 1724776257 -0400\\ncommitter GitHub &lt;noreply@github.com&gt; 1724776257 -0400\\n\\nAdd documentation clarifying appropriate use of weights in `slice_sample()` (#7052)\\n\\n* Add documentation clarifying appropriate use of weights in dplyr's `slice_sample()`.\\r\\n\\r\\n* Add documentation to relevant .Rd file.\\r\\n\\r\\n* Tweak documentation placement a bit\\r\\n\\r\\n---------\\r\\n\\r\\nCo-authored-by: Davis Vaughan &lt;davis@posit.co&gt;\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       tree 852e02c951972c5a4e9a831c68e2425085e7fdd5\\nparent e0555277878ed174d40bda86690674ecdc27db55\\nauthor Núria Mercadé-Besora &lt;61558739+nmercadeb@users.noreply.github.com&gt; 1724773867 +0100\\ncommitter GitHub &lt;noreply@github.com&gt; 1724773867 -0400\\n\\nDocument that `group_by()` works with data-masking (#7071)\\n\\n\n6 tree 18d4e6763ceb64f3967f9addb712ad0878798b38\\nparent 173b4232bff810f563e1739211ea7545ed0651e6\\nauthor James Wade &lt;github@jameshwade.com&gt; 1724773246 -0400\\ncommitter GitHub &lt;noreply@github.com&gt; 1724773246 -0400\\n\\nAdd a `ptype` argument to `between()` (#7073)\\n\\n* add ptype argument to between Fixes #6906\\r\\n\\r\\n* update NEWS with ptype argument\\r\\n\\r\\n* document() and add tests\\r\\n\\r\\n* add back see also\\r\\n\\r\\n* add back see also\\r\\n\\r\\n* Redocument\\r\\n\\r\\n* Trim trailing whitespace\\r\\n\\r\\n* Remove extra line\\r\\n\\r\\n* Minor docs tweaks\\r\\n\\r\\n* require names ptype, update tests, update function documentation\\r\\n\\r\\n* remove unnecessary if else blocks\\r\\n\\r\\n* Tweak NEWS bullet\\r\\n\\r\\n* A few more tweaks\\r\\n\\r\\n* Few more tweaks\\r\\n\\r\\n---------\\r\\n\\r\\nCo-authored-by: Davis Vaughan &lt;davis@posit.co&gt;\n                                                                                            url\n1 https://api.github.com/repos/tidyverse/dplyr/commits/fb25640fa1eb74746a7a74a06090045106e5d20f\n2 https://api.github.com/repos/tidyverse/dplyr/commits/e4e9a295a373b85e02ae084a23f12e9212a72b98\n3 https://api.github.com/repos/tidyverse/dplyr/commits/1d17672a54305170dc75c251f8ae69a85c0bea37\n4 https://api.github.com/repos/tidyverse/dplyr/commits/cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84\n5 https://api.github.com/repos/tidyverse/dplyr/commits/85e94fcde02ad49c77510991078899278489fd8f\n6 https://api.github.com/repos/tidyverse/dplyr/commits/e0555277878ed174d40bda86690674ecdc27db55\n                                                                            html_url\n1 https://github.com/tidyverse/dplyr/commit/fb25640fa1eb74746a7a74a06090045106e5d20f\n2 https://github.com/tidyverse/dplyr/commit/e4e9a295a373b85e02ae084a23f12e9212a72b98\n3 https://github.com/tidyverse/dplyr/commit/1d17672a54305170dc75c251f8ae69a85c0bea37\n4 https://github.com/tidyverse/dplyr/commit/cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84\n5 https://github.com/tidyverse/dplyr/commit/85e94fcde02ad49c77510991078899278489fd8f\n6 https://github.com/tidyverse/dplyr/commit/e0555277878ed174d40bda86690674ecdc27db55\n                                                                                            comments_url\n1 https://api.github.com/repos/tidyverse/dplyr/commits/fb25640fa1eb74746a7a74a06090045106e5d20f/comments\n2 https://api.github.com/repos/tidyverse/dplyr/commits/e4e9a295a373b85e02ae084a23f12e9212a72b98/comments\n3 https://api.github.com/repos/tidyverse/dplyr/commits/1d17672a54305170dc75c251f8ae69a85c0bea37/comments\n4 https://api.github.com/repos/tidyverse/dplyr/commits/cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84/comments\n5 https://api.github.com/repos/tidyverse/dplyr/commits/85e94fcde02ad49c77510991078899278489fd8f/comments\n6 https://api.github.com/repos/tidyverse/dplyr/commits/e0555277878ed174d40bda86690674ecdc27db55/comments\n  author.login author.id       author.node_id\n1       krlmlr   1741643 MDQ6VXNlcjE3NDE2NDM=\n2 DavisVaughan  19150088 MDQ6VXNlcjE5MTUwMDg4\n3    ilovemane  58779940 MDQ6VXNlcjU4Nzc5OTQw\n4  apeterson91   4251291 MDQ6VXNlcjQyNTEyOTE=\n5    nmercadeb  61558739 MDQ6VXNlcjYxNTU4NzM5\n6   JamesHWade   6314313 MDQ6VXNlcjYzMTQzMTM=\n                                     author.avatar_url author.gravatar_id\n1  https://avatars.githubusercontent.com/u/1741643?v=4                   \n2 https://avatars.githubusercontent.com/u/19150088?v=4                   \n3 https://avatars.githubusercontent.com/u/58779940?v=4                   \n4  https://avatars.githubusercontent.com/u/4251291?v=4                   \n5 https://avatars.githubusercontent.com/u/61558739?v=4                   \n6  https://avatars.githubusercontent.com/u/6314313?v=4                   \n                                 author.url                 author.html_url\n1       https://api.github.com/users/krlmlr       https://github.com/krlmlr\n2 https://api.github.com/users/DavisVaughan https://github.com/DavisVaughan\n3    https://api.github.com/users/ilovemane    https://github.com/ilovemane\n4  https://api.github.com/users/apeterson91  https://github.com/apeterson91\n5    https://api.github.com/users/nmercadeb    https://github.com/nmercadeb\n6   https://api.github.com/users/JamesHWade   https://github.com/JamesHWade\n                                 author.followers_url\n1       https://api.github.com/users/krlmlr/followers\n2 https://api.github.com/users/DavisVaughan/followers\n3    https://api.github.com/users/ilovemane/followers\n4  https://api.github.com/users/apeterson91/followers\n5    https://api.github.com/users/nmercadeb/followers\n6   https://api.github.com/users/JamesHWade/followers\n                                              author.following_url\n1       https://api.github.com/users/krlmlr/following{/other_user}\n2 https://api.github.com/users/DavisVaughan/following{/other_user}\n3    https://api.github.com/users/ilovemane/following{/other_user}\n4  https://api.github.com/users/apeterson91/following{/other_user}\n5    https://api.github.com/users/nmercadeb/following{/other_user}\n6   https://api.github.com/users/JamesHWade/following{/other_user}\n                                           author.gists_url\n1       https://api.github.com/users/krlmlr/gists{/gist_id}\n2 https://api.github.com/users/DavisVaughan/gists{/gist_id}\n3    https://api.github.com/users/ilovemane/gists{/gist_id}\n4  https://api.github.com/users/apeterson91/gists{/gist_id}\n5    https://api.github.com/users/nmercadeb/gists{/gist_id}\n6   https://api.github.com/users/JamesHWade/gists{/gist_id}\n                                                author.starred_url\n1       https://api.github.com/users/krlmlr/starred{/owner}{/repo}\n2 https://api.github.com/users/DavisVaughan/starred{/owner}{/repo}\n3    https://api.github.com/users/ilovemane/starred{/owner}{/repo}\n4  https://api.github.com/users/apeterson91/starred{/owner}{/repo}\n5    https://api.github.com/users/nmercadeb/starred{/owner}{/repo}\n6   https://api.github.com/users/JamesHWade/starred{/owner}{/repo}\n                                 author.subscriptions_url\n1       https://api.github.com/users/krlmlr/subscriptions\n2 https://api.github.com/users/DavisVaughan/subscriptions\n3    https://api.github.com/users/ilovemane/subscriptions\n4  https://api.github.com/users/apeterson91/subscriptions\n5    https://api.github.com/users/nmercadeb/subscriptions\n6   https://api.github.com/users/JamesHWade/subscriptions\n                        author.organizations_url\n1       https://api.github.com/users/krlmlr/orgs\n2 https://api.github.com/users/DavisVaughan/orgs\n3    https://api.github.com/users/ilovemane/orgs\n4  https://api.github.com/users/apeterson91/orgs\n5    https://api.github.com/users/nmercadeb/orgs\n6   https://api.github.com/users/JamesHWade/orgs\n                                 author.repos_url\n1       https://api.github.com/users/krlmlr/repos\n2 https://api.github.com/users/DavisVaughan/repos\n3    https://api.github.com/users/ilovemane/repos\n4  https://api.github.com/users/apeterson91/repos\n5    https://api.github.com/users/nmercadeb/repos\n6   https://api.github.com/users/JamesHWade/repos\n                                           author.events_url\n1       https://api.github.com/users/krlmlr/events{/privacy}\n2 https://api.github.com/users/DavisVaughan/events{/privacy}\n3    https://api.github.com/users/ilovemane/events{/privacy}\n4  https://api.github.com/users/apeterson91/events{/privacy}\n5    https://api.github.com/users/nmercadeb/events{/privacy}\n6   https://api.github.com/users/JamesHWade/events{/privacy}\n                                 author.received_events_url author.type\n1       https://api.github.com/users/krlmlr/received_events        User\n2 https://api.github.com/users/DavisVaughan/received_events        User\n3    https://api.github.com/users/ilovemane/received_events        User\n4  https://api.github.com/users/apeterson91/received_events        User\n5    https://api.github.com/users/nmercadeb/received_events        User\n6   https://api.github.com/users/JamesHWade/received_events        User\n  author.user_view_type author.site_admin committer.login committer.id\n1                public             FALSE          krlmlr      1741643\n2                public             FALSE        web-flow     19864447\n3                public             FALSE        web-flow     19864447\n4                public             FALSE        web-flow     19864447\n5                public             FALSE        web-flow     19864447\n6                public             FALSE        web-flow     19864447\n     committer.node_id                                 committer.avatar_url\n1 MDQ6VXNlcjE3NDE2NDM=  https://avatars.githubusercontent.com/u/1741643?v=4\n2 MDQ6VXNlcjE5ODY0NDQ3 https://avatars.githubusercontent.com/u/19864447?v=4\n3 MDQ6VXNlcjE5ODY0NDQ3 https://avatars.githubusercontent.com/u/19864447?v=4\n4 MDQ6VXNlcjE5ODY0NDQ3 https://avatars.githubusercontent.com/u/19864447?v=4\n5 MDQ6VXNlcjE5ODY0NDQ3 https://avatars.githubusercontent.com/u/19864447?v=4\n6 MDQ6VXNlcjE5ODY0NDQ3 https://avatars.githubusercontent.com/u/19864447?v=4\n  committer.gravatar_id                         committer.url\n1                         https://api.github.com/users/krlmlr\n2                       https://api.github.com/users/web-flow\n3                       https://api.github.com/users/web-flow\n4                       https://api.github.com/users/web-flow\n5                       https://api.github.com/users/web-flow\n6                       https://api.github.com/users/web-flow\n           committer.html_url                         committer.followers_url\n1   https://github.com/krlmlr   https://api.github.com/users/krlmlr/followers\n2 https://github.com/web-flow https://api.github.com/users/web-flow/followers\n3 https://github.com/web-flow https://api.github.com/users/web-flow/followers\n4 https://github.com/web-flow https://api.github.com/users/web-flow/followers\n5 https://github.com/web-flow https://api.github.com/users/web-flow/followers\n6 https://github.com/web-flow https://api.github.com/users/web-flow/followers\n                                       committer.following_url\n1   https://api.github.com/users/krlmlr/following{/other_user}\n2 https://api.github.com/users/web-flow/following{/other_user}\n3 https://api.github.com/users/web-flow/following{/other_user}\n4 https://api.github.com/users/web-flow/following{/other_user}\n5 https://api.github.com/users/web-flow/following{/other_user}\n6 https://api.github.com/users/web-flow/following{/other_user}\n                                    committer.gists_url\n1   https://api.github.com/users/krlmlr/gists{/gist_id}\n2 https://api.github.com/users/web-flow/gists{/gist_id}\n3 https://api.github.com/users/web-flow/gists{/gist_id}\n4 https://api.github.com/users/web-flow/gists{/gist_id}\n5 https://api.github.com/users/web-flow/gists{/gist_id}\n6 https://api.github.com/users/web-flow/gists{/gist_id}\n                                         committer.starred_url\n1   https://api.github.com/users/krlmlr/starred{/owner}{/repo}\n2 https://api.github.com/users/web-flow/starred{/owner}{/repo}\n3 https://api.github.com/users/web-flow/starred{/owner}{/repo}\n4 https://api.github.com/users/web-flow/starred{/owner}{/repo}\n5 https://api.github.com/users/web-flow/starred{/owner}{/repo}\n6 https://api.github.com/users/web-flow/starred{/owner}{/repo}\n                          committer.subscriptions_url\n1   https://api.github.com/users/krlmlr/subscriptions\n2 https://api.github.com/users/web-flow/subscriptions\n3 https://api.github.com/users/web-flow/subscriptions\n4 https://api.github.com/users/web-flow/subscriptions\n5 https://api.github.com/users/web-flow/subscriptions\n6 https://api.github.com/users/web-flow/subscriptions\n                 committer.organizations_url\n1   https://api.github.com/users/krlmlr/orgs\n2 https://api.github.com/users/web-flow/orgs\n3 https://api.github.com/users/web-flow/orgs\n4 https://api.github.com/users/web-flow/orgs\n5 https://api.github.com/users/web-flow/orgs\n6 https://api.github.com/users/web-flow/orgs\n                          committer.repos_url\n1   https://api.github.com/users/krlmlr/repos\n2 https://api.github.com/users/web-flow/repos\n3 https://api.github.com/users/web-flow/repos\n4 https://api.github.com/users/web-flow/repos\n5 https://api.github.com/users/web-flow/repos\n6 https://api.github.com/users/web-flow/repos\n                                    committer.events_url\n1   https://api.github.com/users/krlmlr/events{/privacy}\n2 https://api.github.com/users/web-flow/events{/privacy}\n3 https://api.github.com/users/web-flow/events{/privacy}\n4 https://api.github.com/users/web-flow/events{/privacy}\n5 https://api.github.com/users/web-flow/events{/privacy}\n6 https://api.github.com/users/web-flow/events{/privacy}\n                          committer.received_events_url committer.type\n1   https://api.github.com/users/krlmlr/received_events           User\n2 https://api.github.com/users/web-flow/received_events           User\n3 https://api.github.com/users/web-flow/received_events           User\n4 https://api.github.com/users/web-flow/received_events           User\n5 https://api.github.com/users/web-flow/received_events           User\n6 https://api.github.com/users/web-flow/received_events           User\n  committer.user_view_type committer.site_admin\n1                   public                FALSE\n2                   public                FALSE\n3                   public                FALSE\n4                   public                FALSE\n5                   public                FALSE\n6                   public                FALSE\n                                                                                                                                                                                                                      parents\n1 e4e9a295a373b85e02ae084a23f12e9212a72b98, https://api.github.com/repos/tidyverse/dplyr/commits/e4e9a295a373b85e02ae084a23f12e9212a72b98, https://github.com/tidyverse/dplyr/commit/e4e9a295a373b85e02ae084a23f12e9212a72b98\n2 1d17672a54305170dc75c251f8ae69a85c0bea37, https://api.github.com/repos/tidyverse/dplyr/commits/1d17672a54305170dc75c251f8ae69a85c0bea37, https://github.com/tidyverse/dplyr/commit/1d17672a54305170dc75c251f8ae69a85c0bea37\n3 cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84, https://api.github.com/repos/tidyverse/dplyr/commits/cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84, https://github.com/tidyverse/dplyr/commit/cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84\n4 85e94fcde02ad49c77510991078899278489fd8f, https://api.github.com/repos/tidyverse/dplyr/commits/85e94fcde02ad49c77510991078899278489fd8f, https://github.com/tidyverse/dplyr/commit/85e94fcde02ad49c77510991078899278489fd8f\n5 e0555277878ed174d40bda86690674ecdc27db55, https://api.github.com/repos/tidyverse/dplyr/commits/e0555277878ed174d40bda86690674ecdc27db55, https://github.com/tidyverse/dplyr/commit/e0555277878ed174d40bda86690674ecdc27db55\n6 173b4232bff810f563e1739211ea7545ed0651e6, https://api.github.com/repos/tidyverse/dplyr/commits/173b4232bff810f563e1739211ea7545ed0651e6, https://github.com/tidyverse/dplyr/commit/173b4232bff810f563e1739211ea7545ed0651e6\n\n\nThen, we can extract specific data from the commits including details like the commit message, author, and date. We will create a simplified data frame with just these columns.\n\ncommits_df &lt;- tibble(\n    sha = commits$sha,\n    author = commits$commit$author$name,\n    date = commits$commit$author$date,\n    message = commits$commit$message)\ncommits_df\n\n# A tibble: 30 × 4\n   sha                                      author               date    message\n   &lt;chr&gt;                                    &lt;chr&gt;                &lt;chr&gt;   &lt;chr&gt;  \n 1 fb25640fa1eb74746a7a74a06090045106e5d20f Kirill Müller        2024-1… \"Move …\n 2 e4e9a295a373b85e02ae084a23f12e9212a72b98 Davis Vaughan        2024-1… \"Remov…\n 3 1d17672a54305170dc75c251f8ae69a85c0bea37 Mike Du              2024-0… \"Add e…\n 4 cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84 Adam                 2024-0… \"Add d…\n 5 85e94fcde02ad49c77510991078899278489fd8f Núria Mercadé-Besora 2024-0… \"Docum…\n 6 e0555277878ed174d40bda86690674ecdc27db55 James Wade           2024-0… \"Add a…\n 7 173b4232bff810f563e1739211ea7545ed0651e6 Kirill Müller        2024-0… \"Fix e…\n 8 b2c7e047081301afe2ca376c508491d77bea4bde Jeremy Winget        2024-0… \"Fix `…\n 9 663d7f07140b45d5d3a256465728d9d5c35b9455 Rodrigo Dal Ben      2024-0… \"Fix t…\n10 cdc99196a2d80f14b48ceb5edad328ab34a5bf65 Davis Vaughan        2024-0… \"Add `…\n# ℹ 20 more rows\n\n\n\n\nAuthentication\nAuthenticating with the GitHub API via an API key allows you to send much more requests to the API.\nAPI access keys for the GitHub API are called personal access tokens (PAT) and the documentation explains how to generate a PAT once you have logged into your GitHub account.\nTo create a PAT: You can create a PAT from your GitHub account (Settings &gt; Developer settings &gt; Personal access tokens). It’s a good idea to only grant “read” permissions.\n\n\n\n\n\n\nWhere to store API keys\n\n\n\nFirst, please be careful with your PATs and never publish them.\nIt is suggested you keep them in your .Renviron file which looks something like this on the inside:\nGITHUB_PAT = &lt;add my GitHub PAT here&gt; \nIf you do not have an .Renviron file in your home directory, you can make one:\ncd ~\ntouch .Renviron\nIf you want additional guidance on where you should store them, I like this post:\n\nhttps://www.r-bloggers.com/2015/11/how-to-store-and-use-webservice-keys-and-authentication-details-with-r/\n\n\n\nAssuming you have created and stored an API key in the .Renviron file in your home directory, you can fetch it with the Sys.getenv() function and use the PAT in our httr2 request.\n\n# Read the PAT from environment variables\ngithub_pat &lt;- Sys.getenv(\"GITHUB_PAT\")\n\n# Make the GET request with PAT for authentication\nresponse &lt;- request(url) %&gt;%\n  req_auth_bearer_token(github_pat) %&gt;%\n  req_perform()\n\nNow, we check the response as before\n\nif (resp_status(response) == 200) {\n  commits &lt;- resp_body_json(response, simplifyVector = TRUE)\n  commits_df &lt;- tibble(\n    sha = commits$sha,\n    author = commits$commit$author$name,\n    date = commits$commit$author$date,\n    message = commits$commit$message)\n  commits_df\n} else {\n  message(\"Failed to retrieve data. Status code: \", resp_status(response))\n}\n\n# A tibble: 30 × 4\n   sha                                      author               date    message\n   &lt;chr&gt;                                    &lt;chr&gt;                &lt;chr&gt;   &lt;chr&gt;  \n 1 fb25640fa1eb74746a7a74a06090045106e5d20f Kirill Müller        2024-1… \"Move …\n 2 e4e9a295a373b85e02ae084a23f12e9212a72b98 Davis Vaughan        2024-1… \"Remov…\n 3 1d17672a54305170dc75c251f8ae69a85c0bea37 Mike Du              2024-0… \"Add e…\n 4 cfb25a030f9f7c39f77fed2c97f3fa7b15a55e84 Adam                 2024-0… \"Add d…\n 5 85e94fcde02ad49c77510991078899278489fd8f Núria Mercadé-Besora 2024-0… \"Docum…\n 6 e0555277878ed174d40bda86690674ecdc27db55 James Wade           2024-0… \"Add a…\n 7 173b4232bff810f563e1739211ea7545ed0651e6 Kirill Müller        2024-0… \"Fix e…\n 8 b2c7e047081301afe2ca376c508491d77bea4bde Jeremy Winget        2024-0… \"Fix `…\n 9 663d7f07140b45d5d3a256465728d9d5c35b9455 Rodrigo Dal Ben      2024-0… \"Fix t…\n10 cdc99196a2d80f14b48ceb5edad328ab34a5bf65 Davis Vaughan        2024-0… \"Add `…\n# ℹ 20 more rows\n\n\n\n\nExample: Learn about Stephanie\nLet’s start by using the GitHub API to learn information about myself (Stephanie Hicks). First, let’s check out https://api.github.com/users/stephaniehicks.\nNow, we have decided to explore https://api.github.com/users/stephaniehicks/repos.\nTo use httr2, start by creating a request:\n\nowner &lt;- \"stephaniehicks\"\nurl &lt;- paste0(\"https://api.github.com/users/\", owner,\"/repos\")\n\n# Make the GET request with PAT for authentication\nresponse &lt;- request(url) %&gt;%\n  req_auth_bearer_token(github_pat) %&gt;%\n  req_perform()\n\nstephanie &lt;- resp_body_json(response, simplifyVector = TRUE)\n\nWe convert the response to a parsed JSON file (or a list)."
  },
  {
    "objectID": "readings/04-data-collection-apis/index.html#a-bit-of-eda-fun",
    "href": "readings/04-data-collection-apis/index.html#a-bit-of-eda-fun",
    "title": "Retrieving data from APIs with httr2",
    "section": "A bit of EDA fun",
    "text": "A bit of EDA fun\nLet’s have a bit of fun and explore some questions:\n\nHow many public repositories do I have?\n\n\nstephanie$forks\n\n [1]  4  0  1  0  1  0  0  2  0  0  0  4  1  1  0  1 11  0  0  3  0  3  0  1  1\n[26]  0  0  1  0  0\n\n\nWhat’s the most popular language?\n\ntable(stephanie$language)\n\n\n            HTML Jupyter Notebook                R             Ruby \n               7                1               12                2 \n             TeX \n               1 \n\n\nTo find out how many repos that I have with open issues, we can just create a table:\n\n# how many repos have open issues? \ntable(stephanie$open_issues)\n\n\n 0  1 \n27  3 \n\n\nWhew! Not as many as I thought.\n\n\n\n\n\n\nOther examples with GitHub API\n\n\n\nFinally, I will leave you with a few other examples of using GitHub API:\n\nHow long does it take to close a GitHub Issue in the dplyr package?\nHow to retrieve all commits for a branch\nGetting my GitHub Activity"
  },
  {
    "objectID": "readings/05-database-programming/index.html",
    "href": "readings/05-database-programming/index.html",
    "title": "Relational databases and SQL basics",
    "section": "",
    "text": "We will load them here before kicking off the lecture.\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RSQLite)\nlibrary(dbplyr)"
  },
  {
    "objectID": "readings/05-database-programming/index.html#languages",
    "href": "readings/05-database-programming/index.html#languages",
    "title": "Relational databases and SQL basics",
    "section": "Languages",
    "text": "Languages\nWe write queries in a language called Structured Query Language (SQL), which provides hundreds of different ways to analyze and recombine data.\nMany database managers understand SQL but each stores data in a different way, so a database created with one cannot be used directly by another.\nHowever, every database manager can import and export data in a variety of formats like .csv, .sql, so it is possible to move information from one to another.\nNext, we will some example SQL queries that are common tasks for data scientists."
  },
  {
    "objectID": "readings/05-database-programming/index.html#example-data",
    "href": "readings/05-database-programming/index.html#example-data",
    "title": "Relational databases and SQL basics",
    "section": "Example data",
    "text": "Example data\nBefore we get into using SQLite to select the data, let’s take a look at the tables of the database we will use in our examples:\n\n\nPerson: People who took readings, id being the unique identifier for that person.\n\n\n\nid\npersonal\nfamily\n\n\n\n\ndyer\nWilliam\nDyer\n\n\npb\nFrank\nPabodie\n\n\nlake\nAnderson\nLake\n\n\nroe\nValentina\nRoerich\n\n\ndanforth\nFrank\nDanforth\n\n\n\nSite: Locations of the sites where readings were taken.\n\n\n\nname\nlat\nlong\n\n\n\n\nDR-1\n-49.85\n-128.57\n\n\nDR-3\n-47.15\n-126.72\n\n\nMSK-4\n-48.87\n-123.4\n\n\n\nVisited: Specific identification id of the precise locations where readings were taken at the sites and dates.\n\n\n\nid\nsite\ndated\n\n\n\n\n619\nDR-1\n1927-02-08\n\n\n622\nDR-1\n1927-02-10\n\n\n734\nDR-3\n1930-01-07\n\n\n735\nDR-3\n1930-01-12\n\n\n751\nDR-3\n1930-02-26\n\n\n752\nDR-3\n-null-\n\n\n837\nMSK-4\n1932-01-14\n\n\n844\nDR-1\n1932-03-22\n\n\n\n\n\nSurvey: The measurements taken at each precise location on these sites. They are identified as taken. The field quant is short for quantity and indicates what is being measured. The values are rad, sal, and temp referring to ‘radiation’, ‘salinity’ and ‘temperature’, respectively.\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n619\ndyer\nrad\n9.82\n\n\n619\ndyer\nsal\n0.13\n\n\n622\ndyer\nrad\n7.8\n\n\n622\ndyer\nsal\n0.09\n\n\n734\npb\nrad\n8.41\n\n\n734\nlake\nsal\n0.05\n\n\n734\npb\ntemp\n-21.5\n\n\n735\npb\nrad\n7.22\n\n\n735\n-null-\nsal\n0.06\n\n\n735\n-null-\ntemp\n-26.0\n\n\n751\npb\nrad\n4.35\n\n\n751\npb\ntemp\n-18.5\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nrad\n2.19\n\n\n752\nlake\nsal\n0.09\n\n\n752\nlake\ntemp\n-16.0\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nrad\n1.46\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5\n\n\n844\nroe\nrad\n11.25"
  },
  {
    "objectID": "readings/05-database-programming/index.html#sql-.tables-and-.schema",
    "href": "readings/05-database-programming/index.html#sql-.tables-and-.schema",
    "title": "Relational databases and SQL basics",
    "section": "SQL .tables and .schema",
    "text": "SQL .tables and .schema\nIn an interactive sqlite3 session,\n\nType .tables to list the tables in the database\nType .schema to see the SQL statements used to create the tables in the database. The statements will have a list of the columns and the data types each column stores.\n\n\n\n\n\n\n\nMore about .schema\n\n\n\nThe output from .schema is formatted as &lt;columnName dataType&gt;.\n\n\nOutput\n\nCREATE TABLE Person (id text, personal text, family text);\nCREATE TABLE Site (name text, lat real, long real);\nCREATE TABLE Survey (taken integer, person text, quant text, reading real);\nCREATE TABLE Visited (id integer, site text, dated text);\n\nThus we can see from the first line that the table Person has three columns:\n\nid with type text\npersonal with type text\nfamily with type text\n\n\n\nThe available data types vary based on the database manager - you can search online for what data types are supported."
  },
  {
    "objectID": "readings/05-database-programming/index.html#more-about-select",
    "href": "readings/05-database-programming/index.html#more-about-select",
    "title": "Relational databases and SQL basics",
    "section": "More about SELECT",
    "text": "More about SELECT\nRow and columns in a database table are not actually stored in any particular order.\nThey will always be displayed in some order, but we can control that in various ways.\n\n\n\n\n\n\nExample\n\n\n\nWe could swap the columns in the output by writing our query as:\n\n\nSQL\n\nSELECT personal, family FROM Person;\n\n\n\nOutput\n\n|personal |family  |\n|---------|--------|\n|William  |Dyer    |\n|Frank    |Pabodie |\n|Anderson |Lake    |\n|Valentina|Roerich |\n|Frank    |Danforth|\n\nor even repeat columns:\n\n\nSQL\n\nSELECT id, id, id FROM Person;\n\n\n\nOutput\n\n|id      |id      |id      |\n|--------|--------|--------|\n|dyer    |dyer    |dyer    |\n|pb      |pb      |pb      |\n|lake    |lake    |lake    |\n|roe     |roe     |roe     |\n|danforth|danforth|danforth|\n\n\n\n\nThe * operator\nAs a shortcut, we can select all of the columns in a table using *:\n\n\nSQL\n\nSELECT * FROM Person;\n\n\n\nOutput\n\n|id      |personal |family  |\n|--------|---------|--------|\n|dyer    |William  |Dyer    |\n|pb      |Frank    |Pabodie |\n|lake    |Anderson |Lake    |\n|roe     |Valentina|Roerich |\n|danforth|Frank    |Danforth|"
  },
  {
    "objectID": "readings/05-database-programming/index.html#sorting-and-removing-duplicates",
    "href": "readings/05-database-programming/index.html#sorting-and-removing-duplicates",
    "title": "Relational databases and SQL basics",
    "section": "Sorting and removing duplicates",
    "text": "Sorting and removing duplicates\nIn this section, we will explore the following questions of the Antarctic data\n\nWhat are the unique types of measurements taken in Survey?\nWhich scientists took measurements on the expedition?\n\nTo answer the first question, we will extract the values in column quant (short for quantity) from Survey, which contains values rad, sal, and temp referring to ‘radiation’, ‘salinity’ and ‘temperature’, respectively.\nHowever, we only want the unique value labels.\nThe following will extract the quant column from the Survey table, but not return unique / distinct labels.\n\n\nSQL\n\nSELECT quant FROM Survey;\n\nBut, adding the DISTINCT keyword to our query eliminates the redundant output to make the result more readable:\n\n\nSQL\n\nSELECT DISTINCT quant FROM Survey;\n\n\n\nOutput\n\n|quant|\n|-----|\n|rad  |\n|sal  |\n|temp |\n\nYou can also use the DISTINCT keyword on multiple columns.\nIf we select more than one column, distinct sets of values are returned (in this case pairs, because we are selecting two columns) and duplicates are removed:\n\n\nSQL\n\nSELECT DISTINCT taken, quant FROM Survey;\n\n\n\nOutput\n\n|taken|quant|\n|-----|-----|\n|619  |rad  |\n|619  |sal  |\n|622  |rad  |\n|622  |sal  |\n|734  |rad  |\n|734  |sal  |\n|734  |temp |\n|735  |rad  |\n|735  |sal  |\n|735  |temp |\n|751  |rad  |\n|751  |temp |\n|751  |sal  |\n|752  |rad  |\n|752  |sal  |\n|752  |temp |\n|837  |rad  |\n|837  |sal  |\n|844  |rad  |\n\nNext, we will look at the Person table and sort the scientists names.\nDatabase records are not necessarily sorted in any particular order.\nIf you want to have the table returned sorted in a particular way, you add the ORDER BY clause to our query:\n\n\nSQL\n\nSELECT * FROM Person ORDER BY id;\n\n\n\nOutput\n\n|id     |personal |family  |\n|-------|---------|--------|\n|danfort|Frank    |Danforth|\n|dyer   |William  |Dyer    |\n|lake   |Anderson |Lake    |\n|pb     |Frank    |Pabodie |\n|roe    |Valentina|Roerich |\n\nThe default is to sort in an ascending order, but we can sort in a descending order using DESC (for “descending”):\n\n\nSQL\n\nSELECT * FROM person ORDER BY id DESC;\n\n\n\nOutput\n\n|id     |personal |family  |\n|-------|---------|--------|\n|roe    |Valentina|Roerich |\n|pb     |Frank    |Pabodie |\n|lake   |Anderson |Lake    |\n|dyer   |William  |Dyer    |\n|danfort|Frank    |Danforth|\n\n(And if we want to make it clear that we’re sorting in ascending order, we can use ASC instead of DESC.)\n\n\n\n\n\n\nExample\n\n\n\nLet’s look at which scientist (person) measured what quantities (quant) during each visit (taken) with the Survey table.\nWe also want to sort by two columns at once\n\nSort results first in ascending order by taken\nAnd then in descending order by person within each group of equal taken values:\n\n\n\nSQL\n\nSELECT taken, person, quant FROM Survey ORDER BY taken ASC, person DESC;\n\n\n\nOutput\n\n|taken|person|quant|\n|-----|------|-----|\n|619  |dyer  |rad  |\n|619  |dyer  |sal  |\n|622  |dyer  |rad  |\n|622  |dyer  |sal  |\n|734  |pb    |rad  |\n|734  |pb    |temp |\n|734  |lake  |sal  |\n|735  |pb    |rad  |\n|735  |-null-|sal  |\n|735  |-null-|temp |\n|751  |pb    |rad  |\n|751  |pb    |temp |\n|751  |lake  |sal  |\n|752  |roe   |sal  |\n|752  |lake  |rad  |\n|752  |lake  |sal  |\n|752  |lake  |temp |\n|837  |roe   |sal  |\n|837  |lake  |rad  |\n|837  |lake  |sal  |\n|844  |roe   |rad  |\n\nThis query gives us a good idea of which scientist was involved in which visit, and what measurements they performed during the visit.\n\n\nLooking at the table, it seems like some scientists specialized in certain kinds of measurements.\nWe can examine which scientists performed which measurements by selecting the appropriate columns and removing duplicates.\n\n\nSQL\n\nSELECT DISTINCT quant, person FROM Survey ORDER BY quant ASC;\n\n\n\nOutput\n\n|quant|person|\n|-----|------|\n|rad  |dyer  |\n|rad  |pb    |\n|rad  |lake  |\n|rad  |roe   |\n|sal  |dyer  |\n|sal  |lake  |\n|sal  |-null-|\n|sal  |roe   |\n|temp |pb    |\n|temp |-null-|\n|temp |lake  |"
  },
  {
    "objectID": "readings/05-database-programming/index.html#other-important-tasks",
    "href": "readings/05-database-programming/index.html#other-important-tasks",
    "title": "Relational databases and SQL basics",
    "section": "Other important tasks",
    "text": "Other important tasks\nThere are many other tasks you can do with SQL, but for purposes of the lecture, I will leave you to work through this carpentries tutorial if you want to know more:\n\nhttps://swcarpentry.github.io/sql-novice-survey\n\n\nFiltering\nHow can you select subsets of data? You use WHERE.\nHere is an example of filtering for all rows that contain “dyer” in the Person column.\n\n\nSQL\n\nSELECT * FROM Survey WHERE person = \"dyer\";\n\n\n\nOutput\n\n619|dyer|rad|9.82\n619|dyer|sal|0.13\n622|dyer|rad|7.8\n622|dyer|sal|0.09\n\nFor more information about filtering, read through this tutorial:\n\nhttps://swcarpentry.github.io/sql-novice-survey/03-filter\n\n\n\nAnd more\nThe carpentries tutorial has so much more including how to:\n\nCalculating new values (https://swcarpentry.github.io/sql-novice-survey/04-calc)\nHow to deal with missing data (https://swcarpentry.github.io/sql-novice-survey/05-null)\nHow to aggregate data to calculate summaries (https://swcarpentry.github.io/sql-novice-survey/06-agg)\nHow to write queries that joins together two tables (https://swcarpentry.github.io/sql-novice-survey/07-join)\nHow to create tables or modify exisiting data in tables (https://swcarpentry.github.io/sql-novice-survey/09-create)"
  },
  {
    "objectID": "readings/05-database-programming/index.html#connect-to-the-sql-database",
    "href": "readings/05-database-programming/index.html#connect-to-the-sql-database",
    "title": "Relational databases and SQL basics",
    "section": "Connect to the SQL database",
    "text": "Connect to the SQL database\nThe main workhorse packages that we will use are the DBI and RSQLite packages.\n\nDBI is an R package that connects R to database management systems (DBMS). DBI separates the connectivity to the DBMS into a “front-end” and a “back-end”. The package defines an interface that is implemented by DBI backends such as RPostgres, RMariaDB, RSQLite, odbc, bigrquery, and more!\nRSQLite is an R package that embeds the SQLite database engine in R, providing a DBI-compliant interface. SQLite is a public-domain, single-user, very light-weight database engine that implements a decent subset of the SQL 92 standard, including the core table creation, updating, insertion, and selection operations, plus transaction management."
  },
  {
    "objectID": "readings/05-database-programming/index.html#example-workflow",
    "href": "readings/05-database-programming/index.html#example-workflow",
    "title": "Relational databases and SQL basics",
    "section": "Example workflow",
    "text": "Example workflow\n\n\n\n\n\n\nExample\n\n\n\nHere’s a short R program that sorts the scientists names in a descending order from from an SQLite database stored in a file called survey.db:\n\nlibrary(RSQLite)\nconnection &lt;- dbConnect(drv = RSQLite::SQLite(), \n                        dbname = here::here(\"readings\",\"05-database-programming\", \"data\", \"survey.db\"))\nresults &lt;- dbGetQuery(connection, \"SELECT * FROM Person ORDER BY id DESC;\")\nprint(results)\n\n        id  personal   family\n1      roe Valentina  Roerich\n2       pb     Frank  Pabodie\n3     lake  Anderson     Lake\n4     dyer   William     Dyer\n5 danforth     Frank Danforth\n\ndbDisconnect(connection)\n\n\n\nLet’s break this down.\nThe program starts by importing the RSQLite library.\nIf we were connecting to MySQL, DB2, or some other database, we would import a different library, but all of them provide the same functions, so that the rest of our program does not have to change (at least, not much) if we switch from one database to another.\nLine 2 establishes a connection to the database.\nSince we’re using SQLite, all we need to specify is the name of the database file. Other systems may require us to provide a username and password as well.\nOn line 3, we retrieve the results from an SQL query.\nIt’s our job to make sure that SQL is properly formatted; if it isn’t, or if something goes wrong when it is being executed, the database will report an error.\nThis result is a data.frame with one row for each entry and one column for each column in the database.\nFinally, the last line closes our connection, since the database can only keep a limited number of these open at one time.\nSince establishing a connection takes time, though, we should not open a connection, do one operation, then close the connection, only to reopen it a few microseconds later to do another operation.\nInstead, it’s normal to create one connection that stays open for the lifetime of the program.\nQueries in real applications will often depend on values provided by users.\nFor example, this function takes a user’s ID as a parameter and returns only the rows with their ID:\n\nlibrary(RSQLite)\nconnection &lt;- dbConnect(drv = SQLite(), \n                        dbname = here::here(\"readings\",\"05-database-programming\", \"data\", \"survey.db\"))\n\ngetName &lt;- function(personID) {\n  query &lt;- paste0(\"SELECT * FROM Survey WHERE person ='\", \n                  personID, \"';\")\n  return(dbGetQuery(connection, query))\n}\n\ngetName(\"dyer\")\n\n  taken person quant reading\n1   619   dyer   rad    9.82\n2   619   dyer   sal    0.13\n3   622   dyer   rad    7.80\n4   622   dyer   sal    0.09\n\ndbDisconnect(connection)\n\nWe use string concatenation on the first line of this function to construct a query containing the user ID we have been given."
  },
  {
    "objectID": "readings/05-database-programming/index.html#database-helper-functions-in-r",
    "href": "readings/05-database-programming/index.html#database-helper-functions-in-r",
    "title": "Relational databases and SQL basics",
    "section": "Database helper functions in R",
    "text": "Database helper functions in R\nR’s database interface packages (like RSQLite) all share a common set of helper functions useful for exploring databases and reading/writing entire tables at once.\nTo view all tables in a database, we can use dbListTables():\n\nconnection &lt;- dbConnect(SQLite(), \n                        here::here(\"readings\", \"05-database-programming\", \"data\", \"survey.db\"))\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\"\n\n\nTo view all column names of a table, use dbListFields():\n\ndbListFields(connection, \"Survey\")\n\n[1] \"taken\"   \"person\"  \"quant\"   \"reading\"\n\n\nTo read an entire table as a dataframe, use dbReadTable():\n\ndbReadTable(connection, \"Person\")\n\n        id  personal   family\n1     dyer   William     Dyer\n2       pb     Frank  Pabodie\n3     lake  Anderson     Lake\n4      roe Valentina  Roerich\n5 danforth     Frank Danforth\n\n\nFinally, to write an entire table to a database, you can use dbWriteTable().\n\n\n\n\n\n\nNote\n\n\n\nWe will always want to use the row.names = FALSE argument or R will write the row names as a separate column.\n\n\n\ndbWriteTable(connection, \"iris\", iris, row.names = FALSE)\nhead(dbReadTable(connection, \"iris\"))\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nIn this example we will write R’s built-in iris dataset as a table in survey.db.\nWhich you can see here:\n\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\" \"iris\"   \n\n\nWe can remove iris as a table with dbRemoveTable() and check it’s been removed with dbListTables().\n\ndbRemoveTable(connection, \"iris\")\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\"\n\n\nAnd as always, remember to close the database connection when done!\n\ndbDisconnect(connection)"
  },
  {
    "objectID": "readings/05-database-programming/index.html#example-album-covers",
    "href": "readings/05-database-programming/index.html#example-album-covers",
    "title": "Relational databases and SQL basics",
    "section": "Example: album covers",
    "text": "Example: album covers\nWe will use the\n\nchinook sqlite database\n\nThe database represents a “digital media store, including tables for artists, albums, media tracks, invoices and customers”.\nFrom the Readme.md file:\n\nSample Data\nMedia related data was created using real data from an iTunes Library. … Customer and employee information was manually created using fictitious names, addresses that can be located on Google maps, and other well formatted data (phone, fax, email, etc.). Sales information is auto generated using random data for a four year period.\n\nThe data are saved in our /data folder:\n\nlibrary(here)\n\nhere() starts at /Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024\n\nlist.files(here(\"readings\", \"05-database-programming\", \"data\"))\n\n[1] \"Chinook.sqlite\" \"survey.db\""
  },
  {
    "objectID": "readings/05-database-programming/index.html#connect-to-the-sqlite-database",
    "href": "readings/05-database-programming/index.html#connect-to-the-sqlite-database",
    "title": "Relational databases and SQL basics",
    "section": "Connect to the SQLite database",
    "text": "Connect to the SQLite database\nLet’s connect to the Chinook.sqlite file\n\nconnection &lt;- dbConnect(SQLite(), \n                        here(\"readings\", \"05-database-programming\", \"data\", \"Chinook.sqlite\"))\n\nSo we have opened up a connection with the SQLite database. Next, we can see what tables are available in the database using the dbListTables() function:\n\ndbListTables(connection)\n\n [1] \"Album\"         \"Artist\"        \"Customer\"      \"Employee\"     \n [5] \"Genre\"         \"Invoice\"       \"InvoiceLine\"   \"MediaType\"    \n [9] \"Playlist\"      \"PlaylistTrack\" \"Track\"        \n\n\nI have shown you how to write SQL queries with dbGetQuery().\nAn alternative approach to interact with SQL databases is to leverage the dplyr framework.\n\n“The dplyr package now has a generalized SQL backend for talking to databases, and the new dbplyr package translates R code into database-specific variants. As of this writing, SQL variants are supported for the following databases: Oracle, Microsoft SQL Server, PostgreSQL, Amazon Redshift, Apache Hive, and Apache Impala. More will follow over time.\n\nSo if we want to query a SQL databse with dplyr, the benefit of using dbplyr is:\n\n“You can write your code in dplyr syntax, and dplyr will translate your code into SQL. There are several benefits to writing queries in dplyr syntax: you can keep the same consistent language both for R objects and database tables, no knowledge of SQL or the specific SQL variant is required, and you can take advantage of the fact that dplyr uses lazy evaluation.\n\nLet’s take a closer look at the conn database that we just connected to:\n\nlibrary(dbplyr)\nsrc_dbi(connection)\n\nsrc:  sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/readings/05-database-programming/data/Chinook.sqlite]\ntbls: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine,\n  MediaType, Playlist, PlaylistTrack, Track\n\n\nYou can think of the multiple tables similar to having multiple worksheets in a spreadsheet.\nLet’s try interacting with one."
  },
  {
    "objectID": "readings/05-database-programming/index.html#using-dplyr",
    "href": "readings/05-database-programming/index.html#using-dplyr",
    "title": "Relational databases and SQL basics",
    "section": "Using dplyr",
    "text": "Using dplyr\nFirst, let’s look at the first ten rows in the Album table using the tbl() function from dplyr:\n\ntbl(connection, \"Album\") %&gt;%\n  head(n=10)\n\n# Source:   SQL [10 x 3]\n# Database: sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/readings/05-database-programming/data/Chinook.sqlite]\n   AlbumId Title                                 ArtistId\n     &lt;int&gt; &lt;chr&gt;                                    &lt;int&gt;\n 1       1 For Those About To Rock We Salute You        1\n 2       2 Balls to the Wall                            2\n 3       3 Restless and Wild                            2\n 4       4 Let There Be Rock                            1\n 5       5 Big Ones                                     3\n 6       6 Jagged Little Pill                           4\n 7       7 Facelift                                     5\n 8       8 Warner 25 Anos                               6\n 9       9 Plays Metallica By Four Cellos               7\n10      10 Audioslave                                   8\n\n\nThe output looks just like a data.frame that we are familiar with. But it’s important to know that it’s not really a data frame. For example, what about if we use the dim() function?\n\ntbl(connection, \"Album\") %&gt;%\n  dim()\n\n[1] NA  3\n\n\nInteresting! We see that the number of rows returned is NA. This is because these functions are different than operating on datasets in memory (e.g. loading data into memory using read_csv()).\nInstead, dplyr communicates differently with a SQLite database.\nLet’s consider our example. If we were to use straight SQL, the following SQL query returns the first 10 rows from the Album table:\n\n\nSQL\n\nSELECT * FROM Album LIMIT 10;\n\n\n\nOutput\n\n1|For Those About To Rock We Salute You|1\n2|Balls to the Wall|2\n3|Restless and Wild|2\n4|Let There Be Rock|1\n5|Big Ones|3\n6|Jagged Little Pill|4\n7|Facelift|5\n8|Warner 25 Anos|6\n9|Plays Metallica By Four Cellos|7\n10|Audioslave|8\n\nIn the background, dplyr does the following:\n\ntranslates your R code into SQL\nsubmits it to the database\ntranslates the database’s response into an R data frame\n\nTo better understand the dplyr code, we can use the show_query() function:\n\nAlbum &lt;- tbl(connection, \"Album\")\nshow_query(head(Album, n = 10))\n\n&lt;SQL&gt;\nSELECT `Album`.*\nFROM `Album`\nLIMIT 10\n\n\nThis is nice because instead of having to write the SQL query our self, we can just use the dplyr and R syntax that we are used to.\nHowever, the downside is that dplyr never gets to see the full Album table. It only sends our query to the database, waits for a response and returns the query.\nHowever, in this way we can interact with large datasets!\nMany of the usual dplyr functions are available too:\n\nselect()\nfilter()\nsummarize()\n\nand many join functions.\nOk let’s try some of the functions out. First, let’s count how many albums each artist has made.\n\ntbl(connection, \"Album\") %&gt;%\n  group_by(ArtistId) %&gt;% \n  summarize(n = count(ArtistId)) %&gt;% \n  head(n=10)\n\n# Source:   SQL [10 x 2]\n# Database: sqlite 3.46.0 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/readings/05-database-programming/data/Chinook.sqlite]\n   ArtistId     n\n      &lt;int&gt; &lt;int&gt;\n 1        1     2\n 2        2     2\n 3        3     1\n 4        4     1\n 5        5     1\n 6        6     2\n 7        7     1\n 8        8     3\n 9        9     1\n10       10     1"
  },
  {
    "objectID": "readings/05-database-programming/index.html#data-viz",
    "href": "readings/05-database-programming/index.html#data-viz",
    "title": "Relational databases and SQL basics",
    "section": "data viz",
    "text": "data viz\nNext, let’s plot it.\n\ntbl(connection, \"Album\") %&gt;%\n  group_by(ArtistId) %&gt;% \n  summarize(n = count(ArtistId)) %&gt;% \n  arrange(desc(n)) %&gt;% \n  ggplot(aes(x = ArtistId, y = n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nLet’s also extract the first letter from each album and plot the frequency of each letter.\n\ntbl(connection, \"Album\") %&gt;%\n  mutate(first_letter = str_sub(Title, end = 1)) %&gt;% \n  ggplot(aes(first_letter)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nIf you decide to make an album, you should try picking a less frequently used letter like E, J, K, Q, U, W, or Z!"
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html",
    "href": "readings/08-oop-paradigm/index.html",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Object oriented programming is one of the most successful and widespread philosophies of programming and is a cornerstone of many programming languages including Java, Ruby, Python, and C++.\nAt it’s core, object oriented programming (OOP) is a paradigm that is made up of classes and objects.\nAt a high-level, we use OOP to structure software programs into small, reusable pieces of code blueprints (i.e. classes), which are used to create instances of concrete objects.\nThe blueprint (or class) typically represents broad categories, e.g. bus or car that share attributes (e.g. color) (or fields).\n\nThe classes specify what attributes you want, but not the actual values for a particular object.\nHowever, when you create instances with objects, you are specifying the attributes (e.g. a blue car, a red car, etc).\n\nIn addition, classes can also contain functions, called methods available only to objects of that type.\n\nThese functions are defined within the class and perform some action helpful to that specific type of object.\nFor example, our car class may have a method repaint that changes the color attribute of our car.\nThis function is only helpful to objects of type car, so we declare it within the car class thus making it a method.\n\n\n\nBase R has three object oriented systems, because the roots of R date back to 1976, when the idea of object orientated programming was barely four years old.\nNew object oriented paradigms were added to R as they were invented, and they exist in their own R packages.\n\n\n\n\n\n\nWhy is OOP hard in R?\n\n\n\nOOP is a little more challenging in R than in other languages because:\n\nThere are multiple OOP systems to choose from. Here, I will focus on the following three: S3, R6, and S4.\n\n\nS3 and S4 are provided by base R (two older OOP languages).\nR6 is provided by the R6 package, and is similar to the\nReference Classes, or RC for short, from base R. Programmers who are already familiar with object oriented programming will feel at home using RC.\n\n\nThere is disagreement about the relative importance of the OOP systems. Hadley Wickham thinks S3 is most important, followed by R6, then S4. Others believe that S4 is most important (e.g. Bioconductor community), followed by RC, and that S3 should be avoided. This means that different R communities use different systems.\nS3 and S4 use generic function OOP which is rather different from the encapsulated OOP used by most languages popular today (the exception is Julia which also uses generic function OOP) (more on these later). Basically, while the underlying ideas of OOP are the same across languages, their expressions are rather different. This means that you can not immediately transfer your existing OOP skills to R.\n\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nGenerally in R, functional programming is much more important than object-oriented programming, because you typically solve complex problems by decomposing them into simple functions, not simple objects.\n\n\nThis lesson focuses on the mechanics of OOP, not its effective use, and it may be challenging to fully understand if you have not done object-oriented programming before.\n\n\n\nBefore we go on I want to introduce the sloop package:\n\nlibrary(sloop)\n\nThe sloop package (think “sail the seas of OOP”) provides a number of helpers that fill in missing pieces in base R. The first of these is sloop::otype(). It makes it easy to figure out the OOP system used by a wild-caught object:\n\notype(1:10)\n\n[1] \"base\"\n\n\n\nlibrary(palmerpenguins)\notype(penguins)\n\n[1] \"S3\"\n\n\n\nmle_obj &lt;- stats4::mle(function(x = 1) (x - 2) ^ 2)\notype(mle_obj)\n\n[1] \"S4\"\n\n\n\n\n\nDifferent people use OOP terms in different ways, so this section provides a quick overview of important vocabulary. The explanations are necessarily compressed, but we will come back to these ideas multiple times.\nThe main reason to use OOP is polymorphism (literally: many shapes).\n\nPolymorphism means that a developer can consider a function’s interface separately from its implementation, making it possible to use the same function form for different types of input.\nThis is closely related to the idea of encapsulation: the user doesn’t need to worry about details of an object because they are encapsulated behind a standard interface.\n\nTo be concrete, polymorphism is what allows summary() to produce different outputs for numeric and factor variables:\n\nsummary(penguins$bill_length_mm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  32.10   39.23   44.45   43.92   48.50   59.60       2 \n\nsummary(penguins$species)\n\n   Adelie Chinstrap    Gentoo \n      152        68       124 \n\n\nYou could imagine summary() containing a series of if-else statements, but that would mean only the original author could add new implementations. An OOP system makes it possible for any developer to extend the interface with implementations for new types of input.\nTo be more precise, OO systems call the type of an object its class, and an implementation for a specific class is called a method. Roughly speaking,\n\na class defines what an object is and\nmethods describe what that object can do\n\nThe class defines the fields (or attributes), the data possessed by every instance of that class. Classes are organised in a hierarchy so that if a method does not exist for one class, its parent’s method is used, and the child is said to inherit behavior.\n\n\n\n\n\n\nExample\n\n\n\n\nAn ordered factor inherits from a regular factor.\nA generalized linear model inherits from a linear model.\n\n\n\nThe process of finding the correct method given a class is called method dispatch.\n\n\n\n\n\n\nTwo paradigms of OOP\n\n\n\nThe two main paradigms of OOP differ in how methods and classes are related. We will call these paradigms encapsulated and functional:\n\nIn encapsulated OOP, methods belong to objects or classes, and method calls typically look like object.method(arg1, arg2). This is called encapsulated because the object encapsulates both data (with fields) and behavior (with methods), and is the paradigm found in most popular languages.\nIn functional OOP, methods belong to generic functions, and method calls look like ordinary function calls: generic(object, arg2, arg3). This is called functional because from the outside it looks like a regular function call, and internally the components are also functions.\n\n\n\nWith this terminology in hand, we can now talk precisely about the different OO systems available in R.\n\n\n\nOk let’s talk more about some OOP principles. The first is is the idea of a class and an object.\nThe world is made up of physical objects - the chair you are sitting in, the clock next to your bed, the bus you ride every day, etc. Just like the world is full of physical objects, your programs can be made of objects as well.\nA class is a blueprint for an object: it describes the parts of an object, how to make an object, and what the object is able to do.\n\n\n\n\n\n\nExample\n\n\n\nIf you were to think about a class for a bus (as in the public buses that roam the roads), this class would describe attributes for the bus like\n\nthe number of seats on the bus\nthe number of windows\nthe color of the bus\nthe top speed of the bus\nthe maximum distance the bus can drive on one tank of gas\n\n\n\nA method is a function that is associated with a class to perform an action.\n\n\n\n\n\n\nExample\n\n\n\nBuses, in general, can perform the same actions, and these actions are also described in the class:\n\na bus can open and close its doors\nthe bus can steer\nthe accelerator or the brake can be used to slow down or speed up the bus\n\n\n\nA constructor is a method to specify attributes of the class to create a object with the specific attributes that we specified.\n\n\n\n\n\n\nExample\n\n\n\nWe will use the bus class in order to create individual bus objects.\nTo do this, we will create a constructor method for the bus class to return an individual bus object with the attributes that we specified.\n\n\nIf we want to make a new class that has all the same attributes and methods as an existing class, but also has additional attributes, we do not want to rewrite the entire class, but rather we want to define a new class that inherits from the original class.\n\n\n\n\n\n\nExample\n\n\n\nImagine that after making the bus class you might want to make a special kind of class for a party bus.\nThe party_bus class has all of the same attributes and methods as our bus class, but they also has additional attributes and methods like\n\nthe number of refrigerators\nwindow blinds that can be opened and closed\nsmoke machines that can be turned on and off\n\n\n\nIn this framework of inheritance, we talk about the bus class as the super-class of the party bus, and the party bus is the sub-class of the bus.\nWhat this relationship means is that the party bus has all of the same attributes and methods as the bus class plus additional attributes and methods.\n\n\n\nBase R provides three OOP systems: S3, S4, and reference classes (RC):\n\nS3 is R’s first OOP system, and is described in Statistical Models in S. S3 is an informal implementation of functional OOP and relies on common conventions rather than ironclad guarantees. This makes it easy to get started with, providing a low cost way of solving many simple problems.\nS4 is a formal and rigorous rewrite of S3, and was introduced in Programming with Data. It requires more upfront work than S3, but in return provides more guarantees and greater encapsulation. S4 is implemented in the base methods package, which is always installed with R.\n\n\n\n\n\n\n\nPro-tip\n\n\n\nYou might wonder if S1 and S2 exist. They don’t: S3 and S4 were named according to the versions of S that they accompanied. The first two versions of S didn’t have any OOP framework.\n\n\n\nRC implements encapsulated OO. RC objects are a special type of S4 objects that are also mutable (i.e., instead of using R’s usual copy-on-modify semantics, they can be modified in place). This makes them harder to reason about, but allows them to solve problems that are difficult to solve in the functional OOP style of S3 and S4."
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#oop-in-r",
    "href": "readings/08-oop-paradigm/index.html#oop-in-r",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Base R has three object oriented systems, because the roots of R date back to 1976, when the idea of object orientated programming was barely four years old.\nNew object oriented paradigms were added to R as they were invented, and they exist in their own R packages.\n\n\n\n\n\n\nWhy is OOP hard in R?\n\n\n\nOOP is a little more challenging in R than in other languages because:\n\nThere are multiple OOP systems to choose from. Here, I will focus on the following three: S3, R6, and S4.\n\n\nS3 and S4 are provided by base R (two older OOP languages).\nR6 is provided by the R6 package, and is similar to the\nReference Classes, or RC for short, from base R. Programmers who are already familiar with object oriented programming will feel at home using RC.\n\n\nThere is disagreement about the relative importance of the OOP systems. Hadley Wickham thinks S3 is most important, followed by R6, then S4. Others believe that S4 is most important (e.g. Bioconductor community), followed by RC, and that S3 should be avoided. This means that different R communities use different systems.\nS3 and S4 use generic function OOP which is rather different from the encapsulated OOP used by most languages popular today (the exception is Julia which also uses generic function OOP) (more on these later). Basically, while the underlying ideas of OOP are the same across languages, their expressions are rather different. This means that you can not immediately transfer your existing OOP skills to R.\n\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nGenerally in R, functional programming is much more important than object-oriented programming, because you typically solve complex problems by decomposing them into simple functions, not simple objects.\n\n\nThis lesson focuses on the mechanics of OOP, not its effective use, and it may be challenging to fully understand if you have not done object-oriented programming before."
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#sloop",
    "href": "readings/08-oop-paradigm/index.html#sloop",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Before we go on I want to introduce the sloop package:\n\nlibrary(sloop)\n\nThe sloop package (think “sail the seas of OOP”) provides a number of helpers that fill in missing pieces in base R. The first of these is sloop::otype(). It makes it easy to figure out the OOP system used by a wild-caught object:\n\notype(1:10)\n\n[1] \"base\"\n\n\n\nlibrary(palmerpenguins)\notype(penguins)\n\n[1] \"S3\"\n\n\n\nmle_obj &lt;- stats4::mle(function(x = 1) (x - 2) ^ 2)\notype(mle_obj)\n\n[1] \"S4\""
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#oop-systems",
    "href": "readings/08-oop-paradigm/index.html#oop-systems",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Different people use OOP terms in different ways, so this section provides a quick overview of important vocabulary. The explanations are necessarily compressed, but we will come back to these ideas multiple times.\nThe main reason to use OOP is polymorphism (literally: many shapes).\n\nPolymorphism means that a developer can consider a function’s interface separately from its implementation, making it possible to use the same function form for different types of input.\nThis is closely related to the idea of encapsulation: the user doesn’t need to worry about details of an object because they are encapsulated behind a standard interface.\n\nTo be concrete, polymorphism is what allows summary() to produce different outputs for numeric and factor variables:\n\nsummary(penguins$bill_length_mm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  32.10   39.23   44.45   43.92   48.50   59.60       2 \n\nsummary(penguins$species)\n\n   Adelie Chinstrap    Gentoo \n      152        68       124 \n\n\nYou could imagine summary() containing a series of if-else statements, but that would mean only the original author could add new implementations. An OOP system makes it possible for any developer to extend the interface with implementations for new types of input.\nTo be more precise, OO systems call the type of an object its class, and an implementation for a specific class is called a method. Roughly speaking,\n\na class defines what an object is and\nmethods describe what that object can do\n\nThe class defines the fields (or attributes), the data possessed by every instance of that class. Classes are organised in a hierarchy so that if a method does not exist for one class, its parent’s method is used, and the child is said to inherit behavior.\n\n\n\n\n\n\nExample\n\n\n\n\nAn ordered factor inherits from a regular factor.\nA generalized linear model inherits from a linear model.\n\n\n\nThe process of finding the correct method given a class is called method dispatch.\n\n\n\n\n\n\nTwo paradigms of OOP\n\n\n\nThe two main paradigms of OOP differ in how methods and classes are related. We will call these paradigms encapsulated and functional:\n\nIn encapsulated OOP, methods belong to objects or classes, and method calls typically look like object.method(arg1, arg2). This is called encapsulated because the object encapsulates both data (with fields) and behavior (with methods), and is the paradigm found in most popular languages.\nIn functional OOP, methods belong to generic functions, and method calls look like ordinary function calls: generic(object, arg2, arg3). This is called functional because from the outside it looks like a regular function call, and internally the components are also functions.\n\n\n\nWith this terminology in hand, we can now talk precisely about the different OO systems available in R."
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#oop-principles",
    "href": "readings/08-oop-paradigm/index.html#oop-principles",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Ok let’s talk more about some OOP principles. The first is is the idea of a class and an object.\nThe world is made up of physical objects - the chair you are sitting in, the clock next to your bed, the bus you ride every day, etc. Just like the world is full of physical objects, your programs can be made of objects as well.\nA class is a blueprint for an object: it describes the parts of an object, how to make an object, and what the object is able to do.\n\n\n\n\n\n\nExample\n\n\n\nIf you were to think about a class for a bus (as in the public buses that roam the roads), this class would describe attributes for the bus like\n\nthe number of seats on the bus\nthe number of windows\nthe color of the bus\nthe top speed of the bus\nthe maximum distance the bus can drive on one tank of gas\n\n\n\nA method is a function that is associated with a class to perform an action.\n\n\n\n\n\n\nExample\n\n\n\nBuses, in general, can perform the same actions, and these actions are also described in the class:\n\na bus can open and close its doors\nthe bus can steer\nthe accelerator or the brake can be used to slow down or speed up the bus\n\n\n\nA constructor is a method to specify attributes of the class to create a object with the specific attributes that we specified.\n\n\n\n\n\n\nExample\n\n\n\nWe will use the bus class in order to create individual bus objects.\nTo do this, we will create a constructor method for the bus class to return an individual bus object with the attributes that we specified.\n\n\nIf we want to make a new class that has all the same attributes and methods as an existing class, but also has additional attributes, we do not want to rewrite the entire class, but rather we want to define a new class that inherits from the original class.\n\n\n\n\n\n\nExample\n\n\n\nImagine that after making the bus class you might want to make a special kind of class for a party bus.\nThe party_bus class has all of the same attributes and methods as our bus class, but they also has additional attributes and methods like\n\nthe number of refrigerators\nwindow blinds that can be opened and closed\nsmoke machines that can be turned on and off\n\n\n\nIn this framework of inheritance, we talk about the bus class as the super-class of the party bus, and the party bus is the sub-class of the bus.\nWhat this relationship means is that the party bus has all of the same attributes and methods as the bus class plus additional attributes and methods."
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#oop-in-r-v2",
    "href": "readings/08-oop-paradigm/index.html#oop-in-r-v2",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Base R provides three OOP systems: S3, S4, and reference classes (RC):\n\nS3 is R’s first OOP system, and is described in Statistical Models in S. S3 is an informal implementation of functional OOP and relies on common conventions rather than ironclad guarantees. This makes it easy to get started with, providing a low cost way of solving many simple problems.\nS4 is a formal and rigorous rewrite of S3, and was introduced in Programming with Data. It requires more upfront work than S3, but in return provides more guarantees and greater encapsulation. S4 is implemented in the base methods package, which is always installed with R.\n\n\n\n\n\n\n\nPro-tip\n\n\n\nYou might wonder if S1 and S2 exist. They don’t: S3 and S4 were named according to the versions of S that they accompanied. The first two versions of S didn’t have any OOP framework.\n\n\n\nRC implements encapsulated OO. RC objects are a special type of S4 objects that are also mutable (i.e., instead of using R’s usual copy-on-modify semantics, they can be modified in place). This makes them harder to reason about, but allows them to solve problems that are difficult to solve in the functional OOP style of S3 and S4."
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#base-types",
    "href": "readings/08-oop-paradigm/index.html#base-types",
    "title": "Object Oriented Programming",
    "section": "Base types",
    "text": "Base types\nWhile only OO objects have a class attribute, every object has a base type:\n\ntypeof(1:10)\n\n[1] \"integer\"\n\ntypeof(mtcars)\n\n[1] \"list\"\n\n\nBase types do not form an OOP system because functions that behave differently for different base types are primarily written in C code that uses switch statements.\nThis means that only the R-core team can create new types, and creating a new type is a lot of work because every switch statement needs to be modified to handle a new case. As a consequence, new base types are rarely added.\n\n\n\n\n\n\nPro-tip\n\n\n\nIn total, there are 25 different base types.\n\n\nHere are some more base types we have already learned about:\n\ntypeof(NULL)\n\n[1] \"NULL\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(1i)\n\n[1] \"complex\""
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#oo-objects",
    "href": "readings/08-oop-paradigm/index.html#oo-objects",
    "title": "Object Oriented Programming",
    "section": "OO objects",
    "text": "OO objects\nAt a high-level, an S3 object is a base type with at least a class attribute.\n\n\n\n\n\n\nExample\n\n\n\nTake the factor. Its base type is the integer vector, it has a class attribute of “factor”, and a levels attribute that stores the possible levels:\n\nf &lt;- factor(c(\"a\", \"b\", \"c\"))\ntypeof(f)\n\n[1] \"integer\"\n\nattributes(f)\n\n$levels\n[1] \"a\" \"b\" \"c\"\n\n$class\n[1] \"factor\"\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s consider the penguins data frame.\n\nWhat is it’s base type?\nWhat is it’s class attribute?\nWhat other attributes does it have?\n\n\n## try it here\n\n\n\nCool. Let’s try creating a new class in the S3 system.\nIn the S3 system you can arbitrarily assign a class to any object. Class assignments can be made using the structure() function, or you can assign the class using class() and &lt;-:\n\nspecial_num_1 &lt;- structure(1, class = \"special_number\")\nspecial_num_1\n\n[1] 1\nattr(,\"class\")\n[1] \"special_number\"\n\nclass(special_num_1)\n\n[1] \"special_number\"\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s assign the number 2 to special_num_2 and look at the class of special_num_2.\n\n### try it here\n\nWhat’s happened here?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nNext, let’s assign “special_number” to the class of special_num_2.\n\nclass(special_num_2) &lt;- \"special_number\"\nclass(special_num_2)\nspecial_num_2\n\nWhat’s happening here?\n\n\nAs crazy as this is, it is completely legal R code, but if you want to have a better behaved S3 class you should create a constructor which returns an S3 object.\n\nCreate a constructor called shape_s3()\n\n\n\n\n\n\nExample\n\n\n\nConsider the shape_s3() function below, which is a constructor that returns a shape_S3 object:\n\nshape_s3 &lt;- function(side_lengths){\n  structure(list(side_lengths = side_lengths), class = \"shape_S3\")\n}\n\nsquare_4 &lt;- shape_s3(c(4, 4, 4, 4))\nclass(square_4)\n\n[1] \"shape_S3\"\n\ntriangle_3 &lt;- shape_s3(c(3, 3, 3))\nclass(triangle_3)\n\n[1] \"shape_S3\"\n\n\nWe have now made two shape_S3 objects: square_4 and triangle_3, which are both instantiations of the shape_S3 class.\n\n\nImagine that you wanted to create a method (or function) that would return TRUE if a shape_S3 object was a square, FALSE if a shape_S3 object was not a square, and NA if the object provided as an argument to the method was not a shape_S3 object.\nThis can be achieved using R’s generic methods system. A generic method can return different values based depending on the class of its input.\n\n\n\n\n\n\nExample\n\n\n\nFor example, mean() is a generic method that can find the average of a vector of number or it can find the “average day” from a vector of dates.\n\nmean(c(2, 3, 7))\n\n[1] 4\n\nmean(c(as.Date(\"2016-09-01\"), as.Date(\"2016-09-03\")))\n\n[1] \"2016-09-02\"\n\n\n\n\n\n\nCreate a generic method called is_square()\nNow, let’s create a generic method for identifying shape_S3 objects that are squares.\n\n\n\n\n\n\nStep 1: use UseMethod()\n\n\n\nFirst, the creation of every generic method uses the UseMethod() function in the following way with only slight variations:\n[name of method] &lt;- function(x) UseMethod(\"[name of method]\")\nLet’s call this method is_square:\n\nis_square &lt;- function(x) UseMethod(\"is_square\")\n\n\n\n\n\n\n\n\n\nStep 2: Define what’s inside the method\n\n\n\nNext, we add the actual definition for the function to detect whether or not a shape is a square by specifying is_square.shape_S3.\nBy putting a dot (.) and then the name of the class after is_square, we can create a method that associates is_square with the shape_S3 class:\n\nis_square.shape_S3 &lt;- function(x){\n  length(x$side_lengths) == 4 &&\n    x$side_lengths[1] == x$side_lengths[2] &&\n    x$side_lengths[2] == x$side_lengths[3] &&\n    x$side_lengths[3] == x$side_lengths[4]\n}\n\nis_square(square_4)\n\n[1] TRUE\n\nis_square(triangle_3)\n\n[1] FALSE\n\n\n\n\nSeems to be working well!\nWe also want is_square() to return NA when its argument is not a shape_S3.\nWe can specify is_square.default as a last resort if there is not method associated with the object passed to is_square().\n\nis_square.default &lt;- function(x){\n  NA\n}\n\nis_square(\"square\")\n\n[1] NA\n\nis_square(c(1, 1, 1, 1))\n\n[1] NA\n\n\nLet’s try printing square_4:\n\nprint(square_4)\n\n$side_lengths\n[1] 4 4 4 4\n\nattr(,\"class\")\n[1] \"shape_S3\"\n\n\nDoesn’t that look ugly?\n\n\nCreate a generic method print() for shape_S3 class\nLucky for us print() is a generic method, so we can specify a print method for the shape_S3 class:\n\nprint.shape_S3 &lt;- function(x){\n  if(length(x$side_lengths) == 3){\n    paste(\"A triangle with side lengths of\", x$side_lengths[1], \n          x$side_lengths[2], \"and\", x$side_lengths[3])\n  } else if(length(x$side_lengths) == 4) {\n    if(is_square(x)){\n      paste(\"A square with four sides of length\", x$side_lengths[1])\n    } else {\n      paste(\"A quadrilateral with side lengths of\", x$side_lengths[1],\n            x$side_lengths[2], x$side_lengths[3], \"and\", x$side_lengths[4])\n    }\n  } else {\n    paste(\"A shape with\", length(x$side_lengths), \"sides.\")\n  }\n}\n\nprint(square_4)\n\n[1] \"A square with four sides of length 4\"\n\nprint(triangle_3)\n\n[1] \"A triangle with side lengths of 3 3 and 3\"\n\nprint(shape_s3(c(10, 10, 20, 20, 15)))\n\n[1] \"A shape with 5 sides.\"\n\nprint(shape_s3(c(2, 3, 4, 5)))\n\n[1] \"A quadrilateral with side lengths of 2 3 4 and 5\"\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nSince printing an object to the console is one of the most common things to do in R, nearly every class has an associated print method!\nTo see all of the methods associated with a generic like print() use the methods() function:\n\nlength(methods(print))\n\n[1] 262\n\nhead(methods(print), 10)\n\n [1] \"print.acf\"               \"print.activeConcordance\"\n [3] \"print.AES\"               \"print.anova\"            \n [5] \"print.aov\"               \"print.aovlist\"          \n [7] \"print.ar\"                \"print.Arima\"            \n [9] \"print.arima0\"            \"print.AsIs\"             \n\n\n\n\n\n\nInheritance\nOne last note on S3 with regard to inheritance.\nIn the previous section we discussed how a sub-class can inherit attributes and methods from a super-class.\nSince you can assign any class to an object in S3, you can specify a super class for an object the same way you would specify a class for an object:\n\nclass(square_4)\n\n[1] \"shape_S3\"\n\nclass(square_4) &lt;- c(\"shape_S3\", \"square\")\nclass(square_4)\n\n[1] \"shape_S3\" \"square\"  \n\n\nTo check if an object is a sub-class of a specified class you can use the inherits() function:\n\ninherits(square_4, \"square\")\n\n[1] TRUE"
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#example-s3-classmethods-for-polygons",
    "href": "readings/08-oop-paradigm/index.html#example-s3-classmethods-for-polygons",
    "title": "Object Oriented Programming",
    "section": "Example: S3 Class/Methods for Polygons",
    "text": "Example: S3 Class/Methods for Polygons\nThe S3 system doesn’t have a formal way to define a class but typically, we use a list to define the class and elements of the list serve as data elements.\nHere is our definition of a polygon represented using Cartesian coordinates.\n\nThe class contains an element called xcoord and ycoord for the x- and y-coordinates, respectively.\nThe make_poly() function is the “constructor” function for polygon objects. It takes as arguments a numeric vector of x-coordinates and a corresponding numeric vector of y-coordinates.\n\n\n## Constructor function for polygon objects\n## x a numeric vector of x coordinates\n## y a numeric vector of y coordinates\nmake_poly &lt;- function(x, y) {\n        if(length(x) != length(y))\n                stop(\"'x' and 'y' should be the same length\")\n        \n        ## Create the \"polygon\" object \n        object &lt;- list(xcoord = x, ycoord = y)\n        \n        ## Set the class name\n        class(object) &lt;- \"polygon\"\n        object\n}\n\nNow that we have a class definition, we can develop some methods for operating on objects from that class.\nThe first method that we will define is the print() method. The print() method should just show some simple information about the object and should not be too verbose—just enough information that the user knows what the object is.\nHere the print() method just shows the user how many vertices the polygon has.\nIt is a convention for print() methods to return the object x invisibly using the invisible() function.\n\n## Print method for polygon objects\n## x an object of class \"polygon\"\n\nprint.polygon &lt;- function(x, ...) {\n        cat(\"a polygon with\", length(x$xcoord), \n            \"vertices\\n\")\n        invisible(x)\n}\n\n\n\n\n\n\n\nPro-tip\n\n\n\nThe invisible() function is useful when it is desired to have functions return values which can be assigned, but which do not print when they are not assigned.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThese functions both return their argument\n\nf1 &lt;- function(x) x\nf2 &lt;- function(x) invisible(x)\n\nf1(1)  # prints\n\n[1] 1\n\nf2(1)  # does not print\n\nHowever, when you assign the f2() function to an object, it does return the value\n\nz &lt;- f2(1)\nz\n\n[1] 1\n\n\n\n\nNext is the summary() method.\nThe summary() method typically shows a bit more information and may even do some calculations, but does not print something. The general strategy of summary() methods is\n\nThe summary() method returns an object of class \"summary_'class name'\"\nThere is a separate print() method for \"summary_'class name'\" objects.\n\nFor example, here is a summary() method for polygon objects that computes the ranges of the x- and y-coordinates.\n\n## object an object of class \"polygon\"\n\nsummary.polygon &lt;- function(object, ...) {\n        object &lt;- list(rng.x = range(object$xcoord),\n                       rng.y = range(object$ycoord))\n        class(object) &lt;- \"summary_polygon\"\n        object\n}\n\n\n\n\n\n\n\nNote\n\n\n\nThe summary method simply returns an object of class summary_polygon.\n\n\nNow the corresponding print() method for summary.polygon objects:\n\n## Note: x an object of class \"summary_polygon\"\nprint.summary_polygon &lt;- function(x, ...) {\n        cat(\"x:\", x$rng.x[1], \"--&gt;\", x$rng.x[2], \"\\n\")\n        cat(\"y:\", x$rng.y[1], \"--&gt;\", x$rng.y[2], \"\\n\")\n        invisible(x)\n}\n\nNow we can make use of our new polygon class and methods (summary() and print()).\n\n## Construct a new \"polygon\" object\nx &lt;- make_poly(1:4, c(1, 5, 2, 1))\nattributes(x)\n\n$names\n[1] \"xcoord\" \"ycoord\"\n\n$class\n[1] \"polygon\"\n\n\nWe can use the print() to see what the object is.\n\nprint(x)\n\na polygon with 4 vertices\n\n\nAnd we can use the summary() method to get a bit more information about the object.\n\nout &lt;- summary(x)\nclass(out)\n\n[1] \"summary_polygon\"\n\nprint(out)\n\nx: 1 --&gt; 4 \ny: 1 --&gt; 5 \n\n\nBecause of auto-printing we can just call the summary() method and let the results auto-print.\n\nsummary(x)\n\nx: 1 --&gt; 4 \ny: 1 --&gt; 5 \n\n\n\n\n\n\n\n\nWhat next?\n\n\n\nFrom here, we could build other methods for interacting with our polygon object.\nFor example, it may make sense to define a plot() method or maybe methods for intersecting two polygons together."
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#constructors-in-s4",
    "href": "readings/08-oop-paradigm/index.html#constructors-in-s4",
    "title": "Object Oriented Programming",
    "section": "Constructors in S4",
    "text": "Constructors in S4\n\nTo create a new class in S4 you need to use the setClass() function.\nYou need to specify two (or three arguments) for this function:\n\nClass which is the name of the class as a string\nslots, which is a named list of attributes for the class with the class of those attributes specified\n(optionally) contains, which includes the super-class of they class you are specifying (if there is a super-class)\n\n\nTake look at the class definition for a bus_S4 and a party_bus_S4 below:\n\nsetClass(Class = \"bus_S4\",\n         slots = list(n_seats = \"numeric\", \n                      top_speed = \"numeric\",\n                      current_speed = \"numeric\",\n                      brand = \"character\"))\nsetClass(Class = \"party_bus_S4\",\n         slots = list(n_subwoofers = \"numeric\",\n                      smoke_machine_on = \"logical\"),\n         contains = \"bus_S4\")\n\nNow that we have created the bus_S4 and the party_bus_S4 classes we can create bus objects using the new() function. The new() function’s arguments are the name of the class and values for each “slot” in our S4 object.\n\nmy_bus &lt;- new(\"bus_S4\", n_seats = 20, top_speed = 80, \n              current_speed = 0, brand = \"Volvo\")\nmy_bus\n\nAn object of class \"bus_S4\"\nSlot \"n_seats\":\n[1] 20\n\nSlot \"top_speed\":\n[1] 80\n\nSlot \"current_speed\":\n[1] 0\n\nSlot \"brand\":\n[1] \"Volvo\"\n\nmy_party_bus &lt;- new(\"party_bus_S4\", n_seats = 10, top_speed = 100,\n                    current_speed = 0, brand = \"Mercedes-Benz\", \n                    n_subwoofers = 2, smoke_machine_on = FALSE)\nmy_party_bus\n\nAn object of class \"party_bus_S4\"\nSlot \"n_subwoofers\":\n[1] 2\n\nSlot \"smoke_machine_on\":\n[1] FALSE\n\nSlot \"n_seats\":\n[1] 10\n\nSlot \"top_speed\":\n[1] 100\n\nSlot \"current_speed\":\n[1] 0\n\nSlot \"brand\":\n[1] \"Mercedes-Benz\"\n\n\nYou can use the @ operator to access the slots of an S4 object:\n\nmy_bus@n_seats\n\n[1] 20\n\nmy_party_bus@top_speed\n\n[1] 100\n\n\nThis is essentially the same as using the $ operator with a list or an environment."
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#methods-in-s4",
    "href": "readings/08-oop-paradigm/index.html#methods-in-s4",
    "title": "Object Oriented Programming",
    "section": "Methods in S4",
    "text": "Methods in S4\nS4 classes use a generic method system that is similar to S3 classes. In order to implement a new generic method you need to use the setGeneric() function and the standardGeneric() function in the following way:\nsetGeneric(\"new_generic\", function(x){\n  standardGeneric(\"new_generic\")\n})\nLet’s create a generic function called is_bus_moving() to see if a bus_S4 object is in motion:\n\nsetGeneric(\"is_bus_moving\", function(x){\n  standardGeneric(\"is_bus_moving\")\n})\n\n[1] \"is_bus_moving\"\n\n\nNow, we need to actually define the function, which we can to with setMethod().\nThe setMethod() functions takes as arguments\n\nthe name of the method as a string (or f)\nthe method signature (signature), which specifies the class of each argument for the method\nthe function definition of the method\n\n\nsetMethod(f = \"is_bus_moving\",\n          signature = c(x = \"bus_S4\"),\n          definition = function(x){\n                          x@current_speed &gt; 0\n                      }\n          )\n\nis_bus_moving(my_bus)\n\n[1] FALSE\n\nmy_bus@current_speed &lt;- 1\nis_bus_moving(my_bus)\n\n[1] TRUE\n\n\nIn addition to creating your own generic methods, you can also create a method for your new class from an existing generic.\nFirst, use the setGeneric() function with the name of the existing method you want to use with your class, and then use the setMethod() function like in the previous example. Let’s make a print() method for the bus_S4 class:\n\nsetGeneric(\"print\")\n\n[1] \"print\"\n\nsetMethod(f = \"print\",\n          signature = c(x = \"bus_S4\"),\n          definition = function(x){\n            paste(\"This\", x@brand, \"bus is traveling at a speed of\", x@current_speed)\n          })\n\nprint(my_bus)\n\n[1] \"This Volvo bus is traveling at a speed of 1\"\n\nprint(my_party_bus)\n\n[1] \"This Mercedes-Benz bus is traveling at a speed of 0\""
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#background",
    "href": "readings/08-oop-paradigm/index.html#background",
    "title": "Object Oriented Programming",
    "section": "Background",
    "text": "Background\nContinuous glucose monitoring (CGM) is novel sensor modality which estimates blood glucose quasi-continuously over 2 weeks in free-living conditions. This facilitates real-time management and comprehensive characterization of glucose for persons with diabetes.\n\n\n\nCGM Device (Abbott Libre Pro)\n\n\n\n\n\nExample CGM Time-Series"
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#oop-for-cgm-data",
    "href": "readings/08-oop-paradigm/index.html#oop-for-cgm-data",
    "title": "Object Oriented Programming",
    "section": "OOP For CGM Data",
    "text": "OOP For CGM Data\nCGM is often collected with other biomarkers, demographic information, and follow-up indicators when used in epidemiological studies. OOP makes it possible to store these different data modalities together in an Object for each person and to standardize operations upon a person’s data.\n\nsimulated_CGM &lt;- as.numeric(arima.sim(model = list(ar = 0.8, ma = 0.5), n = 1440) + 80)\nsimulated_TS &lt;- seq(from = Sys.time(), length.out = 1440, by = 15*60)\ndemo &lt;- list(Age = 55, Gender = \"F\")\nbiomk &lt;- list(BMI = 25, HbA1c = 8.5)"
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#s3-constructor-for-cgm-object",
    "href": "readings/08-oop-paradigm/index.html#s3-constructor-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S3 Constructor for CGM Object",
    "text": "S3 Constructor for CGM Object\n\ncgm_s3 &lt;- function(CGM_data, CGM_datetimes, demographics, biomarkers){\n  structure(list(Data = CGM_data, Times = CGM_datetimes,\n                 Age = demographics$Age, Gender = demographics$Gender, \n                 BMI = biomarkers$BMI, HbA1c = biomarkers$BMI), class = \"cgm_S3\")\n}\n\ncgm_profile &lt;- cgm_s3(simulated_CGM, simulated_TS, demo, biomk)\nclass(cgm_profile)\n\n[1] \"cgm_S3\""
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#s3-methods-for-cgm-object",
    "href": "readings/08-oop-paradigm/index.html#s3-methods-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S3 Methods for CGM Object",
    "text": "S3 Methods for CGM Object\nWe may want to overwrite the generic “print” and “summary” methods, outputting a plot of the CGM data in the former case or returning a subset of pertinent information in the latter.\n\nprint.cgm_S3 &lt;- function(x, ...){\n  plot(x = x$Times, y = x$Data, type = \"l\", \n       xlab = \"Date-time\", ylab = \"Glucose (mg/dL)\")\n  invisible(x)\n}\n\nprint(cgm_profile)\n\n\n\n\n\n\n\n\n\nsummary.cgm_S3 &lt;- function(x, ...){\n  demo_string &lt;- paste0(\"Age: \", x$Age, \", Gender: \", x$Gender)\n  biomk_string &lt;- paste0(\"BMI: \", x$BMI, \", HbA1c: \", x$HbA1c)\n  cgm_string &lt;- paste0(\"Mean Glucose: \", round(mean(x$Data), 2), \", Std. Dev. Glucose: \", round(sd(x$Data), 2))\n  object &lt;- list(demographics = demo_string, \n                 biomarkers = biomk_string, \n                 cgm = cgm_string)\n  class(object) &lt;- \"summary_CGM\"\n  object\n}\n\nprint.summary_CGM &lt;- function(x, ...){\n  cat(paste(paste0(\"Demographics - \", x$demographics), \n            paste0(\"Biomarkers - \", x$biomarkers), \n            paste0(\"CGM Metrics - \", x$cgm), sep = \"\\n\"))\n  invisible(x)\n}\n\nsummary(cgm_profile)\n\nDemographics - Age: 55, Gender: F\nBiomarkers - BMI: 25, HbA1c: 25\nCGM Metrics - Mean Glucose: 80, Std. Dev. Glucose: 2.37\n\n\nWe may also wish to perform any range of standard operations upon the CGM time series data, like smoothing.\n\nsmooth &lt;- function(x) UseMethod(\"smooth\")\nsmooth.cgm_S3 &lt;- function(x){\n  smoothed_CGM &lt;- fitted(lm(x$Data ~ bs(x$Times, df = 12*14)))\n  x$Data &lt;- smoothed_CGM\n  return(x)\n}\n\nsmoothed_cgm_profile = smooth(cgm_profile)\nprint(smoothed_cgm_profile)"
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#s4-constructor-for-cgm-object",
    "href": "readings/08-oop-paradigm/index.html#s4-constructor-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S4 Constructor for CGM Object",
    "text": "S4 Constructor for CGM Object\n\nsetClass(Class = \"cgm_S4\", \n         slots = list(Data = \"numeric\", \n                      Times = \"POSIXct\", \n                      Age = \"numeric\", \n                      Gender = \"character\", \n                      BMI = \"numeric\", \n                      HbA1c = \"numeric\"))\n\ncgm_profile &lt;- new(\"cgm_S4\", Data = simulated_CGM, Times = simulated_TS,\n                   Age = demo$Age, Gender = demo$Gender, BMI = biomk$BMI, \n                   HbA1c = biomk$HbA1c)\n\nclass(cgm_profile)\n\n[1] \"cgm_S4\"\nattr(,\"package\")\n[1] \".GlobalEnv\""
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#s4-methods-for-cgm-object",
    "href": "readings/08-oop-paradigm/index.html#s4-methods-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S4 Methods for CGM Object",
    "text": "S4 Methods for CGM Object\nWe can overwrite the generic “print” and “summary” methods to achieve the same functionality in S4.\n\nsetGeneric(\"print\")\n\n[1] \"print\"\n\nsetGeneric(\"summary\")\n\n[1] \"summary\"\n\nsetGeneric(\"smooth\", function(x){\n  standardGeneric(\"smooth\")\n})\n\n[1] \"smooth\"\n\n\n\nsetMethod(f = \"print\", \n          signature = c(x = \"cgm_S4\"), \n          definition = function(x){\n            plot(x = x@Times, y = x@Data, type = \"l\", \n            xlab = \"Date-time\", ylab = \"Glucose (mg/dL)\")\n            invisible(x)\n          })\n\nprint(cgm_profile)\n\n\n\n\n\n\n\n\n\nsetMethod(f = \"summary\", \n          signature = c(object = \"cgm_S4\"), \n          definition = function(object){\n            MG = round(mean(object@Data), 2)\n            SDG = round(sd(object@Data), 2)\n            \n            demo_string &lt;- paste0(\"Demographics - Age: \", object@Age, \", Gender: \", object@Gender)\n            biomk_string &lt;- paste0(\"Biomarkers - BMI: \", object@BMI, \", HbA1c: \", object@HbA1c)\n            cgm_string &lt;- paste0(\"CGM Metrics - Mean Glucose: \", MG, \", Std. Dev. Glucose: \", SDG)\n            cat(paste(demo_string, biomk_string, cgm_string, sep = \"\\n\"))\n            invisible(object)\n          })\n\nsummary(cgm_profile)\n\nDemographics - Age: 55, Gender: F\nBiomarkers - BMI: 25, HbA1c: 8.5\nCGM Metrics - Mean Glucose: 80, Std. Dev. Glucose: 2.37\n\n\n\nsetMethod(f = \"smooth\", \n          signature = c(x = \"cgm_S4\"), \n          definition = function(x){\n            smoothed_CGM &lt;- fitted(lm(x@Data ~ bs(x@Times, df = 12*14)))\n            x@Data &lt;- smoothed_CGM\n            x\n          })\n\nsmoothed_cgm_profile = smooth(cgm_profile)\nprint(smoothed_cgm_profile)"
  },
  {
    "objectID": "readings/08-oop-paradigm/index.html#rc-constructor-for-cgm-object-with-methods",
    "href": "readings/08-oop-paradigm/index.html#rc-constructor-for-cgm-object-with-methods",
    "title": "Object Oriented Programming",
    "section": "RC Constructor for CGM Object with Methods",
    "text": "RC Constructor for CGM Object with Methods\nAll of the same functionality can also be replicated using Reference Classes. This alternative framework might even be preferable for this application, as packaging methods with objects compartmentalizes functionality for easily-distributable and accessible software. The objects are also mutable, unlike S3 and S4, which is preferable for certain types of objects which should be fluid when used.\n\ncgm_RC &lt;- setRefClass(\"cgm_RC\", \n                      fields = list(Data = \"numeric\", \n                                    Times = \"POSIXct\", \n                                    Age = \"numeric\", \n                                    Gender = \"character\", \n                                    BMI = \"numeric\", \n                                    HbA1c = \"numeric\"), \n              methods = list(\n                  print = function(){\n                    plot(x = Times, y = Data, type = \"l\", \n                        xlab = \"Date-time\", ylab = \"Glucose (mg/dL)\")\n                    invisible(.self)\n                  },\n                  summmary = function(){\n                    MG = round(mean(Data), 2)\n                    SDG = round(sd(Data), 2)\n            \n                    demo_string &lt;- paste0(\"Demographics - Age: \", Age, \", Gender: \", Gender)\n                    biomk_string &lt;- paste0(\"Biomarkers - BMI: \", BMI, \", HbA1c: \", HbA1c)\n                    cgm_string &lt;- paste0(\"CGM Metrics - Mean Glucose: \", MG, \", Std. Dev. Glucose: \", SDG)\n                    cat(paste(demo_string, biomk_string, cgm_string, sep = \"\\n\"))\n                    invisible(.self)\n                  },\n                  smooth = function(){\n                    smoothed_CGM &lt;- fitted(lm(Data ~ bs(Times, df = 12*14)))\n                    Data &lt;&lt;- smoothed_CGM\n                  }\n                ))\n\ncgm_profile &lt;- cgm_RC$new(Data = simulated_CGM, Times = simulated_TS,\n                   Age = demo$Age, Gender = demo$Gender, BMI = biomk$BMI, \n                   HbA1c = biomk$HbA1c)\n\n\ncgm_profile$print()\n\n\n\n\n\n\n\n\n\ncgm_profile$summmary()\n\nDemographics - Age: 55, Gender: F\nBiomarkers - BMI: 25, HbA1c: 8.5\nCGM Metrics - Mean Glucose: 80, Std. Dev. Glucose: 2.37\n\n\n\ncgm_profile$smooth()\ncgm_profile$print()"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html",
    "href": "readings/12-programming-in-python/index.html",
    "title": "Programming in Python with reticulate",
    "section": "",
    "text": "As the number of computational and statistical methods for the analysis data continue to increase, you will find many will be implemented in other languages.\nOften Python is the language of choice.\nPython is incredibly powerful and I increasingly interact with it on very frequent basis these days. To be able to leverage software tools implemented in Python, today I am giving an overview of using Python from the perspective of an R user.\n\n\nFor this lecture, we will be using the reticulate R package, which provides a set of tools for interoperability between Python and R. The package includes facilities for:\n\nCalling Python from R in a variety of ways including (i) R Markdown, (ii) sourcing Python scripts, (iii) importing Python modules, and (iv) using Python interactively within an R session.\nTranslation between R and Python objects (for example, between R and Pandas data frames, or between R matrices and NumPy arrays).\n\n\n[Source: Rstudio]\n\n\n\n\n\n\nPro-tip for installing python\n\n\n\nInstalling python: If you would like recommendations on installing python, I like these resources:\n\nPy Pkgs: https://py-pkgs.org/02-setup#installing-python\nmy fav: Using conda environments with mini-forge: https://github.com/conda-forge/miniforge\nfrom reticulate: https://rstudio.github.io/reticulate/articles/python_packages.html\n\nWhat’s happening under the hood?: reticulate embeds a Python session within your R session, enabling seamless, high-performance interoperability.\nIf you are an R developer that uses Python for some of your work or a member of data science team that uses both languages, reticulate can make your life better!\n\n\n\n\n\nLet’s try it out. Before we get started, you will need to install the packages:\n\ninstall.package(\"reticulate\")\n\nWe will also load the here and tidyverse packages for our lesson:\n\nlibrary(here)\nlibrary(tidyverse)\nlibrary(reticulate)\n\n\n\n\nIf python is not installed on your computer, you can use the install_python() function from reticulate to install it.\n\nhttps://rstudio.github.io/reticulate/reference/install_python\n\nIf python is already installed, by default, reticulate uses the version of Python found on your PATH\n\nSys.which(\"python3\")\n\n                    python3 \n\"/opt/homebrew/bin/python3\" \n\n\nThe use_python() function enables you to specify an alternate version, for example:\n\nuse_python(\"/usr/&lt;new&gt;/&lt;path&gt;/local/bin/python\")\n\nFor example, I can define the path explicitly:\n\nuse_python(\"/opt/homebrew/Caskroom/miniforge/base/bin/python\")\n\nYou can confirm that reticulate is using the correct version of python that you requested using the py_discover_config function:\n\npy_discover_config()\n\npython:         /opt/homebrew/Caskroom/miniforge/base/bin/python\nlibpython:      /opt/homebrew/Caskroom/miniforge/base/lib/libpython3.9.dylib\npythonhome:     /opt/homebrew/Caskroom/miniforge/base:/opt/homebrew/Caskroom/miniforge/base\nversion:        3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:38:11)  [Clang 14.0.6 ]\nnumpy:          /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/numpy\nnumpy_version:  1.26.4\n\nNOTE: Python version was forced by use_python() function\n\n\n\n\n\nThere are a variety of ways to integrate Python code into your R projects:\n\nPython in R Markdown — A new Python language engine for R Markdown that supports bi-directional communication between R and Python (R chunks can access Python objects and vice-versa).\nImporting Python modules — The import() function enables you to import any Python module and call its functions directly from R.\nSourcing Python scripts — The source_python() function enables you to source a Python script the same way you would source() an R script (Python functions and objects defined within the script become directly available to the R session).\nPython REPL — The repl_python() function creates an interactive Python console within R. Objects you create within Python are available to your R session (and vice-versa).\n\nBelow I will focus on introducing the first and last one. However, before we do that, let’s introduce a bit about python basics."
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#overview",
    "href": "readings/12-programming-in-python/index.html#overview",
    "title": "Programming in Python with reticulate",
    "section": "",
    "text": "For this lecture, we will be using the reticulate R package, which provides a set of tools for interoperability between Python and R. The package includes facilities for:\n\nCalling Python from R in a variety of ways including (i) R Markdown, (ii) sourcing Python scripts, (iii) importing Python modules, and (iv) using Python interactively within an R session.\nTranslation between R and Python objects (for example, between R and Pandas data frames, or between R matrices and NumPy arrays).\n\n\n[Source: Rstudio]\n\n\n\n\n\n\nPro-tip for installing python\n\n\n\nInstalling python: If you would like recommendations on installing python, I like these resources:\n\nPy Pkgs: https://py-pkgs.org/02-setup#installing-python\nmy fav: Using conda environments with mini-forge: https://github.com/conda-forge/miniforge\nfrom reticulate: https://rstudio.github.io/reticulate/articles/python_packages.html\n\nWhat’s happening under the hood?: reticulate embeds a Python session within your R session, enabling seamless, high-performance interoperability.\nIf you are an R developer that uses Python for some of your work or a member of data science team that uses both languages, reticulate can make your life better!"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#install-reticulate",
    "href": "readings/12-programming-in-python/index.html#install-reticulate",
    "title": "Programming in Python with reticulate",
    "section": "",
    "text": "Let’s try it out. Before we get started, you will need to install the packages:\n\ninstall.package(\"reticulate\")\n\nWe will also load the here and tidyverse packages for our lesson:\n\nlibrary(here)\nlibrary(tidyverse)\nlibrary(reticulate)"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#python-path",
    "href": "readings/12-programming-in-python/index.html#python-path",
    "title": "Programming in Python with reticulate",
    "section": "",
    "text": "If python is not installed on your computer, you can use the install_python() function from reticulate to install it.\n\nhttps://rstudio.github.io/reticulate/reference/install_python\n\nIf python is already installed, by default, reticulate uses the version of Python found on your PATH\n\nSys.which(\"python3\")\n\n                    python3 \n\"/opt/homebrew/bin/python3\" \n\n\nThe use_python() function enables you to specify an alternate version, for example:\n\nuse_python(\"/usr/&lt;new&gt;/&lt;path&gt;/local/bin/python\")\n\nFor example, I can define the path explicitly:\n\nuse_python(\"/opt/homebrew/Caskroom/miniforge/base/bin/python\")\n\nYou can confirm that reticulate is using the correct version of python that you requested using the py_discover_config function:\n\npy_discover_config()\n\npython:         /opt/homebrew/Caskroom/miniforge/base/bin/python\nlibpython:      /opt/homebrew/Caskroom/miniforge/base/lib/libpython3.9.dylib\npythonhome:     /opt/homebrew/Caskroom/miniforge/base:/opt/homebrew/Caskroom/miniforge/base\nversion:        3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:38:11)  [Clang 14.0.6 ]\nnumpy:          /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/numpy\nnumpy_version:  1.26.4\n\nNOTE: Python version was forced by use_python() function"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#calling-python-in-r",
    "href": "readings/12-programming-in-python/index.html#calling-python-in-r",
    "title": "Programming in Python with reticulate",
    "section": "",
    "text": "There are a variety of ways to integrate Python code into your R projects:\n\nPython in R Markdown — A new Python language engine for R Markdown that supports bi-directional communication between R and Python (R chunks can access Python objects and vice-versa).\nImporting Python modules — The import() function enables you to import any Python module and call its functions directly from R.\nSourcing Python scripts — The source_python() function enables you to source a Python script the same way you would source() an R script (Python functions and objects defined within the script become directly available to the R session).\nPython REPL — The repl_python() function creates an interactive Python console within R. Objects you create within Python are available to your R session (and vice-versa).\n\nBelow I will focus on introducing the first and last one. However, before we do that, let’s introduce a bit about python basics."
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#start-python",
    "href": "readings/12-programming-in-python/index.html#start-python",
    "title": "Programming in Python with reticulate",
    "section": "start python",
    "text": "start python\nThere are two modes you can write Python code in: interactive mode or script mode. If you open up a UNIX command window and have a command-line interface, you can simply type python (or python3) in the shell:\n\npython3\n\nand the interactive mode will open up. You can write code in the interactive mode and Python will interpret the code using the python interpreter.\nAnother way to pass code to Python is to store code in a file ending in .py, and execute the file in the script mode using\n\npython3 myscript.py\n\nTo check what version of Python you are using, type the following in the shell:\n\npython3 --version"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#objects-in-python",
    "href": "readings/12-programming-in-python/index.html#objects-in-python",
    "title": "Programming in Python with reticulate",
    "section": "objects in python",
    "text": "objects in python\nEverything in Python is an object. Think of an object as a data structure that contains both data as well as functions. These objects can be variables, functions, and modules which are all objects. We can operate on this objects with what are called operators (e.g. addition, subtraction, concatenation or other operations), define/apply functions, test/apply for conditionals statements, (e.g. if, else statements) or iterate over the objects.\nNot all objects are required to have attributes and methods to operate on the objects in Python, but everything is an object (i.e. all objects can be assigned to a variable or passed as an argument to a function). A user can work with built-in defined classes of objects or can create new classes of objects. Using these objects, a user can perform operations on the objects by modifying / interacting with them."
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#variables",
    "href": "readings/12-programming-in-python/index.html#variables",
    "title": "Programming in Python with reticulate",
    "section": "variables",
    "text": "variables\nVariable names are case sensitive, can contain numbers and letters, can contain underscores, cannot begin with a number, cannot contain illegal characters and cannot be one of the 31 keywords in Python:\n\n“and, as, assert, break, class, continue, def, del, elif, else, except, exec, finally, for, from, global, if, import, in, is, lambda, not, or, pass, print, raise, return, try, while, with, yield”"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#operators",
    "href": "readings/12-programming-in-python/index.html#operators",
    "title": "Programming in Python with reticulate",
    "section": "operators",
    "text": "operators\n\nNumeric operators are +, -, *, /, ** (exponent), % (modulus if applied to integers)\nString and list operators: + and * .\nAssignment operator: =\nThe augmented assignment operator += (or -=) can be used like n += x which is equal to n = n + x\nBoolean relational operators: == (equal), != (not equal), &gt;, &lt;, &gt;= (greater than or equal to), &lt;= (less than or equal to)\nBoolean expressions will produce True or False\nLogical operators: and, or, and not. e.g. x &gt; 1 and x &lt;= 5\n\n\n2 ** 3\n\n8\n\nx = 3 \nx &gt; 1 and x &lt;= 5\n\nTrue\n\n\nAnd in R, the execution changes from Python to R seamlessly\n\n2^3 \n\n[1] 8\n\nx = 3\nx &gt; 1 & x &lt;=5\n\n[1] TRUE"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#format-operators",
    "href": "readings/12-programming-in-python/index.html#format-operators",
    "title": "Programming in Python with reticulate",
    "section": "format operators",
    "text": "format operators\nIf % is applied to strings, this operator is the format operator. It tells Python how to format a list of values in a string. For example,\n\n%d says to format the value as an integer\n%g says to format the value as an float\n%s says to format the value as an string\n\n\nprint('In %d days, I have eaten %g %s.' % (5, 3.5, 'cupcakes'))\n\nIn 5 days, I have eaten 3.5 cupcakes."
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#functions",
    "href": "readings/12-programming-in-python/index.html#functions",
    "title": "Programming in Python with reticulate",
    "section": "functions",
    "text": "functions\nPython contains a small list of very useful built-in functions.\nAll other functions need defined by the user or need to be imported from modules.\n\n\n\n\n\n\nPro-tip\n\n\n\nFor a more detailed list on the built-in functions in Python, see Built-in Python Functions.\n\n\nThe first function we will discuss, type(), reports the type of any object, which is very useful when handling multiple data types (remember, everything in Python is an object). Here are some the mains types you will encounter:\n\ninteger (int)\nfloating-point (float)\nstring (str)\nlist (list)\ndictionary (dict)\ntuple (tuple)\nfunction (function)\nmodule (module)\nboolean (bool): e.g. True, False\nenumerate (enumerate)\n\nIf we asked for the type of a string “Let’s go Ravens!”\n\ntype(\"Let's go Ravens!\")\n\n&lt;class 'str'&gt;\n\n\nThis would return the str type.\nYou have also seen how to use the print() function. The function print will accept an argument and print the argument to the screen. Print can be used in two ways:\n\nprint(\"Let's go Ravens!\")\n\n[1] \"Let's go Ravens!\""
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#new-functions",
    "href": "readings/12-programming-in-python/index.html#new-functions",
    "title": "Programming in Python with reticulate",
    "section": "new functions",
    "text": "new functions\nNew functions can be defined using one of the 31 keywords in Python def.\n\ndef new_world(): \n    return 'Hello world!'\n    \nprint(new_world())\n\nHello world!\n\n\nThe first line of the function (the header) must start with def, the name of the function (which can contain underscores), parentheses (with any arguments inside of it) and a colon. The arguments can be specified in any order.\nThe rest of the function (the body) always has an indentation of four spaces. If you define a function in the interactive mode, the interpreter will print ellipses (…) to let you know the function is not complete. To complete the function, enter an empty line (not necessary in a script).\nTo return a value from a function, use return. The function will immediately terminate and not run any code written past this point.\n\ndef squared(x):\n    \"\"\" Return the square of a  \n        value \"\"\"\n    return x ** 2\n\nprint(squared(4))\n\n16\n\n\n\n\n\n\n\n\nNote\n\n\n\npython has its version of ... (also from docs.python.org)\n\ndef concat(*args, sep=\"/\"):\n return sep.join(args)  \n\nconcat(\"a\", \"b\", \"c\")\n\n'a/b/c'"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#iteration",
    "href": "readings/12-programming-in-python/index.html#iteration",
    "title": "Programming in Python with reticulate",
    "section": "iteration",
    "text": "iteration\nIterative loops can be written with the for, while and break statements.\nDefining a for loop is similar to defining a new function.\n\nThe header ends with a colon and the body is indented.\nThe function range(n) takes in an integer n and creates a set of values from 0 to n - 1.\n\n\nfor i in range(3):\n  print('Baby shark, doo doo doo doo doo doo!')\n\nBaby shark, doo doo doo doo doo doo!\nBaby shark, doo doo doo doo doo doo!\nBaby shark, doo doo doo doo doo doo!\n\nprint('Baby shark!')\n\nBaby shark!\n\n\nfor loops are not just for counters, but they can iterate through many types of objects such as strings, lists and dictionaries.\nThe function len() can be used to:\n\nCalculate the length of a string\nCalculate the number of elements in a list\nCalculate the number of items (key-value pairs) in a dictionary\nCalculate the number elements in the tuple\n\n\nx = 'Baby shark!'\nlen(x)\n\n11"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#methods-for-each-type-of-object-dot-notation",
    "href": "readings/12-programming-in-python/index.html#methods-for-each-type-of-object-dot-notation",
    "title": "Programming in Python with reticulate",
    "section": "methods for each type of object (dot notation)",
    "text": "methods for each type of object (dot notation)\nFor strings, lists and dictionaries, there are set of methods you can use to manipulate the objects. In general, the notation for methods is the dot notation.\nThe syntax is the name of the object followed by a dot (or period) followed by the name of the method.\n\nx = \"Hello Baltimore!\"\nx.split()\n\n['Hello', 'Baltimore!']"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#data-structures",
    "href": "readings/12-programming-in-python/index.html#data-structures",
    "title": "Programming in Python with reticulate",
    "section": "Data structures",
    "text": "Data structures\nWe have already seen lists. Python has other data structures built in.\n\nSets {\"a\", \"a\", \"a\", \"b\"} (unique elements)\nTuples (1, 2, 3) (a lot like lists but not mutable, i.e. need to create a new to modify)\nDictionaries\n\n\ndict = {\"a\" : 1, \"b\" : 2}\ndict['a']\n\n1\n\ndict['b']\n\n2\n\n\nMore about data structures can be founds at the python docs"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#python-engine-within-r-markdown",
    "href": "readings/12-programming-in-python/index.html#python-engine-within-r-markdown",
    "title": "Programming in Python with reticulate",
    "section": "Python engine within R Markdown",
    "text": "Python engine within R Markdown\nThe reticulate package includes a Python engine for R Markdown with the following features:\n\nRun Python chunks in a single Python session embedded within your R session (shared variables/state between Python chunks)\nPrinting of Python output, including graphical output from matplotlib.\nAccess to objects created within Python chunks from R using the py object (e.g. py$x would access an x variable created within Python from R).\nAccess to objects created within R chunks from Python using the r object (e.g. r.x would access to x variable created within R from Python)\n\n\n\n\n\n\n\nConversions\n\n\n\nBuilt in conversion for many Python object types is provided, including NumPy arrays and Pandas data frames."
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#from-python-to-r",
    "href": "readings/12-programming-in-python/index.html#from-python-to-r",
    "title": "Programming in Python with reticulate",
    "section": "From Python to R",
    "text": "From Python to R\nAs an example, you can use Pandas to read and manipulate data then easily plot the Pandas data frame using ggplot2:\nLet’s first create a flights.csv dataset in R and save it using write_csv from readr:\n\n# checks to see if a folder called \"data\" exists; if not, it installs it\nif(!file.exists(here(\"data\"))){\n  dir.create(here(\"data\"))\n}\n\n# checks to see if a file called \"flights.csv\" exists; if not, it saves it to the data folder\nif(!file.exists(here(\"data\", \"flights.csv\"))){\n  readr::write_csv(nycflights13::flights, \n                   file = here(\"data\", \"flights.csv\"))\n}\n\nnycflights13::flights %&gt;% \n  head()\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNext, we use Python to read in the file and do some data wrangling\n\nimport pandas\nflights_path = \"/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/data/flights.csv\"\nflights = pandas.read_csv(flights_path)\nflights = flights[flights['dest'] == \"ORD\"]\nflights = flights[['carrier', 'dep_delay', 'arr_delay']]\nflights = flights.dropna()\nflights\n\n       carrier  dep_delay  arr_delay\n5           UA       -4.0       12.0\n9           AA       -2.0        8.0\n25          MQ        8.0       32.0\n38          AA       -1.0       14.0\n57          AA       -4.0        4.0\n...        ...        ...        ...\n336645      AA      -12.0      -37.0\n336669      UA       -7.0      -13.0\n336675      MQ       -7.0      -11.0\n336696      B6       -5.0      -23.0\n336709      AA      -13.0      -38.0\n\n[16566 rows x 3 columns]\n\n\n\nhead(py$flights)\n\n   carrier dep_delay arr_delay\n5       UA        -4        12\n9       AA        -2         8\n25      MQ         8        32\n38      AA        -1        14\n57      AA        -4         4\n70      UA         9        20\n\npy$flights_path \n\n[1] \"/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2024/data/flights.csv\"\n\n\n\nclass(py$flights)\n\n[1] \"data.frame\"\n\nclass(py$flights_path)\n\n[1] \"character\"\n\n\nNext, we can use R to visualize the Pandas DataFrame.\nThe data frame is loaded in as an R object now stored in the variable py.\n\nggplot(py$flights, aes(x = carrier, y = arr_delay)) + \n  geom_point() + \n  geom_jitter()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe reticulate Python engine is enabled by default within R Markdown whenever reticulate is installed.\n\n\n\nFrom R to Python\nUse R to read and manipulate data\n\nlibrary(tidyverse)\nflights &lt;- read_csv(here(\"data\",\"flights.csv\")) %&gt;%\n  filter(dest == \"ORD\") %&gt;%\n  select(carrier, dep_delay, arr_delay) %&gt;%\n  na.omit()\n\nRows: 336776 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (4): carrier, tailnum, origin, dest\ndbl  (14): year, month, day, dep_time, sched_dep_time, dep_delay, arr_time, ...\ndttm  (1): time_hour\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nflights\n\n# A tibble: 16,566 × 3\n   carrier dep_delay arr_delay\n   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 UA             -4        12\n 2 AA             -2         8\n 3 MQ              8        32\n 4 AA             -1        14\n 5 AA             -4         4\n 6 UA              9        20\n 7 UA              2        21\n 8 AA             -6       -12\n 9 MQ             39        49\n10 B6             -2        15\n# ℹ 16,556 more rows\n\n\n\n\nUse Python to print R dataframe\nIf you recall, we can access objects created within R chunks from Python using the r object (e.g. r.x would access to x variable created within R from Python).\nWe can then ask for the first ten rows using the head() function in python.\n\nr.flights.head(10)\n\n  carrier  dep_delay  arr_delay\n0      UA       -4.0       12.0\n1      AA       -2.0        8.0\n2      MQ        8.0       32.0\n3      AA       -1.0       14.0\n4      AA       -4.0        4.0\n5      UA        9.0       20.0\n6      UA        2.0       21.0\n7      AA       -6.0      -12.0\n8      MQ       39.0       49.0\n9      B6       -2.0       15.0"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#import-python-modules",
    "href": "readings/12-programming-in-python/index.html#import-python-modules",
    "title": "Programming in Python with reticulate",
    "section": "import python modules",
    "text": "import python modules\nYou can use the import() function to import any Python module and call it from R. For example, this code imports the Python os module in python and calls the listdir() function:\n\nos &lt;- import(\"os\")\nos$listdir(\".\")\n\n[1] \"index.qmd\"       \"index_files\"     \"index.rmarkdown\"\n\n\nSimilarly, we can import the pandas library:\n\npd &lt;- import('pandas')\ntest &lt;- pd$read_csv(here(\"data\",\"flights.csv\"))\nhead(test)\n\n  year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n1 2013     1   1      517            515         2      830            819\n2 2013     1   1      533            529         4      850            830\n3 2013     1   1      542            540         2      923            850\n4 2013     1   1      544            545        -1     1004           1022\n5 2013     1   1      554            600        -6      812            837\n6 2013     1   1      554            558        -4      740            728\n  arr_delay carrier flight tailnum origin dest air_time distance hour minute\n1        11      UA   1545  N14228    EWR  IAH      227     1400    5     15\n2        20      UA   1714  N24211    LGA  IAH      227     1416    5     29\n3        33      AA   1141  N619AA    JFK  MIA      160     1089    5     40\n4       -18      B6    725  N804JB    JFK  BQN      183     1576    5     45\n5       -25      DL    461  N668DN    LGA  ATL      116      762    6      0\n6        12      UA   1696  N39463    EWR  ORD      150      719    5     58\n             time_hour\n1 2013-01-01T10:00:00Z\n2 2013-01-01T10:00:00Z\n3 2013-01-01T10:00:00Z\n4 2013-01-01T10:00:00Z\n5 2013-01-01T11:00:00Z\n6 2013-01-01T10:00:00Z\n\nclass(test)\n\n[1] \"data.frame\"\n\n\nor the scikit-learn python library:\n\nskl_lr &lt;- import(\"sklearn.linear_model\")\nskl_lr\n\nModule(sklearn.linear_model)"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#calling-python-scripts",
    "href": "readings/12-programming-in-python/index.html#calling-python-scripts",
    "title": "Programming in Python with reticulate",
    "section": "Calling python scripts",
    "text": "Calling python scripts\n\nsource_python(\"secret_functions.py\")\nsubject_1 &lt;- read_subject(\"secret_data.csv\")"
  },
  {
    "objectID": "readings/12-programming-in-python/index.html#calling-the-python-repl",
    "href": "readings/12-programming-in-python/index.html#calling-the-python-repl",
    "title": "Programming in Python with reticulate",
    "section": "Calling the python repl",
    "text": "Calling the python repl\nIf you want to work with Python interactively you can call the repl_python() function, which provides a Python REPL embedded within your R session.\n\nrepl_python()\n\nObjects created within the Python REPL can be accessed from R using the py object exported from reticulate. For example:\n\n[Source: Rstudio]\ni.e. objects do have permenancy in R after exiting the python repl.\nSo typing x = 4 in the repl will put py$x as 4 in R after you exit the repl.\nEnter exit within the Python REPL to return to the R prompt."
  }
]